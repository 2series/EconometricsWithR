<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Using R for Introduction to Econometrics</title>
  <meta name="description" content="Using <tt>R</tt> for Introduction to Econometrics">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Using R for Introduction to Econometrics" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="Emwikts1970/URFITE-Bookdown" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Using R for Introduction to Econometrics" />
  
  
  

<meta name="author" content="Christoph Hanck, Martin Arnold, Alexander Gerber and Martin Schmelzer">


<meta name="date" content="2018-08-14">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="scatterplots-sample-covariance-and-sample-correlation.html">
<link rel="next" href="lrwor.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.2/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.7.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="libs/plotlyjs-1.29.2/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotlyjs-1.29.2/plotly-latest.min.js"></script>
<script src="js/hideOutput.js"></script>
<script type="text/javascript" src="MathJax-2.7.2/MathJax.js?config=default"></script>

 <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        extensions: ["tex2jax.js", "TeX/AMSmath.js"],
        tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
        jax: ["input/TeX","output/CommonHTML"]
      });
      MathJax.Hub.processSectionDelay = 0;
  </script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110299877-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110299877-1');
</script>

<!-- open review block -->

<script async defer src="https://hypothes.is/embed.js"></script>

<!-- datacamp-light-latest -->

<script src="https://cdn.datacamp.com/datacamp-light-latest.min.js"></script>


<!-- <script src="js/d3.v3.min.js"></script>
<script src="js/leastsquares.js"></script>
<script src="js/d3functions.js"></script>
<script src="d3.slider.js"></script>
<script src="slrm.js"></script> -->


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; background-color: #f8f8f8; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
pre, code { background-color: #f8f8f8; }
code > span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code > span.dt { color: #204a87; } /* DataType */
code > span.dv { color: #0000cf; } /* DecVal */
code > span.bn { color: #0000cf; } /* BaseN */
code > span.fl { color: #0000cf; } /* Float */
code > span.ch { color: #4e9a06; } /* Char */
code > span.st { color: #4e9a06; } /* String */
code > span.co { color: #8f5902; font-style: italic; } /* Comment */
code > span.ot { color: #8f5902; } /* Other */
code > span.al { color: #ef2929; } /* Alert */
code > span.fu { color: #000000; } /* Function */
code > span.er { color: #a40000; font-weight: bold; } /* Error */
code > span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #000000; } /* Constant */
code > span.sc { color: #000000; } /* SpecialChar */
code > span.vs { color: #4e9a06; } /* VerbatimString */
code > span.ss { color: #4e9a06; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #000000; } /* Variable */
code > span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code > span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code > span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code > span.ex { } /* Extension */
code > span.at { color: #c4a000; } /* Attribute */
code > span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code > span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="toc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">URFITE</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="a-very-short-introduction-to-r-and-rstudio.html"><a href="a-very-short-introduction-to-r-and-rstudio.html"><i class="fa fa-check"></i><b>1.1</b> A Very Short Introduction to <tt>R</tt> and <em>RStudio</em></a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="pt.html"><a href="pt.html"><i class="fa fa-check"></i><b>2</b> Probability Theory</a><ul>
<li class="chapter" data-level="2.1" data-path="random-variables-and-probability-distributions.html"><a href="random-variables-and-probability-distributions.html"><i class="fa fa-check"></i><b>2.1</b> Random Variables and Probability Distributions</a><ul>
<li class="chapter" data-level="" data-path="random-variables-and-probability-distributions.html"><a href="random-variables-and-probability-distributions.html#probability-distributions-of-discrete-random-variables"><i class="fa fa-check"></i>Probability Distributions of Discrete Random Variables</a></li>
<li class="chapter" data-level="" data-path="random-variables-and-probability-distributions.html"><a href="random-variables-and-probability-distributions.html#bernoulli-trials"><i class="fa fa-check"></i>Bernoulli Trials</a></li>
<li class="chapter" data-level="" data-path="random-variables-and-probability-distributions.html"><a href="random-variables-and-probability-distributions.html#expected-value-mean-and-variance"><i class="fa fa-check"></i>Expected Value, Mean and Variance</a></li>
<li class="chapter" data-level="" data-path="random-variables-and-probability-distributions.html"><a href="random-variables-and-probability-distributions.html#probability-distributions-of-continuous-random-variables"><i class="fa fa-check"></i>Probability Distributions of Continuous Random Variables</a></li>
<li class="chapter" data-level="" data-path="random-variables-and-probability-distributions.html"><a href="random-variables-and-probability-distributions.html#the-normal-distribution"><i class="fa fa-check"></i>The Normal Distribution</a></li>
<li class="chapter" data-level="" data-path="random-variables-and-probability-distributions.html"><a href="random-variables-and-probability-distributions.html#the-chi-squared-distribution"><i class="fa fa-check"></i>The Chi-Squared Distribution</a></li>
<li class="chapter" data-level="" data-path="random-variables-and-probability-distributions.html"><a href="random-variables-and-probability-distributions.html#thetdist"><i class="fa fa-check"></i>The Student t Distribution</a></li>
<li class="chapter" data-level="" data-path="random-variables-and-probability-distributions.html"><a href="random-variables-and-probability-distributions.html#the-f-distribution"><i class="fa fa-check"></i>The F Distribution</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="RSATDOSA.html"><a href="RSATDOSA.html"><i class="fa fa-check"></i><b>2.2</b> Random Sampling and the Distribution of Sample Averages</a><ul>
<li class="chapter" data-level="" data-path="RSATDOSA.html"><a href="RSATDOSA.html#mean-and-variance-of-the-sample-mean"><i class="fa fa-check"></i>Mean and Variance of the Sample Mean</a></li>
<li class="chapter" data-level="" data-path="RSATDOSA.html"><a href="RSATDOSA.html#large-sample-approximations-to-sampling-distributions"><i class="fa fa-check"></i>Large Sample Approximations to Sampling Distributions</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>2.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="arosur.html"><a href="arosur.html"><i class="fa fa-check"></i><b>3</b> A Review of Statistics using R</a><ul>
<li class="chapter" data-level="3.1" data-path="estimation-of-the-population-mean.html"><a href="estimation-of-the-population-mean.html"><i class="fa fa-check"></i><b>3.1</b> Estimation of the Population Mean</a></li>
<li class="chapter" data-level="3.2" data-path="potsm.html"><a href="potsm.html"><i class="fa fa-check"></i><b>3.2</b> Properties of the Sample Mean</a></li>
<li class="chapter" data-level="3.3" data-path="hypothesis-tests-concerning-the-population-mean.html"><a href="hypothesis-tests-concerning-the-population-mean.html"><i class="fa fa-check"></i><b>3.3</b> Hypothesis Tests Concerning the Population Mean</a><ul>
<li class="chapter" data-level="" data-path="hypothesis-tests-concerning-the-population-mean.html"><a href="hypothesis-tests-concerning-the-population-mean.html#the-p-value"><i class="fa fa-check"></i>The p-Value</a></li>
<li class="chapter" data-level="" data-path="hypothesis-tests-concerning-the-population-mean.html"><a href="hypothesis-tests-concerning-the-population-mean.html#calculating-the-p-value-when-the-standard-deviation-is-known"><i class="fa fa-check"></i>Calculating the p-Value when the Standard Deviation is Known</a></li>
<li class="chapter" data-level="" data-path="hypothesis-tests-concerning-the-population-mean.html"><a href="hypothesis-tests-concerning-the-population-mean.html#SVSSDASE"><i class="fa fa-check"></i>Sample Variance, Sample Standard Deviation and Standard Error</a></li>
<li class="chapter" data-level="" data-path="hypothesis-tests-concerning-the-population-mean.html"><a href="hypothesis-tests-concerning-the-population-mean.html#calculating-the-p-value-when-the-standard-deviation-is-unknown"><i class="fa fa-check"></i>Calculating the p-value When the Standard Deviation is Unknown</a></li>
<li class="chapter" data-level="" data-path="hypothesis-tests-concerning-the-population-mean.html"><a href="hypothesis-tests-concerning-the-population-mean.html#the-t-statistic"><i class="fa fa-check"></i>The t-statistic</a></li>
<li class="chapter" data-level="" data-path="hypothesis-tests-concerning-the-population-mean.html"><a href="hypothesis-tests-concerning-the-population-mean.html#hypothesis-testing-with-a-prespecified-significance-level"><i class="fa fa-check"></i>Hypothesis Testing with a Prespecified Significance Level</a></li>
<li class="chapter" data-level="" data-path="hypothesis-tests-concerning-the-population-mean.html"><a href="hypothesis-tests-concerning-the-population-mean.html#one-sided-alternatives"><i class="fa fa-check"></i>One-sided Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="confidence-intervals-for-the-population-mean.html"><a href="confidence-intervals-for-the-population-mean.html"><i class="fa fa-check"></i><b>3.4</b> Confidence Intervals for the Population Mean</a></li>
<li class="chapter" data-level="3.5" data-path="cmfdp.html"><a href="cmfdp.html"><i class="fa fa-check"></i><b>3.5</b> Comparing Means from Different Populations</a></li>
<li class="chapter" data-level="3.6" data-path="aattggoe.html"><a href="aattggoe.html"><i class="fa fa-check"></i><b>3.6</b> An Application to the Gender Gap of Earnings</a></li>
<li class="chapter" data-level="3.7" data-path="scatterplots-sample-covariance-and-sample-correlation.html"><a href="scatterplots-sample-covariance-and-sample-correlation.html"><i class="fa fa-check"></i><b>3.7</b> Scatterplots, Sample Covariance and Sample Correlation</a></li>
<li class="chapter" data-level="3.8" data-path="exercises-1.html"><a href="exercises-1.html"><i class="fa fa-check"></i><b>3.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="lrwor.html"><a href="lrwor.html"><i class="fa fa-check"></i><b>4</b> Linear Regression with One Regressor</a><ul>
<li class="chapter" data-level="4.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>4.1</b> Simple Linear Regression</a></li>
<li class="chapter" data-level="4.2" data-path="estimating-the-coefficients-of-the-linear-regression-model.html"><a href="estimating-the-coefficients-of-the-linear-regression-model.html"><i class="fa fa-check"></i><b>4.2</b> Estimating the Coefficients of the Linear Regression Model</a><ul>
<li class="chapter" data-level="" data-path="estimating-the-coefficients-of-the-linear-regression-model.html"><a href="estimating-the-coefficients-of-the-linear-regression-model.html#the-ordinary-least-squares-estimator"><i class="fa fa-check"></i>The Ordinary Least Squares Estimator</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="measures-of-fit.html"><a href="measures-of-fit.html"><i class="fa fa-check"></i><b>4.3</b> Measures of Fit</a><ul>
<li class="chapter" data-level="" data-path="measures-of-fit.html"><a href="measures-of-fit.html#the-coefficient-of-determination"><i class="fa fa-check"></i>The Coefficient of Determination</a></li>
<li class="chapter" data-level="" data-path="measures-of-fit.html"><a href="measures-of-fit.html#the-standard-error-of-the-regression"><i class="fa fa-check"></i>The Standard Error of the Regression</a></li>
<li class="chapter" data-level="" data-path="measures-of-fit.html"><a href="measures-of-fit.html#application-to-the-test-score-data"><i class="fa fa-check"></i>Application to the Test Score Data</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="tlsa.html"><a href="tlsa.html"><i class="fa fa-check"></i><b>4.4</b> The Least Squares Assumptions</a><ul>
<li class="chapter" data-level="" data-path="tlsa.html"><a href="tlsa.html#assumption-1-the-error-term-has-conditional-mean-of-zero"><i class="fa fa-check"></i>Assumption 1: The Error Term has Conditional Mean of Zero</a></li>
<li class="chapter" data-level="" data-path="tlsa.html"><a href="tlsa.html#assumption-2-independently-and-identically-distributed-data"><i class="fa fa-check"></i>Assumption 2: Independently and Identically Distributed Data</a></li>
<li class="chapter" data-level="" data-path="tlsa.html"><a href="tlsa.html#assumption-3-large-outliers-are-unlikely"><i class="fa fa-check"></i>Assumption 3: Large Outliers are Unlikely</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="tsdotoe.html"><a href="tsdotoe.html"><i class="fa fa-check"></i><b>4.5</b> The Sampling Distribution of the OLS Estimator</a><ul>
<li class="chapter" data-level="" data-path="tsdotoe.html"><a href="tsdotoe.html#simulation-study-1"><i class="fa fa-check"></i>Simulation Study 1</a></li>
<li class="chapter" data-level="" data-path="tsdotoe.html"><a href="tsdotoe.html#simulation-study-2"><i class="fa fa-check"></i>Simulation Study 2</a></li>
<li class="chapter" data-level="" data-path="tsdotoe.html"><a href="tsdotoe.html#simulation-study-3"><i class="fa fa-check"></i>Simulation Study 3</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="exercises-2.html"><a href="exercises-2.html"><i class="fa fa-check"></i><b>4.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="htaciitslrm.html"><a href="htaciitslrm.html"><i class="fa fa-check"></i><b>5</b> Hypothesis Tests and Confidence Intervals in the Simple Linear Regression Model</a><ul>
<li class="chapter" data-level="5.1" data-path="testing-two-sided-hypotheses-concerning-the-slope-coefficient.html"><a href="testing-two-sided-hypotheses-concerning-the-slope-coefficient.html"><i class="fa fa-check"></i><b>5.1</b> Testing Two-Sided Hypotheses Concerning the Slope Coefficient</a></li>
<li class="chapter" data-level="5.2" data-path="cifrc.html"><a href="cifrc.html"><i class="fa fa-check"></i><b>5.2</b> Confidence Intervals for Regression Coefficients</a><ul>
<li class="chapter" data-level="" data-path="cifrc.html"><a href="cifrc.html#simulation-study-confidence-intervals"><i class="fa fa-check"></i>Simulation Study: Confidence Intervals</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="rwxiabv.html"><a href="rwxiabv.html"><i class="fa fa-check"></i><b>5.3</b> Regression when X is a Binary Variable</a></li>
<li class="chapter" data-level="5.4" data-path="hah.html"><a href="hah.html"><i class="fa fa-check"></i><b>5.4</b> Heteroskedasticity and Homoskedasticity</a><ul>
<li class="chapter" data-level="" data-path="hah.html"><a href="hah.html#a-real-world-example-for-heteroskedasticity"><i class="fa fa-check"></i>A Real-World Example for Heteroskedasticity</a></li>
<li class="chapter" data-level="" data-path="hah.html"><a href="hah.html#should-we-care-about-heteroskedasticity"><i class="fa fa-check"></i>Should We Care About Heteroskedasticity?</a></li>
<li class="chapter" data-level="" data-path="hah.html"><a href="hah.html#computation-of-heteroskedasticity-robust-standard-errors"><i class="fa fa-check"></i>Computation of Heteroskedasticity-Robust Standard Errors</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="the-gauss-markov-theorem.html"><a href="the-gauss-markov-theorem.html"><i class="fa fa-check"></i><b>5.5</b> The Gauss-Markov Theorem</a><ul>
<li class="chapter" data-level="" data-path="the-gauss-markov-theorem.html"><a href="the-gauss-markov-theorem.html#simulation-study-blue-estimator"><i class="fa fa-check"></i>Simulation Study: BLUE Estimator</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="using-the-t-statistic-in-regression-when-the-sample-size-is-small.html"><a href="using-the-t-statistic-in-regression-when-the-sample-size-is-small.html"><i class="fa fa-check"></i><b>5.6</b> Using the t-Statistic in Regression When the Sample Size Is Small</a></li>
<li class="chapter" data-level="5.7" data-path="exercises-3.html"><a href="exercises-3.html"><i class="fa fa-check"></i><b>5.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="rmwmr.html"><a href="rmwmr.html"><i class="fa fa-check"></i><b>6</b> Regression Models with Multiple Regressors</a><ul>
<li class="chapter" data-level="6.1" data-path="omitted-variable-bias.html"><a href="omitted-variable-bias.html"><i class="fa fa-check"></i><b>6.1</b> Omitted Variable Bias</a></li>
<li class="chapter" data-level="6.2" data-path="tmrm.html"><a href="tmrm.html"><i class="fa fa-check"></i><b>6.2</b> The Multiple Regression Model</a></li>
<li class="chapter" data-level="6.3" data-path="mofimr.html"><a href="mofimr.html"><i class="fa fa-check"></i><b>6.3</b> Measures of Fit in Multiple Regression</a></li>
<li class="chapter" data-level="6.4" data-path="ols-assumptions-in-multiple-regression.html"><a href="ols-assumptions-in-multiple-regression.html"><i class="fa fa-check"></i><b>6.4</b> OLS Assumptions in Multiple Regression</a><ul>
<li class="chapter" data-level="" data-path="ols-assumptions-in-multiple-regression.html"><a href="ols-assumptions-in-multiple-regression.html#multicollinearity"><i class="fa fa-check"></i>Multicollinearity</a></li>
<li class="chapter" data-level="" data-path="ols-assumptions-in-multiple-regression.html"><a href="ols-assumptions-in-multiple-regression.html#simulation-study-imperfect-multicollinearity"><i class="fa fa-check"></i>Simulation Study: Imperfect Multicollinearity</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="the-distribution-of-the-ols-estimators-in-multiple-regression.html"><a href="the-distribution-of-the-ols-estimators-in-multiple-regression.html"><i class="fa fa-check"></i><b>6.5</b> The Distribution of the OLS Estimators in Multiple Regression</a></li>
<li class="chapter" data-level="6.6" data-path="exercises-4.html"><a href="exercises-4.html"><i class="fa fa-check"></i><b>6.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="htaciimr.html"><a href="htaciimr.html"><i class="fa fa-check"></i><b>7</b> Hypothesis Tests and Confidence Intervals in Multiple Regression</a><ul>
<li class="chapter" data-level="7.1" data-path="hypothesis-tests-and-confidence-intervals-for-a-single-coefficient.html"><a href="hypothesis-tests-and-confidence-intervals-for-a-single-coefficient.html"><i class="fa fa-check"></i><b>7.1</b> Hypothesis Tests and Confidence Intervals for a Single Coefficient</a></li>
<li class="chapter" data-level="7.2" data-path="an-application-to-test-scores-and-the-student-teacher-ratio.html"><a href="an-application-to-test-scores-and-the-student-teacher-ratio.html"><i class="fa fa-check"></i><b>7.2</b> An Application to Test Scores and the Student-Teacher Ratio</a><ul>
<li class="chapter" data-level="" data-path="an-application-to-test-scores-and-the-student-teacher-ratio.html"><a href="an-application-to-test-scores-and-the-student-teacher-ratio.html#another-augmentation-of-the-model"><i class="fa fa-check"></i>Another Augmentation of the Model</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="joint-hypothesis-testing-using-the-f-statistic.html"><a href="joint-hypothesis-testing-using-the-f-statistic.html"><i class="fa fa-check"></i><b>7.3</b> Joint Hypothesis Testing Using the F-Statistic</a></li>
<li class="chapter" data-level="7.4" data-path="confidence-sets-for-multiple-coefficients.html"><a href="confidence-sets-for-multiple-coefficients.html"><i class="fa fa-check"></i><b>7.4</b> Confidence Sets for Multiple Coefficients</a></li>
<li class="chapter" data-level="7.5" data-path="model-specification-for-multiple-regression.html"><a href="model-specification-for-multiple-regression.html"><i class="fa fa-check"></i><b>7.5</b> Model Specification for Multiple Regression</a><ul>
<li class="chapter" data-level="" data-path="model-specification-for-multiple-regression.html"><a href="model-specification-for-multiple-regression.html#model-specification-in-theory-and-in-practice"><i class="fa fa-check"></i>Model Specification in Theory and in Practice</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="analysis-of-the-test-score-data-set.html"><a href="analysis-of-the-test-score-data-set.html"><i class="fa fa-check"></i><b>7.6</b> Analysis of the Test Score Data Set</a></li>
<li class="chapter" data-level="7.7" data-path="exercises-5.html"><a href="exercises-5.html"><i class="fa fa-check"></i><b>7.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="nrf.html"><a href="nrf.html"><i class="fa fa-check"></i><b>8</b> Nonlinear Regression Functions</a><ul>
<li class="chapter" data-level="8.1" data-path="a-general-strategy-for-modelling-nonlinear-regression-functions.html"><a href="a-general-strategy-for-modelling-nonlinear-regression-functions.html"><i class="fa fa-check"></i><b>8.1</b> A General Strategy for Modelling Nonlinear Regression Functions</a></li>
<li class="chapter" data-level="8.2" data-path="nfoasiv.html"><a href="nfoasiv.html"><i class="fa fa-check"></i><b>8.2</b> Nonlinear Functions of a Single Independent Variable</a><ul>
<li class="chapter" data-level="" data-path="nfoasiv.html"><a href="nfoasiv.html#polynomials"><i class="fa fa-check"></i>Polynomials</a></li>
<li class="chapter" data-level="" data-path="nfoasiv.html"><a href="nfoasiv.html#logarithms"><i class="fa fa-check"></i>Logarithms</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="interactions-between-independent-variables.html"><a href="interactions-between-independent-variables.html"><i class="fa fa-check"></i><b>8.3</b> Interactions Between Independent Variables</a></li>
<li class="chapter" data-level="8.4" data-path="nonlinear-effects-on-test-scores-of-the-student-teacher-ratio.html"><a href="nonlinear-effects-on-test-scores-of-the-student-teacher-ratio.html"><i class="fa fa-check"></i><b>8.4</b> Nonlinear Effects on Test Scores of the Student-Teacher Ratio</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="asbomr.html"><a href="asbomr.html"><i class="fa fa-check"></i><b>9</b> Assessing Studies Based on Multiple Regression</a><ul>
<li class="chapter" data-level="9.1" data-path="internal-and-external-validity.html"><a href="internal-and-external-validity.html"><i class="fa fa-check"></i><b>9.1</b> Internal and External Validity</a></li>
<li class="chapter" data-level="9.2" data-path="threats-to-internal-validity-of-multiple-regression-analysis.html"><a href="threats-to-internal-validity-of-multiple-regression-analysis.html"><i class="fa fa-check"></i><b>9.2</b> Threats to Internal Validity of Multiple Regression Analysis</a></li>
<li class="chapter" data-level="9.3" data-path="internal-and-external-validity-when-the-regression-is-used-for-forecasting.html"><a href="internal-and-external-validity-when-the-regression-is-used-for-forecasting.html"><i class="fa fa-check"></i><b>9.3</b> Internal and External Validity when the Regression is Used for Forecasting</a></li>
<li class="chapter" data-level="9.4" data-path="etsacs.html"><a href="etsacs.html"><i class="fa fa-check"></i><b>9.4</b> Example: Test Scores and Class Size</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="rwpd.html"><a href="rwpd.html"><i class="fa fa-check"></i><b>10</b> Regression with Panel Data</a><ul>
<li class="chapter" data-level="10.1" data-path="panel-data.html"><a href="panel-data.html"><i class="fa fa-check"></i><b>10.1</b> Panel Data</a></li>
<li class="chapter" data-level="10.2" data-path="PDWTTP.html"><a href="PDWTTP.html"><i class="fa fa-check"></i><b>10.2</b> Panel Data with Two Time Periods: “Before and After” Comparisons</a></li>
<li class="chapter" data-level="10.3" data-path="fixed-effects-regression.html"><a href="fixed-effects-regression.html"><i class="fa fa-check"></i><b>10.3</b> Fixed Effects Regression</a><ul>
<li class="chapter" data-level="" data-path="fixed-effects-regression.html"><a href="fixed-effects-regression.html#estimation-and-inference"><i class="fa fa-check"></i>Estimation and Inference</a></li>
<li class="chapter" data-level="" data-path="fixed-effects-regression.html"><a href="fixed-effects-regression.html#application-to-traffic-deaths"><i class="fa fa-check"></i>Application to Traffic Deaths</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="regression-with-time-fixed-effects.html"><a href="regression-with-time-fixed-effects.html"><i class="fa fa-check"></i><b>10.4</b> Regression with Time Fixed Effects</a></li>
<li class="chapter" data-level="10.5" data-path="tferaaseffer.html"><a href="tferaaseffer.html"><i class="fa fa-check"></i><b>10.5</b> The Fixed Effects Regression Assumptions and Standard Errors for Fixed Effects Regression</a></li>
<li class="chapter" data-level="10.6" data-path="drunk-driving-laws-and-traffic-deaths.html"><a href="drunk-driving-laws-and-traffic-deaths.html"><i class="fa fa-check"></i><b>10.6</b> Drunk Driving Laws and Traffic Deaths</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="rwabdv.html"><a href="rwabdv.html"><i class="fa fa-check"></i><b>11</b> Regression with a Binary Dependent Variable</a><ul>
<li class="chapter" data-level="11.1" data-path="binary-dependent-variables-and-the-linear-probability-model.html"><a href="binary-dependent-variables-and-the-linear-probability-model.html"><i class="fa fa-check"></i><b>11.1</b> Binary Dependent Variables and the Linear Probability Model</a></li>
<li class="chapter" data-level="11.2" data-path="probit-and-logit-regression.html"><a href="probit-and-logit-regression.html"><i class="fa fa-check"></i><b>11.2</b> Probit and Logit Regression</a><ul>
<li class="chapter" data-level="" data-path="probit-and-logit-regression.html"><a href="probit-and-logit-regression.html#probit-regression"><i class="fa fa-check"></i>Probit Regression</a></li>
<li class="chapter" data-level="" data-path="probit-and-logit-regression.html"><a href="probit-and-logit-regression.html#logit-regression"><i class="fa fa-check"></i>Logit Regression</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="estimation-and-inference-in-the-logit-and-probit-models.html"><a href="estimation-and-inference-in-the-logit-and-probit-models.html"><i class="fa fa-check"></i><b>11.3</b> Estimation and Inference in the Logit and Probit Models</a></li>
<li class="chapter" data-level="11.4" data-path="application-to-the-boston-hmda-data.html"><a href="application-to-the-boston-hmda-data.html"><i class="fa fa-check"></i><b>11.4</b> Application to the Boston HMDA Data</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="ivr.html"><a href="ivr.html"><i class="fa fa-check"></i><b>12</b> Instrumental Variables Regression</a><ul>
<li class="chapter" data-level="12.1" data-path="TIVEWASRAASI.html"><a href="TIVEWASRAASI.html"><i class="fa fa-check"></i><b>12.1</b> The IV Estimator with a Single Regressor and a Single Instrument</a></li>
<li class="chapter" data-level="12.2" data-path="TGIVRM.html"><a href="TGIVRM.html"><i class="fa fa-check"></i><b>12.2</b> The General IV Regression Model</a></li>
<li class="chapter" data-level="12.3" data-path="civ.html"><a href="civ.html"><i class="fa fa-check"></i><b>12.3</b> Checking Instrument Validity</a></li>
<li class="chapter" data-level="12.4" data-path="attdfc.html"><a href="attdfc.html"><i class="fa fa-check"></i><b>12.4</b> Application to the Demand for Cigarettes</a></li>
<li class="chapter" data-level="12.5" data-path="where-do-valid-instruments-come-from.html"><a href="where-do-valid-instruments-come-from.html"><i class="fa fa-check"></i><b>12.5</b> Where Do Valid Instruments Come From?</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="eaqe.html"><a href="eaqe.html"><i class="fa fa-check"></i><b>13</b> Experiments and Quasi-Experiments</a><ul>
<li class="chapter" data-level="13.1" data-path="potential-outcomes-causal-effects-and-idealized-experiments.html"><a href="potential-outcomes-causal-effects-and-idealized-experiments.html"><i class="fa fa-check"></i><b>13.1</b> Potential Outcomes, Causal Effects and Idealized Experiments</a></li>
<li class="chapter" data-level="13.2" data-path="threats-to-validity-of-experiments.html"><a href="threats-to-validity-of-experiments.html"><i class="fa fa-check"></i><b>13.2</b> Threats to Validity of Experiments</a></li>
<li class="chapter" data-level="13.3" data-path="experimental-estimates-of-the-effect-of-class-size-reductions.html"><a href="experimental-estimates-of-the-effect-of-class-size-reductions.html"><i class="fa fa-check"></i><b>13.3</b> Experimental Estimates of the Effect of Class Size Reductions</a><ul>
<li class="chapter" data-level="" data-path="experimental-estimates-of-the-effect-of-class-size-reductions.html"><a href="experimental-estimates-of-the-effect-of-class-size-reductions.html#experimental-design-and-the-data-set"><i class="fa fa-check"></i>Experimental Design and the Data Set</a></li>
<li class="chapter" data-level="" data-path="experimental-estimates-of-the-effect-of-class-size-reductions.html"><a href="experimental-estimates-of-the-effect-of-class-size-reductions.html#analysis-of-the-star-data"><i class="fa fa-check"></i>Analysis of the STAR Data</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="quasi-experiments.html"><a href="quasi-experiments.html"><i class="fa fa-check"></i><b>13.4</b> Quasi Experiments</a><ul>
<li class="chapter" data-level="" data-path="quasi-experiments.html"><a href="quasi-experiments.html#the-differences-in-differences-estimator"><i class="fa fa-check"></i>The Differences-in-Differences Estimator</a></li>
<li class="chapter" data-level="" data-path="quasi-experiments.html"><a href="quasi-experiments.html#regression-discontinuity-estimators"><i class="fa fa-check"></i>Regression Discontinuity Estimators</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="ittsraf.html"><a href="ittsraf.html"><i class="fa fa-check"></i><b>14</b> Introduction to Time Series Regression and Forecasting</a><ul>
<li class="chapter" data-level="14.1" data-path="using-regression-models-for-forecasting.html"><a href="using-regression-models-for-forecasting.html"><i class="fa fa-check"></i><b>14.1</b> Using Regression Models for Forecasting</a></li>
<li class="chapter" data-level="14.2" data-path="tsdasc.html"><a href="tsdasc.html"><i class="fa fa-check"></i><b>14.2</b> Time Series Data and Serial Correlation</a><ul>
<li class="chapter" data-level="" data-path="tsdasc.html"><a href="tsdasc.html#notation-lags-differences-logarithms-and-growth-rates"><i class="fa fa-check"></i>Notation, Lags, Differences, Logarithms and Growth Rates</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="autoregressions.html"><a href="autoregressions.html"><i class="fa fa-check"></i><b>14.3</b> Autoregressions</a><ul>
<li><a href="autoregressions.html#autoregressive-models-of-order-p">Autoregressive Models of Order <span class="math inline">\(p\)</span></a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="cybtmpi.html"><a href="cybtmpi.html"><i class="fa fa-check"></i><b>14.4</b> Can You Beat the Market? (Part I)</a></li>
<li class="chapter" data-level="14.5" data-path="apatadlm.html"><a href="apatadlm.html"><i class="fa fa-check"></i><b>14.5</b> Additional Predictors and The ADL Model</a><ul>
<li class="chapter" data-level="" data-path="apatadlm.html"><a href="apatadlm.html#forecast-uncertainty-and-forecast-intervals"><i class="fa fa-check"></i>Forecast Uncertainty and Forecast Intervals</a></li>
</ul></li>
<li class="chapter" data-level="14.6" data-path="llsuic.html"><a href="llsuic.html"><i class="fa fa-check"></i><b>14.6</b> Lag Length Selection Using Information Criteria</a></li>
<li class="chapter" data-level="14.7" data-path="nit.html"><a href="nit.html"><i class="fa fa-check"></i><b>14.7</b> Nonstationarity I: Trends</a></li>
<li class="chapter" data-level="14.8" data-path="niib.html"><a href="niib.html"><i class="fa fa-check"></i><b>14.8</b> Nonstationarity II: Breaks</a></li>
<li class="chapter" data-level="14.9" data-path="can-you-beat-the-market-part-ii.html"><a href="can-you-beat-the-market-part-ii.html"><i class="fa fa-check"></i><b>14.9</b> Can You Beat the Market? (Part II)</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="eodce.html"><a href="eodce.html"><i class="fa fa-check"></i><b>15</b> Estimation of Dynamic Causal Effects</a><ul>
<li class="chapter" data-level="15.1" data-path="the-orange-juice-data.html"><a href="the-orange-juice-data.html"><i class="fa fa-check"></i><b>15.1</b> The Orange Juice Data</a></li>
<li class="chapter" data-level="15.2" data-path="dynamic-causal-effects.html"><a href="dynamic-causal-effects.html"><i class="fa fa-check"></i><b>15.2</b> Dynamic Causal Effects</a></li>
<li class="chapter" data-level="15.3" data-path="dynamic-multipliers-and-cumulative-dynamic-multipliers.html"><a href="dynamic-multipliers-and-cumulative-dynamic-multipliers.html"><i class="fa fa-check"></i><b>15.3</b> Dynamic Multipliers and Cumulative Dynamic Multipliers</a></li>
<li class="chapter" data-level="15.4" data-path="hac-standard-errors.html"><a href="hac-standard-errors.html"><i class="fa fa-check"></i><b>15.4</b> HAC Standard Errors</a></li>
<li class="chapter" data-level="15.5" data-path="estimation-of-dynamic-causal-effects-with-strictly-exogeneous-regressors.html"><a href="estimation-of-dynamic-causal-effects-with-strictly-exogeneous-regressors.html"><i class="fa fa-check"></i><b>15.5</b> Estimation of Dynamic Causal Effects with Strictly Exogeneous Regressors</a></li>
<li class="chapter" data-level="15.6" data-path="orange-juice-prices-and-cold-weather.html"><a href="orange-juice-prices-and-cold-weather.html"><i class="fa fa-check"></i><b>15.6</b> Orange Juice Prices and Cold Weather</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="atitsr.html"><a href="atitsr.html"><i class="fa fa-check"></i><b>16</b> Additional Topics in Time Series Regression</a><ul>
<li class="chapter" data-level="16.1" data-path="vector-autoregressions.html"><a href="vector-autoregressions.html"><i class="fa fa-check"></i><b>16.1</b> Vector Autoregressions</a></li>
<li class="chapter" data-level="16.2" data-path="ooiatdfglsurt.html"><a href="ooiatdfglsurt.html"><i class="fa fa-check"></i><b>16.2</b> Orders of Integration and the DF-GLS Unit Root Test</a></li>
<li class="chapter" data-level="16.3" data-path="cointegration.html"><a href="cointegration.html"><i class="fa fa-check"></i><b>16.3</b> Cointegration</a></li>
<li class="chapter" data-level="16.4" data-path="volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html"><a href="volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html"><i class="fa fa-check"></i><b>16.4</b> Volatility Clustering and Autoregressive Conditional Heteroskedasticity</a><ul>
<li class="chapter" data-level="" data-path="volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html"><a href="volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html#arch-and-garch-models"><i class="fa fa-check"></i>ARCH and GARCH Models</a></li>
<li class="chapter" data-level="" data-path="volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html"><a href="volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html#application-to-stock-price-volatility"><i class="fa fa-check"></i>Application to Stock Price Volatility</a></li>
<li class="chapter" data-level="" data-path="volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html"><a href="volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html#summary-8"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Using <tt>R</tt> for Introduction to Econometrics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div class = rmdreview>
This book is in <b>Open Review</b>. We want your feedback to make the book better for you and other students. You may annotate some text by <span style="background-color: #3297FD; color: white">selecting it with the cursor</span> and then click the <i class="h-icon-annotate"></i> on the pop-up menu. You can also see the annotations of others: click the <i class="h-icon-chevron-left"></i> in the upper right hand corner of the page <i class="fa fa-arrow-circle-right  fa-rotate-315" aria-hidden="true"></i>
</div>
<div id="exercises-1" class="section level2">
<h2><span class="header-section-number">3.8</span> Exercises</h2>
<div class="DCexercise">
<h4 id="biased" class="unnumbered">1. Biased …</h4>
<p>Consider the following alternative estimator</p>
<p><span class="math display">\[\widetilde{Y}=\frac{1}{n-1}\sum\limits_{i=1}^n Y_i\]</span></p>
<p>In this exercise we want to illustrate that this estimator is biased.</p>
<p><strong>Instructions:</strong></p>
<ul>
<li><p>Define a function for the estimator by yourself and name it <tt>Y_tilde</tt>.</p></li>
<li><p>Randomly draw 5 observations from the <span class="math inline">\(\mathcal{N}(10, 25)\)</span> distribution and compute an estimate with <tt>Y_tilde()</tt>. Repeat this procedure 10000 times and store the results in <tt>est_biased</tt>.</p></li>
<li><p>Plot a histogram of <tt>est_biased</tt>.</p></li>
<li><p>Add a red vertical line at <span class="math inline">\(\mu=10\)</span> using the function <tt>abline()</tt>.</p></li>
</ul>


<div data-datacamp-exercise data-lang="r">

  <code data-type="sample-code">
  # Define a function for the estimator
  
  
  # Compute repeatedly estimates and store the results in est_biased
  set.seed(123)
  
  
  # Plot a histogram of est_biased
  
  
  # Add a red vertical line at mu = 10
  
   
  </code>
  <code data-type="solution">
  # Define a function for the estimator
  Y_tilde <- function(x){sum(x)/(length(x)-1)}
  
  # Compute repeatedly estimates and store the results in est_biased
  set.seed(123)
  est_biased <- replicate(n = 10000, expr = Y_tilde(rnorm(5, 10, 5)))
  
  # Plot a histogram of est_biased
  hist(est_biased)
  
  # Add a red vertical line at mu = 10
  abline(v = 10, col = "red")
  
  </code>
  <code data-type="sct">
  test_function_definition("Y_tilde", function_test = {
                           test_expression_result("Y_tilde(1:10)")
                           test_expression_result("Y_tilde(1:25)")
                           test_expression_result("Y_tilde(seq(0, 1, 0.1))")
                         })
  test_object("est_biased")
  test_function("hist", args = "x")
  test_function("abline", args = c("v", "col"))
  </code>

</div>


<p><strong>Hints:</strong></p>
<ul>
<li><p>To compute the sum of a vector you can use <tt>sum()</tt>, to get the length of a vector you can use <tt>length()</tt>.</p></li>
<li><p>Use the function <tt>replicate()</tt> to compute repeatedly estimates of random samples. With the arguments <tt>expr</tt> and <tt>n</tt> you can specify the operation and how often it has to be replicated.</p></li>
<li><p>A histogram can be plotted with the function <tt>hist()</tt>.</p></li>
<li><p>The point on the x-axis as well as the color for the vertical line can be specified via the arguments <tt>v</tt> and <tt>col</tt>.</p></li>
</ul>
</div>
<div class="DCexercise">
<h4 id="but-consistent-estimator" class="unnumbered">2. … but consistent estimator</h4>
<p>Consider again the estimator from the previous exercise which is available in your environment as <tt>Y_tilde()</tt>. Do the same procedure as in the previous exercise but now increase the number of observations to draw from 5 to 1000. What do you note? What can you say about this estimator?</p>
<p><strong>Instructions:</strong></p>
<ul>
<li><p>Randomly draw 1000 observations from the <span class="math inline">\(\mathcal{N}(10, 25)\)</span> distribution and compute an estimate with <tt>Y_tilde()</tt>. Repeat this procedure 10000 times and store the results in <tt>est_consistent</tt>.</p></li>
<li><p>Plot a histogram of <tt>est_consistent</tt>.</p></li>
<li><p>Add a red vertical line at <span class="math inline">\(\mu=10\)</span> using the function <tt>abline()</tt>.</p></li>
</ul>


<div data-datacamp-exercise data-lang="r">

  <code data-type="pre-exercise-code">
    Y_tilde <- function(x){sum(x)/(length(x)-1)}
	</code>
  
  <code data-type="sample-code">
  # Compute repeatedly estimates and store the results in est_consistent
  set.seed(123)
  
  
  # Plot a histogram of est_biased
  
  
  # Add a red vertical line at mu = 10
  
  
  </code>
  <code data-type="solution">
  # Compute repeatedly estimates and store the results in est_consistent
  set.seed(123)
  est_consistent <- replicate(n = 10000, expr = Y_tilde(rnorm(1000, 10, 5)))
  
  # Plot a histogram of est_consistent
  hist(est_consistent)
  
  # Add a red vertical line at mu = 10
  abline(v = 10, col = "red")
  
  </code>
  <code data-type="sct">
  test_object("est_consistent")
  test_function("hist", args = "x")
  test_function("abline", args = c("v", "col"))
  </code>

</div>


<p><strong>Hints:</strong></p>
<ul>
<li><p>Use the function <tt>replicate()</tt> to compute repeatedly estimates of random samples. With the arguments <tt>expr</tt> and <tt>n</tt> you can specify the operation and how often it has to be replicated.</p></li>
<li><p>A histogram can be plotted with the function <tt>hist()</tt>.</p></li>
<li><p>The point on the x-axis as well as the color for the vertical line can be specified via the arguments <tt>v</tt> and <tt>col</tt>.</p></li>
</ul>
</div>
<div class="DCexercise">
<h4 id="efficiency-of-an-estimator" class="unnumbered">3. Efficiency of an estimator</h4>
<p>In this exercise we want to illustrate the result that the sample mean</p>
<p><span class="math display">\[\hat{\mu}_Y=\sum\limits_{i=1}^{n}a_iY_i\]</span> with the equal weighting scheme <span class="math inline">\(a_i=\frac{1}{n}\)</span> for <span class="math inline">\(i=1,...,n\)</span> is the best linear unbiased estimator (BLUE) of <span class="math inline">\(\mu_Y\)</span>.</p>
<p>As an alternative consider the estimator</p>
<p><span class="math display">\[\tilde{\mu}_Y=\sum\limits_{i=1}^{n}b_iY_i\]</span></p>
<p>where <span class="math inline">\(b_i\)</span> gives the first <span class="math inline">\(\frac{n}{2}\)</span> observations a higher weighting than the second <span class="math inline">\(\frac{n}{2}\)</span> observations.</p>
<p>The respective weighting vector is already defined and available as <tt>w</tt> in your working environment.</p>
<p><strong>Instructions:</strong></p>
<ul>
<li><p>Verify that <span class="math inline">\(\tilde{\mu}\)</span> is unbiased.</p></li>
<li><p>Define the alternative estimator as a function <tt>mu_tilde()</tt>.</p></li>
<li><p>Randomly draw 100 observations from the <span class="math inline">\(\mathcal{N}(5, 10)\)</span> distribution and compute an estimate with both estimators. Repeat this procedure 10000 times and store the results in <tt>est_bar</tt> and <tt>est_tilde</tt>.</p></li>
<li><p>Compute the sample variances of <tt>est_bar</tt> and <tt>est_tilde</tt>. What can you say about both estimators?</p></li>
</ul>


<div data-datacamp-exercise data-lang="r">
  
  <code data-type="sample-code">
  # Verify that the alternative estimator is unbiased
  n <- 100
  w <- c(rep((1+0.5)/n, n/2), rep((1-0.5)/n, n/2))
  
  
  # Define the alternative estimator mu_tilde
  
  
  # Compute repeatedly estimates for both estimators and store the results in est_bar and est_tilde
  set.seed(123)
  
  
  
  # Compute the sample variances for est_bar and est_tilde
  
  
  
  </code>
  <code data-type="solution">
  # Verify that the alternative estimator is unbiased
  n <- 100
  w <- c(rep((1+0.5)/n, n/2), rep((1-0.5)/n, n/2))
  sum(w)
  
  # Define the alternative estimator mu_tilde
  mu_tilde <- function(x){sum(w*x)}
  
  # Compute repeatedly estimates for both estimators and store the results in est_bar and est_tilde
  set.seed(123)
  est_bar <- replicate(expr = mean(rnorm(100, 5, 10)), n = 10000)
  est_tilde <- replicate(expr = mu_tilde(rnorm(100, 5, 10)), n = 10000)
  
  # Compute the sample variances for est_bar and est_tilde
  var(est_bar)
  var(est_tilde)
  
  </code>
  <code data-type="sct">
  test_function_result("sum")
  test_function_definition("mu_tilde",
                           function_test = {
                             test_expression_result("mu_tilde(1:100)")
                             test_expression_result("mu_tilde(2:101)")
                           })
  test_object("est_bar")
  test_object("est_tilde")
  test_function_result("var", index = 1)
  test_function_result("var", index = 2)
  success_msg("Correct! The sample mean is more efficient (that is, has a lower variance) than the alternative estimator.")
  </code>

</div>


<p><strong>Hints:</strong></p>
<ul>
<li><p>In order for <span class="math inline">\(\tilde{\mu}\)</span> to be an unbiased estimator all weights have to sum up to 1.</p></li>
<li><p>Use the function <tt>replicate()</tt> to compute repeatedly estimates of random samples. With the arguments <tt>expr</tt> and <tt>n</tt> you can specify the operation and how often it has to be replicated.</p></li>
<li><p>To compute sample variances you can use <tt>var()</tt>.</p></li>
</ul>
</div>
<div class="DCexercise">
<h4 id="hypothesis-test-t-statistic" class="unnumbered">4. Hypothesis Test — <span class="math inline">\(t\)</span> Statistic</h4>
<p>Consider the CPS data set from Chapter <a href="aattggoe.html#aattggoe">3.6</a> again which is available as <tt>cps</tt> in your working environment.</p>
<p>We suppose that the average hourly earnings (in prices of 2012) <tt>ahe12</tt> exceed 23.50 <span class="math inline">\(\frac{\$}{h}\)</span> and wish to test this hypothesis at a significance level of <span class="math inline">\(\alpha=0.05\)</span>. For that reason please do the following:</p>
<p><strong>Instructions:</strong></p>
<ul>
<li><p>Compute the test statistic by hand and assign it to <tt>tstat</tt>.</p></li>
<li><p>Use <tt>tstat</tt> to accept or reject the null hypothesis. Please do so using the normal approximation.</p></li>
</ul>


<div data-datacamp-exercise data-lang="r">

  <code data-type="pre-exercise-code">
    cps <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_1276/datasets/cps_ch3.csv", header = T, sep = ";")
	</code>
  
  <code data-type="sample-code">
  # Compute the t statistic by hand and assign it to tstat
   
  
  # Use tstat to accept or reject the null
  
  
  </code>
  <code data-type="solution">
  # Compute the t statistic by hand and assign it to tstat
  tstat <- (mean(cps$ahe12)-23.5)/(sd(cps$ahe12)/sqrt(length(cps$ahe12)))
  
  # Use tstat to accept or reject the null
  tstat > qnorm(0.95)
  
  </code>
  <code data-type="sct">
  test_object("tstat")
  test_function_result("qnorm")
  test_student_typed("tstat", times = 2)
  test_or(test_output_contains("T"), test_output_contains("F"))
  </code>

</div>


<p><strong>Hints:</strong></p>
<ul>
<li><p>We test <span class="math inline">\(H_0:\mu_{Y_{ahe}}\leq 23.5\)</span> vs. <span class="math inline">\(H_1:\mu_{Y_{ahe}}&gt;23.5\)</span>. That is, we conduct a right-sided test.</p></li>
<li><p>The t statistic is defined as <span class="math inline">\(\frac{\bar{Y}-\mu_{Y,0}}{s_{Y}/\sqrt{n}}\)</span> where <span class="math inline">\(s_Y\)</span> denotes the sample variance.</p></li>
<li><p>To decide whether the null hypothesis is accepted or rejected you can compare the <span class="math inline">\(t\)</span>-statistic with the respective quantile of the standard normal distribution. Use logical operators to check for this.</p></li>
</ul>
</div>
<div class="DCexercise">
<h4 id="hypothesis-test-p-value" class="unnumbered">5. Hypothesis Test — <span class="math inline">\(p\)</span>-value</h4>
<p>Reconsider the test situation from previous exercise. <tt>cps</tt> as well as <tt>tstat</tt> are available in your working environment.</p>
<p>Instead of using the <span class="math inline">\(t\)</span>-statistic as decision criterion we can also use the respective <span class="math inline">\(p\)</span>-value. Now please do the following:</p>
<p><strong>Instructions:</strong></p>
<ul>
<li><p>Compute the <span class="math inline">\(p\)</span>-value by hand and assign it to <tt>pval</tt>.</p></li>
<li><p>Use <tt>pval</tt> to accept or reject the null hypothesis.</p></li>
</ul>


<div data-datacamp-exercise data-lang="r">

  <code data-type="pre-exercise-code">
  cps <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_1276/datasets/cps_ch3.csv", header = T, sep = ";")
  tstat <- (mean(cps$ahe12)-23.5)/(sd(cps$ahe12)/sqrt(length(cps$ahe12)))
	</code>
  
  <code data-type="sample-code">
  # Compute the p-value by hand and assign it to pval
  
  
  # Use pval to accept or reject the null
  
  
  </code>
  <code data-type="solution">
  # Compute the p-value by hand and assign it to pval
  pval <- 1-pnorm(tstat)
  
  # Use pval to accept or reject the null
  pval < 0.05
  
  </code>
  <code data-type="sct">
  test_object("pval")
  test_student_typed("pval", times = 2)
  test_or(test_output_contains("T"), test_output_contains("F"))
  </code>

</div>


<p><strong>Hints:</strong></p>
<ul>
<li><p>The <span class="math inline">\(p\)</span>-value for a right-sided test can be computed as <span class="math inline">\(p=P(t&gt;t^{act}|H_0)\)</span>.</p></li>
<li><p>We reject the null if <span class="math inline">\(p&lt;\alpha\)</span>. Use logical operators to check for this.</p></li>
</ul>
</div>
<div class="DCexercise">
<h4 id="hypothesis-test-one-sample-t-test" class="unnumbered">6. Hypothesis Test — One Sample <span class="math inline">\(t\)</span>-test</h4>
<p>In the last two exercises we discovered two ways of conducting a hypothesis test. In practice these approaches seem very cumbersome and so <tt>R</tt>provides the function <tt>t.test()</tt> which does most of the work automatically for us. In fact it provides <span class="math inline">\(t\)</span>-statistics, <span class="math inline">\(p\)</span>-values and even confidence intervals (more on the latter in later exercises). In addition it also uses the <span class="math inline">\(t\)</span>-distribution instead of the normal distribution which becomes important especially for small sample sizes.</p>
<p>The data set <tt>cps</tt> as well as the variable <tt>pval</tt> from Exercise 3.4 are available in your working environment.</p>
<p><strong>Instructions:</strong></p>
<ul>
<li><p>Conduct the hypothesis test from previous exercises with the function <tt>t.test()</tt>.</p></li>
<li><p>Extract the <span class="math inline">\(t\)</span>-statistic and the <span class="math inline">\(p\)</span>-value from the list created by <tt>t.test()</tt>. Assign them to the variables <tt>tstat</tt> and <tt>pvalue</tt>.</p></li>
<li><p>Verify that using the normal approximation here is valid as well by computing the difference between both <span class="math inline">\(p\)</span>-values.</p></li>
</ul>


<div data-datacamp-exercise data-lang="r">

  <code data-type="pre-exercise-code">
  cps <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_1276/datasets/cps_ch3.csv", header = T, sep =   ";")
  tstat <- (mean(cps$ahe12)-23.5)/(sd(cps$ahe12)/sqrt(length(cps$ahe12)))
  pval <- 1-pnorm(tstat)
	</code>
  
  <code data-type="sample-code">
  # Conduct the hypothesis test from previous exercises with t.test()
  
  
  # Extract t statistic and p-value from list created by t.test()
  
  
  
  # Verify that using the normal approximation here is valid as well
  
  
  </code>
  <code data-type="solution">
  # Conduct the hypothesis test from previous exercises with t.test()
  t.test(cps$ahe12, alternative = "greater", mu = 23.5)
  
  # Extract t statistic and p-value from list created by t.test()
  tstat <- t.test(cps$ahe12, alternative = "greater", mu = 23.5)$statistic
  pvalue <- t.test(cps$ahe12, alternative = "greater", mu = 23.5)$p.value
  
  # Verify that using the normal approximation here is valid as well
  pvalue - pval
  
  </code>
  <code data-type="sct">
  test_function_result("t.test")
  test_object("tstat")
  test_object("pvalue")
  test_or(test_student_typed("pvalue - pval"), test_student_typed("pval - pvalue"))
  </code>

</div>


<p><strong>Hints:</strong></p>
<ul>
<li><p>The type of the test as well as the null hypothesis can be specified via the arguments <tt>alternative</tt> and <tt>mu</tt>.</p></li>
<li><p>The <span class="math inline">\(t\)</span>-statistic and the <span class="math inline">\(p\)</span>-value can be obtained via <tt>$statistic</tt> and <tt>$p.value</tt>, respectively.</p></li>
</ul>
</div>
<div class="DCexercise">
<h4 id="hypothesis-test-two-sample-t-test" class="unnumbered">7. Hypothesis Test — Two Sample <span class="math inline">\(t\)</span>-test</h4>
<p>Consider the annual maximum sea levels at Port Pirie (Southern Australia) and Fremantle (Western Australia) for the last 30 years.</p>
<p>The observations are available in the variables <tt>portpirie</tt> and <tt>fremantle</tt> in your working environment.</p>
<p><strong>Instructions:</strong></p>
<ul>
<li>Test whether there is a significant difference in the annual maximum sea levels at a significance level of <span class="math inline">\(\alpha=0.05\)</span>.</li>
</ul>


<div data-datacamp-exercise data-lang="r">

  <code data-type="pre-exercise-code">
  set.seed(123)
  portpirie <- runif(30, 3.6, 4.6)
  fremantle <- runif(30, 1.2, 1.8)
	</code>
  
  <code data-type="sample-code">
  # Conduct a two sample t-test
  
  
  </code>
  <code data-type="solution">
  # Conduct a two sample t-test
  t.test(portpirie, fremantle)
  
  </code>
  <code data-type="sct">
  test_or(test_output_contains("t.test(portpirie, fremantle)"), test_output_contains("t.test(fremantle, portpirie)"))
  </code>

</div>


<p><strong>Hints:</strong></p>
<ul>
<li><p>We test <span class="math inline">\(H_0:\mu_{P}-\mu_{F}=0\)</span> vs. <span class="math inline">\(H_1:\mu_{P}-\mu_{F}\ne 0\)</span>. That is, we conduct a two sample <span class="math inline">\(t\)</span>-test.</p></li>
<li><p>For a two sample <span class="math inline">\(t\)</span>-test the function <tt>t.test()</tt> expects two vectors containing the data.</p></li>
</ul>
</div>
<div class="DCexercise">
<h4 id="confidence-interval" class="unnumbered">8. Confidence Interval</h4>
<p>Reconsider the test situation concerning the annual maximum sea levels at Port Pirie and Fremantle.</p>
<p>The variables <tt>portpirie</tt> and <tt>fremantle</tt> are again available in your working environment.</p>
<p><strong>Instructions:</strong></p>
<ul>
<li>Construct a <span class="math inline">\(95\%\)</span>-confidence interval for the difference in the sea levels using <tt>t.test()</tt>.</li>
</ul>


<div data-datacamp-exercise data-lang="r">

  <code data-type="pre-exercise-code">
  set.seed(123)
  portpirie <- runif(30, 3.6, 4.6)
  fremantle <- runif(30, 1.2, 1.8)
	</code>
  
  <code data-type="sample-code">
  # Construct a 95%-confidence interval using t.test()
  
  
  </code>
  <code data-type="solution">
  # Construct a 95%-confidence interval using t.test()
  t.test(portpirie, fremantle)$conf.int
  
  </code>
  <code data-type="sct">
  test_or(test_output_contains("t.test(portpirie, fremantle)$conf.int"), test_output_contains("t.test(fremantle,             portpirie)$conf.int"))
  </code>

</div>


<p><strong>Hint:</strong></p>
<ul>
<li>The function <tt>t.test()</tt> computes by default a confidence interval which is accessible via <tt>$conf.int</tt>.</li>
</ul>
</div>
<div class="DCexercise">
<h4 id="covariance-and-correlation-i"><span class="header-section-number">3.8</span> 9. (Co)variance and Correlation I</h4>
<p>Consider a random sample <span class="math inline">\((X_i, Y_i)\)</span> for <span class="math inline">\(i=1,...,100\)</span>.</p>
<p>The respective vectors <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are already available in your working environment as <tt>X</tt> and <tt>Y</tt>.</p>
<p><strong>Instructions:</strong></p>
<ul>
<li><p>Compute the variance of <span class="math inline">\(X\)</span> using the function <tt>cov()</tt>.</p></li>
<li><p>Compute the covariance of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.</p></li>
<li><p>Compute the correlation between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.</p></li>
</ul>


<div data-datacamp-exercise data-lang="r">

  <code data-type="pre-exercise-code">
  custom_seed(123)
  X <- runif(100, 900, 1000)
  Y <- 3*X+rnorm(100, 0, 100)
	</code>
  
  <code data-type="sample-code">
  # Compute the variance of X
  
  
  # Compute the covariance of X and Y
  
  
  # Compute the correlation between X and Y
  
  
  </code>
  <code data-type="solution">
  # Compute the variance of X with cov()
  cov(X, X)
  
  # Compute the covariance of X and Y
  cov(X, Y)
    
  # Compute the correlation between X and Y
  cor(X, Y)
  
  </code>
  <code data-type="sct">
  test_function_result("cov", index = 1)
  test_function_result("cov", index = 2)
  test_function_result("cor")
  </code>

</div>


<p><strong>Hints:</strong></p>
<ul>
<li><p>The variance is just a special case of the covariance.</p></li>
<li><p><tt>cov()</tt> as well as <tt>cor()</tt> expect a vector for each variable.</p></li>
</ul>
</div>
<div class="DCexercise">
<h4 id="covariance-and-correlation-ii"><span class="header-section-number">3.8</span> 10. (Co)variance and Correlation II</h4>
<p>In this exercise we want to examine the limitations of the correlation as a dependency measure.</p>
<p>Once the session has initialized you will see the plot of 100 realizations from two random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.</p>
<p>The respective observations are available in the vectors <tt>X</tt> and <tt>Y</tt> in your working environment.</p>
<p><strong>Instructions:</strong></p>
<ul>
<li>Compute the correlation between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. Interpret your result critically.</li>
</ul>


<div data-datacamp-exercise data-lang="r">

  <code data-type="pre-exercise-code">
  custom_seed(123)
  X <- runif(100, 0, 3)
  Y <- exp(-X) + rnorm(100, 0, .05)
  plot(Y ~ X)
	</code>
  
  <code data-type="sample-code">
  # Compute the correlation between X and Y
  
  
  </code>
  <code data-type="solution">
  # Compute the correlation between x and y
  cor(X, Y)
  # The correlation is only able to quantify linear relationships which is not the case here.
  </code>
  <code data-type="sct">
  test_function_result("cor")
  success_msg("Correct! The correlation is able to capture the negative relationship between both variables. However it only measures linear dependencies, whereas the dependency here is clearly nonlinear (exponential).")
  </code>

</div>


<p><strong>Hint:</strong></p>
<ul>
<li><tt>cor()</tt> expects a vector for each variable.</li>
</ul>
</div>

</div>
<!-- </div> -->
            </section>

          </div>
        </div>
      </div>
<a href="scatterplots-sample-covariance-and-sample-correlation.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="lrwor.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 1
},
"edit": null,
"download": null,
"toc": {
"collapse": "subsection",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
