<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Using R for Introduction to Econometrics</title>
  <meta name="description" content="Using <tt>R</tt> for Introduction to Econometrics">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Using R for Introduction to Econometrics" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="Emwikts1970/URFITE-Bookdown" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Using R for Introduction to Econometrics" />
  
  
  

<meta name="author" content="Christoph Hanck, Martin Arnold, Alexander Gerber and Martin Schmelzer">


<meta name="date" content="2018-04-17">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="using-the-t-statistic-in-regression-when-the-sample-size-is-small.html">
<link rel="next" href="regression-models-with-multiple-regressors.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="js/hideOutput.js"></script>
<script type="text/javascript" src="MathJax-2.7.2/MathJax.js?config=default"></script>

 <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        extensions: ["tex2jax.js", "TeX/AMSmath.js"],
        tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
        jax: ["input/TeX","output/CommonHTML"]
      });
      MathJax.Hub.processSectionDelay = 0;
  </script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110299877-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110299877-1');
</script>

<!-- open review block -->

<script async defer src="https://hypothes.is/embed.js"></script>

<!-- datacamp-light-latest -->

<script src="https://cdn.datacamp.com/datacamp-light-latest.min.js"></script>


<!-- <script src="js/d3.v3.min.js"></script>
<script src="js/leastsquares.js"></script>
<script src="js/d3functions.js"></script>
<script src="d3.slider.js"></script>
<script src="slrm.js"></script> -->


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; background-color: #f8f8f8; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
pre, code { background-color: #f8f8f8; }
code > span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code > span.dt { color: #204a87; } /* DataType */
code > span.dv { color: #0000cf; } /* DecVal */
code > span.bn { color: #0000cf; } /* BaseN */
code > span.fl { color: #0000cf; } /* Float */
code > span.ch { color: #4e9a06; } /* Char */
code > span.st { color: #4e9a06; } /* String */
code > span.co { color: #8f5902; font-style: italic; } /* Comment */
code > span.ot { color: #8f5902; } /* Other */
code > span.al { color: #ef2929; } /* Alert */
code > span.fu { color: #000000; } /* Function */
code > span.er { color: #a40000; font-weight: bold; } /* Error */
code > span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #000000; } /* Constant */
code > span.sc { color: #000000; } /* SpecialChar */
code > span.vs { color: #4e9a06; } /* VerbatimString */
code > span.ss { color: #4e9a06; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #000000; } /* Variable */
code > span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code > span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code > span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code > span.ex { } /* Extension */
code > span.at { color: #c4a000; } /* Attribute */
code > span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code > span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="toc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">URFITE</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="probability-theory.html"><a href="probability-theory.html"><i class="fa fa-check"></i><b>2</b> Probability Theory</a><ul>
<li class="chapter" data-level="2.1" data-path="random-variables-and-probability-distributions.html"><a href="random-variables-and-probability-distributions.html"><i class="fa fa-check"></i><b>2.1</b> Random Variables and Probability Distributions</a><ul>
<li class="chapter" data-level="" data-path="random-variables-and-probability-distributions.html"><a href="random-variables-and-probability-distributions.html#probability-distributions-of-discrete-random-variables"><i class="fa fa-check"></i>Probability Distributions of Discrete Random Variables</a></li>
<li class="chapter" data-level="" data-path="random-variables-and-probability-distributions.html"><a href="random-variables-and-probability-distributions.html#bernoulli-trials"><i class="fa fa-check"></i>Bernoulli Trials</a></li>
<li class="chapter" data-level="" data-path="random-variables-and-probability-distributions.html"><a href="random-variables-and-probability-distributions.html#expected-values-mean-and-variance"><i class="fa fa-check"></i>Expected Values, Mean and Variance</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="probability-distributions-of-continuous-random-variables.html"><a href="probability-distributions-of-continuous-random-variables.html"><i class="fa fa-check"></i><b>2.2</b> Probability Distributions of Continuous Random Variables</a><ul>
<li class="chapter" data-level="" data-path="probability-distributions-of-continuous-random-variables.html"><a href="probability-distributions-of-continuous-random-variables.html#the-normal-distribution"><i class="fa fa-check"></i>The Normal Distribution</a></li>
<li class="chapter" data-level="" data-path="probability-distributions-of-continuous-random-variables.html"><a href="probability-distributions-of-continuous-random-variables.html#the-chi-squared-distribution"><i class="fa fa-check"></i>The Chi-Squared Distribution</a></li>
<li><a href="probability-distributions-of-continuous-random-variables.html#thetdist">The Student <span class="math inline">\(t\)</span> Distribution</a></li>
<li><a href="probability-distributions-of-continuous-random-variables.html#the-f-distribution">The <span class="math inline">\(F\)</span> Distribution</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="random-sampling-and-the-distribution-of-sample-averages.html"><a href="random-sampling-and-the-distribution-of-sample-averages.html"><i class="fa fa-check"></i><b>2.3</b> Random Sampling and the Distribution of Sample Averages</a><ul>
<li class="chapter" data-level="" data-path="random-sampling-and-the-distribution-of-sample-averages.html"><a href="random-sampling-and-the-distribution-of-sample-averages.html#mean-and-variance-of-the-sample-mean"><i class="fa fa-check"></i>Mean and Variance of the Sample Mean</a></li>
<li class="chapter" data-level="" data-path="random-sampling-and-the-distribution-of-sample-averages.html"><a href="random-sampling-and-the-distribution-of-sample-averages.html#large-sample-approximations-to-sampling-distributions"><i class="fa fa-check"></i>Large Sample Approximations to Sampling Distributions</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>2.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="a-review-of-statistics-using-r.html"><a href="a-review-of-statistics-using-r.html"><i class="fa fa-check"></i><b>3</b> A Review of Statistics using R</a><ul>
<li class="chapter" data-level="3.1" data-path="estimation-of-the-population-mean.html"><a href="estimation-of-the-population-mean.html"><i class="fa fa-check"></i><b>3.1</b> Estimation of the Population Mean</a></li>
<li class="chapter" data-level="3.2" data-path="properties-of-the-sample-mean.html"><a href="properties-of-the-sample-mean.html"><i class="fa fa-check"></i><b>3.2</b> Properties of the Sample Mean</a></li>
<li class="chapter" data-level="3.3" data-path="hypothesis-tests-concerning-the-population-mean.html"><a href="hypothesis-tests-concerning-the-population-mean.html"><i class="fa fa-check"></i><b>3.3</b> Hypothesis Tests Concerning the Population Mean</a><ul>
<li><a href="hypothesis-tests-concerning-the-population-mean.html#p-value"><span class="math inline">\(p\)</span>-Value</a></li>
<li><a href="hypothesis-tests-concerning-the-population-mean.html#calculating-the-p-value-when-sigma_y-is-known">Calculating the <span class="math inline">\(p\)</span>-Value When <span class="math inline">\(\sigma_Y\)</span> Is Known</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="shade-p-value2-region-in-right-tail.html"><a href="shade-p-value2-region-in-right-tail.html"><i class="fa fa-check"></i><b>3.4</b> shade p-value/2 region in right tail</a><ul>
<li class="chapter" data-level="" data-path="shade-p-value2-region-in-right-tail.html"><a href="shade-p-value2-region-in-right-tail.html#sample-variance-sample-standard-deviation-and-standard-error"><i class="fa fa-check"></i>Sample Variance, Sample Standard Deviation and Standard Error</a></li>
<li><a href="shade-p-value2-region-in-right-tail.html#calculating-the-p-value-when-sigma_y-is-unknown">Calculating the <span class="math inline">\(p\)</span>-value When <span class="math inline">\(\sigma_Y\)</span> is Unknown</a></li>
<li><a href="shade-p-value2-region-in-right-tail.html#the-t-statistic">The <span class="math inline">\(t\)</span>-statistic</a></li>
<li class="chapter" data-level="" data-path="shade-p-value2-region-in-right-tail.html"><a href="shade-p-value2-region-in-right-tail.html#hypothesis-testing-with-a-prespecified-significance-level"><i class="fa fa-check"></i>Hypothesis Testing with a Prespecified Significance Level</a></li>
<li class="chapter" data-level="" data-path="shade-p-value2-region-in-right-tail.html"><a href="shade-p-value2-region-in-right-tail.html#one-sided-alternatives"><i class="fa fa-check"></i>One-sided Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="confidence-intervals-for-the-population-mean.html"><a href="confidence-intervals-for-the-population-mean.html"><i class="fa fa-check"></i><b>3.5</b> Confidence intervals for the Population Mean</a></li>
<li class="chapter" data-level="3.6" data-path="comparing-means-from-different-populations.html"><a href="comparing-means-from-different-populations.html"><i class="fa fa-check"></i><b>3.6</b> Comparing Means from Different Populations</a></li>
<li class="chapter" data-level="3.7" data-path="an-application-to-the-gender-gap-of-earnings.html"><a href="an-application-to-the-gender-gap-of-earnings.html"><i class="fa fa-check"></i><b>3.7</b> An Application to the Gender Gap of Earnings</a></li>
<li class="chapter" data-level="3.8" data-path="scatterplots-sample-covariance-and-sample-correlation.html"><a href="scatterplots-sample-covariance-and-sample-correlation.html"><i class="fa fa-check"></i><b>3.8</b> Scatterplots, Sample Covariance and Sample Correlation</a></li>
<li class="chapter" data-level="3.9" data-path="plots.html"><a href="plots.html"><i class="fa fa-check"></i><b>3.9</b> Plots</a></li>
<li class="chapter" data-level="3.10" data-path="exercises-1.html"><a href="exercises-1.html"><i class="fa fa-check"></i><b>3.10</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="lrwor.html"><a href="lrwor.html"><i class="fa fa-check"></i><b>4</b> Linear Regression with One Regressor</a><ul>
<li class="chapter" data-level="4.1" data-path="estimating-the-coefficients-of-the-linear-regression-model.html"><a href="estimating-the-coefficients-of-the-linear-regression-model.html"><i class="fa fa-check"></i><b>4.1</b> Estimating the Coefficients of the Linear Regression Model</a><ul>
<li class="chapter" data-level="" data-path="estimating-the-coefficients-of-the-linear-regression-model.html"><a href="estimating-the-coefficients-of-the-linear-regression-model.html#the-ordinary-least-squares-estimator"><i class="fa fa-check"></i>The Ordinary Least Squares Estimator</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="measures-of-fit.html"><a href="measures-of-fit.html"><i class="fa fa-check"></i><b>4.2</b> Measures of Fit</a><ul>
<li><a href="measures-of-fit.html#the-r2">The <span class="math inline">\(R^2\)</span></a></li>
<li class="chapter" data-level="" data-path="measures-of-fit.html"><a href="measures-of-fit.html#standard-error-of-the-regression"><i class="fa fa-check"></i>Standard Error of the Regression</a></li>
<li class="chapter" data-level="" data-path="measures-of-fit.html"><a href="measures-of-fit.html#application-to-the-test-score-data"><i class="fa fa-check"></i>Application to the Test Score Data</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="the-least-squares-assumptions.html"><a href="the-least-squares-assumptions.html"><i class="fa fa-check"></i><b>4.3</b> The Least Squares Assumptions</a><ul>
<li class="chapter" data-level="" data-path="the-least-squares-assumptions.html"><a href="the-least-squares-assumptions.html#assumption-1-the-error-term-has-conditional-mean-of-zero"><i class="fa fa-check"></i>Assumption #1: The Error Term has Conditional Mean of Zero</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="the-true-relation.html"><a href="the-true-relation.html"><i class="fa fa-check"></i><b>4.4</b> the true relation</a><ul>
<li><a href="the-true-relation.html#assumption-2-all-x_i-y_i-are-independently-and-identically-distributed">Assumption #2: All <span class="math inline">\((X_i, Y_i)\)</span> are Independently and Identically Distributed</a></li>
<li class="chapter" data-level="" data-path="the-true-relation.html"><a href="the-true-relation.html#assumption-3-large-outliers-are-unlikely"><i class="fa fa-check"></i>Assumption #3: Large outliers are unlikely</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="tsdotoe.html"><a href="tsdotoe.html"><i class="fa fa-check"></i><b>4.5</b> The Sampling Distribution of the OLS Estimator</a><ul>
<li class="chapter" data-level="" data-path="tsdotoe.html"><a href="tsdotoe.html#r-simulation-study-1"><i class="fa fa-check"></i>R Simulation Study 1</a></li>
<li class="chapter" data-level="" data-path="tsdotoe.html"><a href="tsdotoe.html#r-simulation-study-2"><i class="fa fa-check"></i>R Simulation Study 2</a></li>
<li class="chapter" data-level="" data-path="tsdotoe.html"><a href="tsdotoe.html#r-simulation-study-3"><i class="fa fa-check"></i>R Simulation Study 3</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="exercises-2.html"><a href="exercises-2.html"><i class="fa fa-check"></i><b>4.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html"><a href="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html"><i class="fa fa-check"></i><b>5</b> Hypothesis Tests and Confidence Intervals in the Simple Linear Regression Model</a><ul>
<li class="chapter" data-level="5.1" data-path="testing-two-sided-hypotheses-concerning-beta-1.html"><a href="testing-two-sided-hypotheses-concerning-beta-1.html"><i class="fa fa-check"></i><b>5.1</b> Testing Two-Sided Hypotheses Concerning <span class="math inline">\(\beta_1\)</span></a></li>
<li class="chapter" data-level="5.2" data-path="confidence-intervals-for-regression-coefficients.html"><a href="confidence-intervals-for-regression-coefficients.html"><i class="fa fa-check"></i><b>5.2</b> Confidence Intervals for Regression Coefficients</a><ul>
<li class="chapter" data-level="" data-path="confidence-intervals-for-regression-coefficients.html"><a href="confidence-intervals-for-regression-coefficients.html#r-simulation-study-5.1"><i class="fa fa-check"></i>R Simulation Study 5.1</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="regression-when-x-is-a-binary-variable.html"><a href="regression-when-x-is-a-binary-variable.html"><i class="fa fa-check"></i><b>5.3</b> Regression when X is a Binary Variable</a></li>
<li class="chapter" data-level="5.4" data-path="heteroskedasticity-and-homoskedasticity.html"><a href="heteroskedasticity-and-homoskedasticity.html"><i class="fa fa-check"></i><b>5.4</b> Heteroskedasticity and Homoskedasticity</a><ul>
<li class="chapter" data-level="" data-path="heteroskedasticity-and-homoskedasticity.html"><a href="heteroskedasticity-and-homoskedasticity.html#a-real-world-example-for-heteroskedasticity"><i class="fa fa-check"></i>A Real-World Example for Heteroskedasticity</a></li>
<li class="chapter" data-level="" data-path="heteroskedasticity-and-homoskedasticity.html"><a href="heteroskedasticity-and-homoskedasticity.html#should-we-care-about-heteroskedasticity"><i class="fa fa-check"></i>Should We Care About Heteroskedasticity?</a></li>
<li class="chapter" data-level="" data-path="heteroskedasticity-and-homoskedasticity.html"><a href="heteroskedasticity-and-homoskedasticity.html#computation-of-heteroskedasticity-robust-standard-errors"><i class="fa fa-check"></i>Computation of Heteroskedasticity-Robust Standard Errors</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="the-gauss-markov-theorem.html"><a href="the-gauss-markov-theorem.html"><i class="fa fa-check"></i><b>5.5</b> The Gauss-Markov Theorem</a><ul>
<li class="chapter" data-level="" data-path="the-gauss-markov-theorem.html"><a href="the-gauss-markov-theorem.html#r-simulation-study-blue-estimator"><i class="fa fa-check"></i>R Simulation Study: BLUE Estimator</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="using-the-t-statistic-in-regression-when-the-sample-size-is-small.html"><a href="using-the-t-statistic-in-regression-when-the-sample-size-is-small.html"><i class="fa fa-check"></i><b>5.6</b> Using the t-Statistic in Regression When the Sample Size Is Small</a></li>
<li class="chapter" data-level="5.7" data-path="exercises-3.html"><a href="exercises-3.html"><i class="fa fa-check"></i><b>5.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="regression-models-with-multiple-regressors.html"><a href="regression-models-with-multiple-regressors.html"><i class="fa fa-check"></i><b>6</b> Regression Models with Multiple Regressors</a><ul>
<li class="chapter" data-level="6.1" data-path="omitted-variable-bias.html"><a href="omitted-variable-bias.html"><i class="fa fa-check"></i><b>6.1</b> Omitted Variable Bias</a></li>
<li class="chapter" data-level="6.2" data-path="the-multiple-regression-model.html"><a href="the-multiple-regression-model.html"><i class="fa fa-check"></i><b>6.2</b> The Multiple Regression Model</a></li>
<li class="chapter" data-level="6.3" data-path="measures-of-fit-in-multiple-regression.html"><a href="measures-of-fit-in-multiple-regression.html"><i class="fa fa-check"></i><b>6.3</b> Measures of Fit in Multiple Regression</a></li>
<li class="chapter" data-level="6.4" data-path="ols-assumptions-in-multiple-regression.html"><a href="ols-assumptions-in-multiple-regression.html"><i class="fa fa-check"></i><b>6.4</b> OLS Assumptions in Multiple Regression</a><ul>
<li class="chapter" data-level="" data-path="ols-assumptions-in-multiple-regression.html"><a href="ols-assumptions-in-multiple-regression.html#multicollinearity"><i class="fa fa-check"></i>Multicollinearity</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="the-distribution-of-the-ols-estimators-in-multiple-regression.html"><a href="the-distribution-of-the-ols-estimators-in-multiple-regression.html"><i class="fa fa-check"></i><b>6.5</b> The Distribution of the OLS Estimators in Multiple Regression</a></li>
<li class="chapter" data-level="6.6" data-path="exercises-4.html"><a href="exercises-4.html"><i class="fa fa-check"></i><b>6.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html"><a href="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html"><i class="fa fa-check"></i><b>7</b> Hypothesis Tests and Confidence intervals in Multiple Regression</a><ul>
<li class="chapter" data-level="7.1" data-path="hypothesis-tests-and-confidence-intervals-for-a-single-coefficient.html"><a href="hypothesis-tests-and-confidence-intervals-for-a-single-coefficient.html"><i class="fa fa-check"></i><b>7.1</b> Hypothesis Tests and Confidence Intervals for a Single Coefficient</a></li>
<li class="chapter" data-level="7.2" data-path="an-application-to-test-scores-and-the-student-teacher-ratio.html"><a href="an-application-to-test-scores-and-the-student-teacher-ratio.html"><i class="fa fa-check"></i><b>7.2</b> An Application to Test Scores and the Student-Teacher Ratio</a><ul>
<li class="chapter" data-level="" data-path="an-application-to-test-scores-and-the-student-teacher-ratio.html"><a href="an-application-to-test-scores-and-the-student-teacher-ratio.html#another-augmentation-of-the-model"><i class="fa fa-check"></i>Another Augmentation of the Model</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="joint-hypothesis-testing-using-the-f-statistic.html"><a href="joint-hypothesis-testing-using-the-f-statistic.html"><i class="fa fa-check"></i><b>7.3</b> Joint Hypothesis Testing Using the <span class="math inline">\(F\)</span>-Statistic</a></li>
<li class="chapter" data-level="7.4" data-path="confidence-sets-for-multiple-coefficients.html"><a href="confidence-sets-for-multiple-coefficients.html"><i class="fa fa-check"></i><b>7.4</b> Confidence Sets for Multiple Coefficients</a></li>
<li class="chapter" data-level="7.5" data-path="model-specification-for-multiple-regression.html"><a href="model-specification-for-multiple-regression.html"><i class="fa fa-check"></i><b>7.5</b> Model Specification for Multiple Regression</a><ul>
<li class="chapter" data-level="" data-path="model-specification-for-multiple-regression.html"><a href="model-specification-for-multiple-regression.html#model-specification-in-theory-and-in-practice"><i class="fa fa-check"></i>Model Specification in Theory and in Practice</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="analysis-of-the-test-score-data-set.html"><a href="analysis-of-the-test-score-data-set.html"><i class="fa fa-check"></i><b>7.6</b> Analysis of the Test Score Data Set</a></li>
<li class="chapter" data-level="7.7" data-path="exercises-5.html"><a href="exercises-5.html"><i class="fa fa-check"></i><b>7.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="nonlinear-regression-functions.html"><a href="nonlinear-regression-functions.html"><i class="fa fa-check"></i><b>8</b> Nonlinear Regression Functions</a><ul>
<li class="chapter" data-level="8.1" data-path="a-general-strategy-for-modeling-nonlinear-regression-functions.html"><a href="a-general-strategy-for-modeling-nonlinear-regression-functions.html"><i class="fa fa-check"></i><b>8.1</b> A General Strategy for Modeling Nonlinear Regression Functions</a></li>
<li class="chapter" data-level="8.2" data-path="nonlinear-functions-of-a-single-independent-variable.html"><a href="nonlinear-functions-of-a-single-independent-variable.html"><i class="fa fa-check"></i><b>8.2</b> Nonlinear Functions of a Single Independent Variable</a><ul>
<li class="chapter" data-level="" data-path="nonlinear-functions-of-a-single-independent-variable.html"><a href="nonlinear-functions-of-a-single-independent-variable.html#polynomials"><i class="fa fa-check"></i>Polynomials</a></li>
<li class="chapter" data-level="" data-path="nonlinear-functions-of-a-single-independent-variable.html"><a href="nonlinear-functions-of-a-single-independent-variable.html#logarithms"><i class="fa fa-check"></i>Logarithms</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="interactions-between-independent-variables.html"><a href="interactions-between-independent-variables.html"><i class="fa fa-check"></i><b>8.3</b> Interactions Between Independent Variables</a></li>
<li class="chapter" data-level="8.4" data-path="nonlinear-effects-on-test-scores-of-the-student-teacher-ratio.html"><a href="nonlinear-effects-on-test-scores-of-the-student-teacher-ratio.html"><i class="fa fa-check"></i><b>8.4</b> Nonlinear Effects on Test Scores of the Student-Teacher Ratio</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="assessing-studies-based-on-multiple-regression.html"><a href="assessing-studies-based-on-multiple-regression.html"><i class="fa fa-check"></i><b>9</b> Assessing Studies Based on Multiple Regression</a><ul>
<li class="chapter" data-level="9.1" data-path="internal-and-external-validity.html"><a href="internal-and-external-validity.html"><i class="fa fa-check"></i><b>9.1</b> Internal and External Validity</a></li>
<li class="chapter" data-level="9.2" data-path="threats-to-internal-validity-of-multiple-regression-analysis.html"><a href="threats-to-internal-validity-of-multiple-regression-analysis.html"><i class="fa fa-check"></i><b>9.2</b> Threats to Internal Validity of Multiple Regression Analysis</a></li>
<li class="chapter" data-level="9.3" data-path="internal-and-external-validity-when-the-regression-is-used-for-forecasting.html"><a href="internal-and-external-validity-when-the-regression-is-used-for-forecasting.html"><i class="fa fa-check"></i><b>9.3</b> Internal and External Validity When the Regression is Used for Forecasting</a></li>
<li class="chapter" data-level="9.4" data-path="example-test-scores-and-class-size.html"><a href="example-test-scores-and-class-size.html"><i class="fa fa-check"></i><b>9.4</b> Example: Test Scores and Class Size</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="regression-with-panel-data.html"><a href="regression-with-panel-data.html"><i class="fa fa-check"></i><b>10</b> Regression with Panel Data</a><ul>
<li class="chapter" data-level="10.1" data-path="panel-data.html"><a href="panel-data.html"><i class="fa fa-check"></i><b>10.1</b> Panel Data</a></li>
<li class="chapter" data-level="10.2" data-path="PDWTTP.html"><a href="PDWTTP.html"><i class="fa fa-check"></i><b>10.2</b> Panel Data with Two Time Periods: “Before and Afer” Comparisons</a></li>
<li class="chapter" data-level="10.3" data-path="fixed-effects-regression.html"><a href="fixed-effects-regression.html"><i class="fa fa-check"></i><b>10.3</b> Fixed Effects Regression</a><ul>
<li class="chapter" data-level="" data-path="fixed-effects-regression.html"><a href="fixed-effects-regression.html#estimation-and-inference"><i class="fa fa-check"></i>Estimation and Inference</a></li>
<li class="chapter" data-level="" data-path="fixed-effects-regression.html"><a href="fixed-effects-regression.html#application-to-traffic-deaths"><i class="fa fa-check"></i>Application to Traffic Deaths</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="regression-with-time-fixed-effects.html"><a href="regression-with-time-fixed-effects.html"><i class="fa fa-check"></i><b>10.4</b> Regression with Time Fixed Effects</a></li>
<li class="chapter" data-level="10.5" data-path="the-fixed-effects-regression-assumptions-and-standard-errors-for-fixed-effects-regression.html"><a href="the-fixed-effects-regression-assumptions-and-standard-errors-for-fixed-effects-regression.html"><i class="fa fa-check"></i><b>10.5</b> The Fixed Effects Regression Assumptions and Standard Errors for Fixed Effects Regression</a></li>
<li class="chapter" data-level="10.6" data-path="drunk-driving-laws-and-traffic-deaths.html"><a href="drunk-driving-laws-and-traffic-deaths.html"><i class="fa fa-check"></i><b>10.6</b> Drunk Driving Laws and Traffic Deaths</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="regression-with-a-binary-dependent-variable.html"><a href="regression-with-a-binary-dependent-variable.html"><i class="fa fa-check"></i><b>11</b> Regression with a Binary Dependent Variable</a><ul>
<li class="chapter" data-level="11.1" data-path="binary-dependent-variables-and-the-linear-probability-model.html"><a href="binary-dependent-variables-and-the-linear-probability-model.html"><i class="fa fa-check"></i><b>11.1</b> Binary Dependent Variables and the Linear Probability Model</a></li>
<li class="chapter" data-level="11.2" data-path="probit-and-logit-regression.html"><a href="probit-and-logit-regression.html"><i class="fa fa-check"></i><b>11.2</b> Probit and Logit Regression</a><ul>
<li class="chapter" data-level="" data-path="probit-and-logit-regression.html"><a href="probit-and-logit-regression.html#probit-regression"><i class="fa fa-check"></i>Probit Regression</a></li>
<li class="chapter" data-level="" data-path="probit-and-logit-regression.html"><a href="probit-and-logit-regression.html#logit-regression"><i class="fa fa-check"></i>Logit Regression</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="estimation-and-inference-in-the-logit-and-probit-models.html"><a href="estimation-and-inference-in-the-logit-and-probit-models.html"><i class="fa fa-check"></i><b>11.3</b> Estimation and Inference in the Logit and Probit Models</a></li>
<li class="chapter" data-level="11.4" data-path="application-to-the-boston-hmda-data.html"><a href="application-to-the-boston-hmda-data.html"><i class="fa fa-check"></i><b>11.4</b> Application to the Boston HMDA Data</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="instrumental-variables-regression.html"><a href="instrumental-variables-regression.html"><i class="fa fa-check"></i><b>12</b> Instrumental Variables Regression</a><ul>
<li class="chapter" data-level="12.1" data-path="TIVEWASRAASI.html"><a href="TIVEWASRAASI.html"><i class="fa fa-check"></i><b>12.1</b> The IV Estimator with a Single Regressor and a Single Instrument</a></li>
<li class="chapter" data-level="12.2" data-path="TGIVRM.html"><a href="TGIVRM.html"><i class="fa fa-check"></i><b>12.2</b> The General IV Regression Model</a></li>
<li class="chapter" data-level="12.3" data-path="checking-instrument-validity.html"><a href="checking-instrument-validity.html"><i class="fa fa-check"></i><b>12.3</b> Checking Instrument Validity</a></li>
<li class="chapter" data-level="12.4" data-path="application-to-the-demand-for-cigarettes-2.html"><a href="application-to-the-demand-for-cigarettes-2.html"><i class="fa fa-check"></i><b>12.4</b> Application to the Demand for Cigarettes</a></li>
<li class="chapter" data-level="12.5" data-path="where-do-valid-instruments-come-from.html"><a href="where-do-valid-instruments-come-from.html"><i class="fa fa-check"></i><b>12.5</b> Where Do Valid Instruments Come From?</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="experiments-and-quasi-experiments.html"><a href="experiments-and-quasi-experiments.html"><i class="fa fa-check"></i><b>13</b> Experiments and Quasi-Experiments</a><ul>
<li class="chapter" data-level="13.1" data-path="potential-outcomes-causal-effects-and-idealized-experiments.html"><a href="potential-outcomes-causal-effects-and-idealized-experiments.html"><i class="fa fa-check"></i><b>13.1</b> Potential Outcomes, Causal Effects and Idealized Experiments</a></li>
<li class="chapter" data-level="13.2" data-path="threats-to-validity-of-experiments.html"><a href="threats-to-validity-of-experiments.html"><i class="fa fa-check"></i><b>13.2</b> Threats to Validity of Experiments</a></li>
<li class="chapter" data-level="13.3" data-path="experimental-estimates-of-the-effect-of-class-size-reductions.html"><a href="experimental-estimates-of-the-effect-of-class-size-reductions.html"><i class="fa fa-check"></i><b>13.3</b> Experimental Estimates of the Effect of Class Size Reductions</a><ul>
<li class="chapter" data-level="" data-path="experimental-estimates-of-the-effect-of-class-size-reductions.html"><a href="experimental-estimates-of-the-effect-of-class-size-reductions.html#experimental-design-and-the-data-set"><i class="fa fa-check"></i>Experimental Design and the Data Set</a></li>
<li class="chapter" data-level="" data-path="experimental-estimates-of-the-effect-of-class-size-reductions.html"><a href="experimental-estimates-of-the-effect-of-class-size-reductions.html#analysis-of-the-star-data"><i class="fa fa-check"></i>Analysis of the STAR Data</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="quasi-experiments.html"><a href="quasi-experiments.html"><i class="fa fa-check"></i><b>13.4</b> Quasi Experiments</a><ul>
<li class="chapter" data-level="" data-path="quasi-experiments.html"><a href="quasi-experiments.html#the-differences-in-differences-estimator"><i class="fa fa-check"></i>The Differences-in-Differences Estimator</a></li>
<li class="chapter" data-level="" data-path="quasi-experiments.html"><a href="quasi-experiments.html#regression-discontinuity-estimators"><i class="fa fa-check"></i>Regression Discontinuity Estimators</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="introduction-to-time-series-regression-and-forecasting.html"><a href="introduction-to-time-series-regression-and-forecasting.html"><i class="fa fa-check"></i><b>14</b> Introduction to Time Series Regression and Forecasting</a><ul>
<li class="chapter" data-level="14.1" data-path="using-regression-models-for-forecasting.html"><a href="using-regression-models-for-forecasting.html"><i class="fa fa-check"></i><b>14.1</b> Using Regression Models for Forecasting</a></li>
<li class="chapter" data-level="14.2" data-path="time-series-data-and-serial-correlation.html"><a href="time-series-data-and-serial-correlation.html"><i class="fa fa-check"></i><b>14.2</b> Time Series Data and Serial Correlation</a><ul>
<li class="chapter" data-level="" data-path="time-series-data-and-serial-correlation.html"><a href="time-series-data-and-serial-correlation.html#notation-lags-differences-logarithms-and-growth-rates"><i class="fa fa-check"></i>Notation, Lags, Differences, Logarithms and Growth Rates</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="autoregressions.html"><a href="autoregressions.html"><i class="fa fa-check"></i><b>14.3</b> Autoregressions</a><ul>
<li><a href="autoregressions.html#the-pth-order-autoregressive-model">The <span class="math inline">\(p^{th}\)</span>-Order Autoregressive Model</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="can-you-beat-the-market-part-i.html"><a href="can-you-beat-the-market-part-i.html"><i class="fa fa-check"></i><b>14.4</b> Can You Beat the Market? (Part I)</a></li>
<li class="chapter" data-level="14.5" data-path="additional-predictors-and-the-adl-model.html"><a href="additional-predictors-and-the-adl-model.html"><i class="fa fa-check"></i><b>14.5</b> Additional Predictors and The ADL Model</a><ul>
<li class="chapter" data-level="" data-path="additional-predictors-and-the-adl-model.html"><a href="additional-predictors-and-the-adl-model.html#forecast-uncertainty-and-forecast-intervals"><i class="fa fa-check"></i>Forecast Uncertainty and Forecast Intervals</a></li>
</ul></li>
<li class="chapter" data-level="14.6" data-path="lag-length-selection-using-information-criteria.html"><a href="lag-length-selection-using-information-criteria.html"><i class="fa fa-check"></i><b>14.6</b> Lag Length Selection Using Information Criteria</a></li>
<li class="chapter" data-level="14.7" data-path="nonstationarity-i-trends.html"><a href="nonstationarity-i-trends.html"><i class="fa fa-check"></i><b>14.7</b> Nonstationarity I: Trends</a></li>
<li class="chapter" data-level="14.8" data-path="nonstationarity-ii-breaks.html"><a href="nonstationarity-ii-breaks.html"><i class="fa fa-check"></i><b>14.8</b> Nonstationarity II: Breaks</a></li>
<li class="chapter" data-level="14.9" data-path="can-you-beat-the-market-part-ii.html"><a href="can-you-beat-the-market-part-ii.html"><i class="fa fa-check"></i><b>14.9</b> Can You Beat the Market? Part II</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="estimation-of-dynamic-causal-effects.html"><a href="estimation-of-dynamic-causal-effects.html"><i class="fa fa-check"></i><b>15</b> Estimation of Dynamic Causal Effects</a><ul>
<li class="chapter" data-level="15.1" data-path="the-orange-juice-data.html"><a href="the-orange-juice-data.html"><i class="fa fa-check"></i><b>15.1</b> The Orange Juice Data</a></li>
<li class="chapter" data-level="15.2" data-path="dynamic-causal-effects.html"><a href="dynamic-causal-effects.html"><i class="fa fa-check"></i><b>15.2</b> Dynamic Causal Effects</a></li>
<li class="chapter" data-level="15.3" data-path="dynamic-multipliers-and-cumulative-dynamic-multipliers.html"><a href="dynamic-multipliers-and-cumulative-dynamic-multipliers.html"><i class="fa fa-check"></i><b>15.3</b> Dynamic Multipliers and Cumulative Dynamic Multipliers</a></li>
<li class="chapter" data-level="15.4" data-path="hac-standard-errors.html"><a href="hac-standard-errors.html"><i class="fa fa-check"></i><b>15.4</b> HAC Standard Errors</a></li>
<li class="chapter" data-level="15.5" data-path="estimation-of-dynamic-causal-effects-with-strictly-exogeneous-regressors.html"><a href="estimation-of-dynamic-causal-effects-with-strictly-exogeneous-regressors.html"><i class="fa fa-check"></i><b>15.5</b> Estimation of Dynamic Causal Effects with Strictly Exogeneous Regressors</a></li>
<li class="chapter" data-level="15.6" data-path="orange-juice-prices-and-cold-weather.html"><a href="orange-juice-prices-and-cold-weather.html"><i class="fa fa-check"></i><b>15.6</b> Orange Juice Prices and Cold Weather</a></li>
<li class="chapter" data-level="15.7" data-path="summary-7.html"><a href="summary-7.html"><i class="fa fa-check"></i><b>15.7</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="additional-topics-in-time-series-regression.html"><a href="additional-topics-in-time-series-regression.html"><i class="fa fa-check"></i><b>16</b> Additional Topics in Time Series Regression</a><ul>
<li class="chapter" data-level="16.1" data-path="vector-autoregressions.html"><a href="vector-autoregressions.html"><i class="fa fa-check"></i><b>16.1</b> Vector Autoregressions</a></li>
<li class="chapter" data-level="16.2" data-path="orders-of-integration-and-the-df-gls-unit-root-test.html"><a href="orders-of-integration-and-the-df-gls-unit-root-test.html"><i class="fa fa-check"></i><b>16.2</b> Orders of Integration and the DF-GLS Unit Root Test</a></li>
<li class="chapter" data-level="16.3" data-path="cointegration.html"><a href="cointegration.html"><i class="fa fa-check"></i><b>16.3</b> Cointegration</a></li>
<li class="chapter" data-level="16.4" data-path="volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html"><a href="volatility-clustering-and-autoregressive-conditional-heteroskedasticity.html"><i class="fa fa-check"></i><b>16.4</b> Volatility Clustering and Autoregressive Conditional Heteroskedasticity</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Using <tt>R</tt> for Introduction to Econometrics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div class = rmdreview>
This book is in <b>Open Review</b>. We want your feedback to make the book better for you and other students. You may annotate some text by <span style="background-color: #3297FD; color: white">selecting it with the cursor</span> and then click the <i class="h-icon-annotate"></i> on the pop-up menu. You can also see the annotations of others: click the <i class="h-icon-chevron-left"></i> in the upper right hand corner of the page <i class="fa fa-arrow-circle-right  fa-rotate-315" aria-hidden="true"></i>
</div>
<div id="exercises-3" class="section level2">
<h2><span class="header-section-number">5.7</span> Exercises</h2>
<div class="DCexercise">
<h4 id="testing-two-null-hypotheses-individually" class="unnumbered">1. Testing Two Null Hypotheses Individually</h4>
<p>Consider the estimated regression line</p>
<p><span class="math display">\[ \widehat{TestScore} = \underset{(23.96)}{567.43} - \underset{(0.85)}{7.15} \times STR, \, R^2 = 0.8976, \, SER=15.19 \]</span></p>
<p>with standard errors in parentheses.</p>
<p><strong>Instructions:</strong></p>
<ul>
<li>Compute the <span class="math inline">\(p\)</span>-value for a <span class="math inline">\(t\)</span>-test of the hypothesis that the intercept is zero. Save the result to <tt>p_int</tt></li>
<li>Compute the <span class="math inline">\(p\)</span>-value for a <span class="math inline">\(t\)</span>-test of the hypothesis that the coefficient of <tt>STR</tt> is zero. Save the result to <tt>p_STR</tt></li>
</ul>
<p><strong>Hint:</strong> both hypotheses can be tested individually using a two-sided test. Use <tt>pnorm()</tt> to obtain cumulated probabilities for standard normally distributed outcomes, see <tt>?pnorm</tt></p>


<div data-datacamp-exercise data-lang="r">

  <code data-type="sample-code">
  # Compute the p-value for the first significance test and save it to p_int


  # Compute the p-value for the second significance test and save it to p_cs
  
  
  </code>
  <code data-type="solution">
  t_int <- 567.43/23.9606
  p_int <- 2*(1-pnorm(abs(t_int)))
  t_STR <- 7.15/0.8536
  p_STR <- 2*(1-pnorm(abs(t_STR)))
  </code>
  <code data-type="sct">
  test_object("p_int")
  test_object("p_STR")
  </code>
  
</div>


</div>
<div class="DCexercise">
<h4 id="two-null-hypotheses-you-cant-reject-can-you" class="unnumbered">2. Two Null Hypotheses You Can’t Reject, Can You?</h4>
<p><span class="math display">\[\widehat{TestScore} = \underset{(23.96)}{567.43} - \underset{(0.85)}{7.15} \times STR, \, R^2 = 0.8976, \,SER=15.19\]</span></p>
<p>Can you reject the null hypotheses discussed in the previous code exercise using individual <span class="math inline">\(t\)</span>-tests at the <span class="math inline">\(5\%\)</span> significance level?</p>
<p>The variables <tt>t_int</tt> and <tt>t_STR</tt> are the <span class="math inline">\(t\)</span>-statistics. Both are available in your working environment.</p>
<p><strong>Instructions</strong></p>
<ul>
<li>Gather <tt>t_int</tt> and <tt>t_STR</tt> in a vector <tt>test</tt> and use logical operators to check whether the corresponding rejection rule applies.</li>
</ul>
<p><strong>Hints:</strong></p>
<ul>
<li>Both tests are two-sided <span class="math inline">\(t\)</span>-tests. Key Concept 5.2 recaps how a two-sided <span class="math inline">\(t\)</span>-test is conducted.</li>
<li>Use <tt>qnorm()</tt> to obtain normal critical values.</li>
</ul>


<div data-datacamp-exercise data-lang="r">

  <code data-type="pre-exercise-code">
  t_int <- 567.43/23.9606
  t_STR <- 7.15/0.8536
  </code>
  <code data-type="sample-code">
  # check wether the t-tests reject
  
  
  </code>
  <code data-type="solution">
  test <- c(t_int, t_STR)
  # entry is 'TRUE' if a test rejects
  abs(test) >= qnorm(0.95)
  </code>

  <code data-type="sct">
  test_or({
    test <- c(t_int,t_STR)
  },{
    test <- c(t_STR, t_int)
  })
  test_or({
    test_student_typed("abs(test) >= qnorm(0.95)")
  },{
    test_student_typed("abs(test) <= qnorm(0.95)")
  })
  </code>
  
</div>


</div>
<div class="DCexercise">
<h4 id="confidence-intervals" class="unnumbered">3. Confidence Intervals</h4>
<p><tt>mod</tt>, an object of class <tt>lm</tt> which contains the estimated model <span class="math display">\[\widehat{TestScore} = \underset{(23.96)}{567.43} - \underset{(0.85)}{7.15} \times STR, \, R^2 = 0.8976, \,SER=15.19\]</span> is available in your working environment.</p>
<p><strong>Instructions</strong></p>
<ul>
<li>Compute 90% confidence intervals for both coefficients.</li>
</ul>
<p><strong>Hints:</strong></p>
<p>Use the function <tt>confint()</tt>, see <tt>?confint</tt>. The argument <tt>level</tt> sets the confidence level to be used.</p>


<div data-datacamp-exercise data-lang="r">

  <code data-type="pre-exercise-code">
    STR <- c(23, 19, 30, 22, 23, 29, 35, 36, 33, 25)
    TS <- c(430, 430, 333, 410, 390, 377, 325, 310, 328, 375)
    mod <- lm(TS ~ STR)
  </code>
  <code data-type="sample-code">
  # compute 90% confidence intervals for the model coefficients
  
  
  </code>
  <code data-type="solution">
  confint(mod, level = 0.9)
  </code>

  <code data-type="sct">
  test_function("confint", args = c("object","level"))
  </code>
  
</div>


</div>
<div class="DCexercise">
<h4 id="a-confidence-interval-for-the-mean-i" class="unnumbered">4. A Confidence Interval for the Mean I</h4>
<p>Consider the model <span class="math display">\[Y_i = \beta_1 + u_i\]</span> where <span class="math inline">\(Y_i \sim \mathcal{N}(\mu, \sigma^2)\)</span>. Following the discussion preceding equation <a href="confidence-intervals-for-regression-coefficients.html#eq:KI">(5.1)</a>, a <span class="math inline">\(95\%\)</span> confidence interval for the mean of the <span class="math inline">\(Y_i\)</span> can be computed as</p>
<p><span class="math display">\[KI^{\mu}_{0.95} = \left[\hat\mu - 1.96 \times \frac{\sigma}{\sqrt{n}} \ , \ \hat\mu + 1.96 \times \frac{\sigma}{\sqrt{n}} \right].\]</span></p>
<p><strong>Instructions</strong></p>
<ul>
<li>Sample <span class="math inline">\(n=100\)</span> observations from a normal distribution with variance 100 and mean 10.</li>
<li>Use the sample to estimate <span class="math inline">\(\beta_1\)</span>. Save the estimate in <tt>mu_hat</tt>.</li>
<li>Assume that <span class="math inline">\(\sigma^2 = 100\)</span> is known. Replace the zeros in the code below to obtain a <span class="math inline">\(95\%\)</span> confidence interval for the mean of the <span class="math inline">\(Y_i\)</span>.</li>
</ul>
<p><strong>Hints:</strong></p>
<p>Use the function <tt>confint()</tt>, see <tt>?confint</tt>. The argument <tt>level</tt> sets the confidence level to be used.</p>


<div data-datacamp-exercise data-lang="r">

  <code data-type="sample-code">
  # random seed for reproducibility
  set.seed(1)
  
  
  # sample the observations
  
  
  # estimate the mean, assign the estimate to 'mu_hat'
  
  
  # compute the 95% confidence interval using the formula above
  CI <- c(
    "lower" = 0,
    "upper" = 0
  )
  
  </code>
  <code data-type="solution">
  set.seed(1)
  mu_hat <- mean(rnorm(100, mean = 10, sd = 10))
  CI <- c(
   "lower" = mu_hat - 1.96,
   "upper" = mu_hat + 1.96
  )
  </code>
  test_object("CI")
  <code data-type="sct">
  test_object("mu_hat")
  test_object("CI")
  </code>
  
</div>


</div>
<div class="DCexercise">
<h4 id="a-confidence-interval-for-the-mean-ii" class="unnumbered">5. A Confidence Interval for the Mean II</h4>
<p>For historical reasons, some <tt>R</tt> functions that we use to obtain statistical inference on model parameters, among them <tt>confint()</tt> and <tt>summary()</tt>, rely on the <span class="math inline">\(t\)</span>-distribution instead of using the large-sample normal approximation. This is why for small sample sizes (and hence small degrees of freedom), <span class="math inline">\(p\)</span>-values and confidence intervals reported by these functions deviate from those computed using critical values or cumulative probabilities of the standard normal distribution.</p>
<p>The <span class="math inline">\(95\%\)</span> confidence interval for the mean in the previous exercise is <span class="math inline">\([9.1289, 13.0489]\)</span>.</p>
<p>100 observations sampled from a normal distribution with <span class="math inline">\(\mu=10\)</span> and <span class="math inline">\(\sigma^2=100\)</span> have been assigned to the vector <tt>s</tt> and are available in your workspace.</p>
<p><strong>Instructions</strong></p>
<ul>
<li>Set up a suitable regression model to estimate the mean of the observations in <tt>s</tt>. Then use <tt>confint()</tt> to compute a <span class="math inline">\(95\%\)</span> confidence interval for the mean.</li>
</ul>
<p>(Check that the result is different from the interval reported above.)</p>


<div data-datacamp-exercise data-lang="r">

  <code data-type="pre-exercise-code">
  set.seed(1); s <- rnorm(100, mean = 10, sd = 10)
  </code>
  <code data-type="sample-code">
  # use a regression to obtain an estimate of the mean
  
  
  # compute the 95% CI
  
  
  </code>
  <code data-type="solution">
  set.seed(1)
  confint(lm(s ~ 1))
  </code>
  <code data-type="sct">
  test_predefined_objects("s")
  test_output_contains("confint(lm(s ~ 1))")
  </code>
  
</div>


</div>
<div class="DCexercise">
<h4 id="regression-on-a-dummy-i" class="unnumbered">6. Regression on a Dummy I</h4>
<p>Chapter 5.3 discusses regression when <span class="math inline">\(X\)</span> is a dummy variables where we have used a <tt>for()</tt> loop to generate a binary variable indicating whether a schooling district in the <tt>CASchools</tt> data set has a student-teacher ration below 20. Though it is instructive to use a loop for this, there are ways to achieve the same with less code.</p>
<p>A dataframe <tt>DF</tt> with 100 observations of a variable <tt>X</tt> is available in your working environment.</p>
<p><strong>Instructions</strong></p>
<ul>
<li><p>Use <tt>ifelse()</tt> to generate a binary vector <tt>dummy</tt> indicating whether the observations in <tt>X</tt> are positive.</p></li>
<li><p>Append <tt>dummy</tt> to the dataframe <tt>DF</tt>.</p></li>
</ul>


<div data-datacamp-exercise data-lang="r">

  <code data-type="pre-exercise-code">
  set.seed(1)
  DF <- data.frame("X" = rnorm(100))
  </code>
  <code data-type="sample-code">
  # generate the dummy vector 'dummy' using 'ifelse()'
  
  
  # append 'dummy' to 'DF'
  
  
  </code>
  <code data-type="solution">
  dummy <- ifelse(DF$X > 0, 1, 0)
  DF$dummy <- dummy
  </code>
  <code data-type="sct">
  test_object("dummy")
  test_function("ifelse")
  test_object("DF")
  </code>
  
</div>


</div>
<div class="DCexercise">
<h4 id="regression-on-a-dummy-ii" class="unnumbered">7. Regression on a Dummy II</h4>
<p>A dataframe <tt>DF</tt> with 100 observations on <tt>Y</tt> and the binary variable <tt>D</tt> from the previous exercise are available in your working environment.</p>
<p><strong>Instructions</strong></p>
<ul>
<li><p>Compute the group-specific sample means of the observations in <tt>Y</tt>. Save the mean of observations in <tt>Y</tt> where <tt>dummy == 1</tt> to <tt>mu_Y_D1</tt> and assign the mean of those observations with <tt>D == 0</tt> to <tt>mu_Y_D0</tt>.</p></li>
<li><p>Use <tt>lm()</tt> to regress <tt>Y</tt> on <tt>D</tt> i.e. estimate the coefficients in the model <span class="math display">\[\widehat{Y}_i = \beta_0 + \beta_1 \times D_i + u_i.\]</span></p></li>
</ul>
<p>Check that the estimates of the coefficients <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> reflect specific sample means. Can you tell which?</p>


<div data-datacamp-exercise data-lang="r">

  <code data-type="pre-exercise-code">
  set.seed(1)
  DF <- data.frame("Y" = rnorm(100))
  DF$D <- ifelse(DF$Y > 0, 1, 0)
  </code>
  <code data-type="sample-code">
  # compute group-specific sample means of 'Y'
  
  
  # Regress 'Y' on 'D'
  
  
  </code>
  <code data-type="solution">
   mu_Y_D1 <- mean(DF$Y[DF$D ==1])
   mu_Y_D0 <- mean(DF$Y[DF$D ==0])
   lm(Y ~ dummy, data = DF)
  </code>
  <code data-type="sct">
  test_object("mu_Y_D1")
  test_object("mu_Y_D1")
  test_or(
  {
  test_function("lm", args = "formula")
  },{
  ex() %>% override_solution("lm(DF$Y ~ DF$dummy)") %>% check_function("lm") %>% check_arg("formula")
  }
  )
  </code>
  
</div>


</div>
<div class="DCexercise">
<h4 id="regression-on-a-dummy-iii" class="unnumbered">8. Regression on a Dummy III</h4>
<p>In this exercise, you have to visualize some of the results from the dummy regression model <span class="math display">\[\widehat{Y}_i = -0.66 + 1.43 \times D_i\]</span> estimated in the previous exercise.</p>
<p>A dataframe <tt>DF</tt> with 100 observations on <tt>X</tt> and the binary variable <tt>dummy</tt> as well as the model object <tt>dummy_mod</tt> from the previous exercise are available in your working environment.</p>
<p><strong>Instructions</strong></p>
<ul>
<li><p>Start by drawing a visually appealing plot of the observations on <span class="math inline">\(Y\)</span> and <span class="math inline">\(D\)</span> based on the code chunk provided in <tt>Script.R</tt>. Replace the <tt>???</tt> by the correct expressions!</p></li>
<li><p>Add the regression line to the plot.</p></li>
</ul>


<div data-datacamp-exercise data-lang="r">

  <code data-type="pre-exercise-code">
  set.seed(1)
  DF <- data.frame("Y" = rnorm(100))
  DF$D <- ifelse(DF$Y > 0, 1, 0)
  dummy_mod <- lm(Y ~ D, data = DF)
  </code>
  <code data-type="sample-code">
  # Replace the '???' by the correct values
  plot(x = ??? , y = ???, 
     pch = 20, 
     cex = 1,
     col = 'Steelblue',
     xlab = expression(D[i]), ylab = 'Test Score',
     main = 'Dummy Regression'
     )
  
  # add the regression line   
  
  </code>
  <code data-type="solution">
  plot(x = DF$D , y = DF$Y, 
     pch = 20, 
     cex = 1,
     col = 'Steelblue',
     xlab = expression(D[i]), ylab = 'Test Score',
     main = 'Dummy Regression'
    )  
    abline(dummy_mod)
  </code>
  <code data-type="sct">
  test_predefined_objects(c("DF","dummy_mod"))
  test_function("abline")
  test_function("plot", args = c("x","y"))
  success_msg("Nice! Clearly, a line is not a suitable way to think of this model!")
  </code>
  
</div>


</div>
<div class="DCexercise">
<h4 id="gender-wage-gap-i" class="unnumbered">9. Gender Wage Gap I</h4>
<p><tt>CPS1985</tt> is a cross-section data set originating from the May 1985 <em>Current Population Survey</em> by the <em>US Census Bureau</em> and, among others things, containes observations on wage and gender of employees.</p>
<p><tt>CPS1985</tt> is part of the package <tt>AER</tt>.</p>
<p><strong>Instructions</strong></p>
<ul>
<li><p>Load the package <tt>AER</tt> and attach the data set <tt>CPS1985</tt>.</p></li>
<li><p>Estimate the dummy regression model <span class="math display">\[wage_i = \beta_0 + \beta_1 \cdot female_i + u_i\]</span> where</p>
<span class="math display">\[\begin{align*}
  female = 
  \begin{cases}
    1, &amp; \text{if employee is female} \\
    0, &amp; \text{if employee is male}.
  \end{cases}
\end{align*}\]</span>
<p>Save the result in <tt>wage_mod</tt>.</p></li>
</ul>


<div data-datacamp-exercise data-lang="r">

  <code data-type="sample-code">
  # Load the package and attach the data set
  
  
  # Perform the regression
  
  
  </code>
  <code data-type="solution">
  library(AER)
  data(CPS1985)
  dummy_mod <- lm(wage ~ gender, data = CPS1985)
  </code>
  <code data-type="sct">
  test_function("library")
  test_function("data")
  test_or({
    ex() %>% override_solution("attach(CPS1985); dummy_mod <- lm(wage ~ gender)") %>% check_object("dummy_mod")
  },{
    ex() %>% override_solution("dummy_mod <- lm(CPS1985$wage ~ CPS1985$gender)") %>% check_object("dummy_mod")
  },{
    ex() %>% override_solution("dummy_mod <- lm(wage ~ gender, data = CPS1985)") %>% check_object("dummy_mod")
  }
  )
  success_msg("Well done!")
  </code>
  
</div>


</div>
<div class="DCexercise">
<h4 id="gender-wage-gap-ii" class="unnumbered">10. Gender Wage Gap II</h4>
<p>The wage regression from the previous exercise yields <span class="math display">\[\widehat{wage}_i = 9.995 - 2.116 \cdot female_i.\]</span></p>
<p>The model object <tt>dummy_mod</tt> is available in your working environment.</p>
<p><strong>Instructions</strong></p>
<ul>
<li>Test the hypothesis that the coefficient on <span class="math inline">\(female_i\)</span> is zero. This would imply that there is no gender wage gap. Use White’s (1980) heteroskedasticity-robust estimator.</li>
</ul>
<p><strong>Hint:</strong></p>
<ul>
<li><p><tt>vcovHC()</tt> computes heteroskedasticity-robust estimates of the covariance matrix of the coefficient estimators for the model supplied, see <tt>?vcovHC</tt>.</p></li>
<li><p><tt>coeftest()</tt> performs significance tests for the coefficients in model objects. A covariance matrix can be supplied using the argument <tt>vcov.</tt>.</p></li>
</ul>


<div data-datacamp-exercise data-lang="r">
  
  <code data-type="pre-exercise-code">
    library(AER)
    data(CPS1985)
    dummy_mod <- lm(wage ~ gender, data = CPS1985)
  </code>
  <code data-type="sample-code">
  # test whether the gender gap is significantly different from zero 
  # use robust standard errors
  
  
  </code>
  <code data-type="solution">
  coeftest(dummy_mod, vcov. = vcovHC(dummy_mod, type = "HC0"))
  # or
  linearHypothesis(dummy_mod, "genderfemale=0", vcov. = vcovHC(dummy_mod, type = "HC0"))
  </code>
  <code data-type="sct">
  test_predefined_objects("dummy_mod")
  test_or({
    test_function("coeftest", args = c("x", "vcov.")) 
  },{
    test_function("linearHypothesis", args = c("model", "vcov.", "hypothesis.matrix"))
  },{
    f <- ex() %>% override_solution('linearHypothesis(dummy_mod, "genderfemale", vcov. = vcovHC(dummy_mod, type = "HC0"))') %>% check_function("linearHypothesis")
    f %>% check_arg("model")
    f %>% check_arg("vcov.")
    f %>% check_arg("hypothesis.matrix")
  })
  success_msg("Right! The hypothesis that there is no wage gap is rejected at any common level.")
  </code>
  
</div>


</div>
<div class="DCexercise">
<h4 id="heteroskedasticity-robust-standard-errors" class="unnumbered">11. Heteroskedasticity-Robust Standard Errors</h4>
<p>In the simple regression model, the covariance matrix of the coefficient estimators is denoted</p>
<span class="math display">\[\begin{equation}
\text{Var}
  \begin{pmatrix}
    \hat\beta_0 \\
    \hat\beta_1
  \end{pmatrix} = 
\begin{pmatrix}
  \text{Var}(\hat\beta_0) &amp; \text{Cov}(\hat\beta_0,\hat\beta_1) \\
\text{Cov}(\hat\beta_0,\hat\beta_1) &amp; \text{Var}(\hat\beta_1)
\end{pmatrix}
\end{equation}\]</span>
<p>The function <tt>vcovHC</tt> can be used to obtain estimates of this matrix for a model object of interest.</p>
<p><tt>gender_mod</tt>, a model object containing the wage regression dealt with in exercises 9 and 10 is available in your working environment.</p>
<p><strong>Instructions</strong></p>
<ul>
<li>Compute robust standard errors of the type <tt>HC0</tt> for the coefficients estimators in the model object <tt>gender_mod</tt>. Store the standard errors in a vector named <tt>rob_SEs</tt>.</li>
</ul>
<p><strong>Hint:</strong></p>
<ul>
<li><p>The standard errors we seek can be obtained by taking the square root of the diagonal elements of the estimated covariance matrix.</p></li>
<li><p><tt>diag(A)</tt> returns the diagonal elements of the matrix <tt>A</tt>.</p></li>
</ul>


<div data-datacamp-exercise data-lang="r">
  
  <code data-type="pre-exercise-code">
    library(AER)
    data(CPS1985)
    dummy_mod <- lm(wage ~ gender, data = CPS1985)
  </code>
  <code data-type="sample-code">
  # compute robust standard errors and save them in rob_SEs
  
  
  </code>
  <code data-type="solution">
  rob_SEs <- sqrt(diag(vcovHC(dummy_mod, typ = "HC0")))
  </code>
  <code data-type="sct">
  test_predefined_objects("dummy_mod")
  test_object("rob_SEs")
  success_msg("Nice! ")
  </code>
  
</div>


</div>
<div class="DCexercise">
<h4 id="robust-confidence-intervals" class="unnumbered">12. Robust Confidence Intervals</h4>
<p>The function <tt>confint()</tt> computes confidence intervals for regression models using homoskedasticity-only standard errors such that this function is not an option when there is heteroskedasticity.</p>
<p>The function <tt>Rob_CI()</tt> is meant to compute and report heteroskedasticity-robust confidence intervals for both model coefficients in a simple regression model.</p>
<p><tt>gender_mod</tt>, a model object containing the wage regression dealt with in the previous exercises is available in your working environment.</p>
<p><strong>Instructions</strong></p>
<ul>
<li><p>Complete the code of <tt>Rob_CI()</tt> given in <tt>Script.R</tt> such that lower and upper bounds of <span class="math inline">\(95\%\)</span> confidence intervals are returned.</p></li>
<li><p>Use the function to obtain <span class="math inline">\(95\%\)</span> confidence intervals for the model coefficients in <tt>dummy_mod</tt>.</p></li>
</ul>


<div data-datacamp-exercise data-lang="r">
  
  <code data-type="pre-exercise-code">
    library(AER)
    data(CPS1985)
    dummy_mod <- lm(wage ~ gender, data = CPS1985)
  </code>
  <code data-type="sample-code">
  # complete the function below
  
  Rob_CI <- function(model) {
    SEs <- ???
    lower <- model$coef - ???
    upper <- model$coef + ???
    return(
      cbind("Lower" = lower, "Upper" = upper)
    )
  }
  
  </code>
  <code data-type="solution">
    Rob_CI <- function(model) {
    SEs <- sqrt(diag(vcovHC(model, type = "HC0")))
    lower <- model$coef - 1.96 * SEs
    upper <- model$coef + 1.96 * SEs
    return(
      cbind("Lower" = lower, "Upper" = upper)
    )
  }
  </code>
  <code data-type="sct">
  test_function_definition("Rob_CI",
                         function_test = test_expression_result("Rob_CI(dummy_mod)"))
  test_output_contains("Rob_CI(dummy_mod)")
  success_msg("Nice!")
  </code>
  
</div>


</div>
<div class="DCexercise">
<h4 id="a-small-simulation-study-i" class="unnumbered">13. A Small Simulation Study I</h4>
Consider the data generating process
<span class="math display">\[\begin{align*}
  X_i \sim&amp; \, \mathcal{U}[2,10],\\
  e_i \sim&amp; \, N(0, X_i),\\
  Yi =&amp; \, \beta_1 X_i + e_i  
\end{align*}\]</span>
<p>where <span class="math inline">\(\mathcal{U}[0,10]\)</span> denotes the uniform distribution on the interval <span class="math inline">\([0,10]\)</span> and <span class="math inline">\(\beta_1=2\)</span>.</p>
<p>Notice that the errors <span class="math inline">\(e_i\)</span> are heteroskedastic since the variance is a linear function of <span class="math inline">\(X_i\)</span>.</p>
<p><strong>Instructions</strong></p>
<ul>
<li>Write a function <tt>DGP_OLS</tt> that generates a sample <span class="math inline">\((X_i,Y_i)\)</span>, <span class="math inline">\(i=1,…,100\)</span> and returns the OLS estimate of <span class="math inline">\(\beta_1\)</span>.</li>
</ul>
<p><strong>Hints</strong></p>
<p><tt>runif()</tt> can be used to obtain random samples form a uniform distribution, see <tt>?runif</tt></p>


<div data-datacamp-exercise data-lang="r">
  
  <code data-type="pre-exercise-code">

  </code>
  <code data-type="sample-code">
  # write the function
  </code>
  <code data-type="solution">
  set.seed(1)
  # write the function
  DGP_OLS <- function() {
  X <- runif(100,2,10)
  Y <- X + rnorm(100, sd = sqrt(X))
  return(
    c("beta_1_hat" = sum(X*Y)/sum(X^2))
  )
  }
  </code>
  <code data-type="sct">
  test_function_definition("DGP_OLS", 
                           function_test =
                           test_expression_result("DGP_OLS()")
  )
  success_msg("Well Done!")
  </code>
  
</div>


</div>
<div class="DCexercise">
<h4 id="a-small-simulation-study-ii" class="unnumbered">14. A Small Simulation Study II</h4>
<p>The function <tt>DGP_OLS()</tt> from the previous exercise is available in your working environment.</p>
<p><strong>Instructions</strong></p>
<ul>
<li><p>Use <tt>replicate()</tt> to generate a sample of <span class="math inline">\(1000\)</span> OLS estimates <span class="math inline">\(\widehat{\beta}_1\)</span> using the function <tt>DGP_OLS</tt>. Store the estimates in a vector named <tt>estimates</tt>.</p></li>
<li><p>Estimate the variance of the OLS estimates. Store the result in <tt>est_var_OLS</tt>.</p></li>
</ul>


<div data-datacamp-exercise data-lang="r">
  
  <code data-type="pre-exercise-code">
  DGP_OLS <- function() {
    X <- runif(100,2,10)
    Y <- X + rnorm(100, sd = sqrt(X))
    return(
      c("beta_1_hat" = sum(X*Y)/sum(X^2))
    )
    }
  </code>
  <code data-type="sample-code">
  set.seed(1)
  # Generate 1000 estimates of beta_1 using 'GDP_OLS()', store them in 'estimates'


  # Estimate the variance of the estimates
  
  
  </code>
  <code data-type="solution">
  set.seed(1)
  # Generate 1000 estimates of beta_1 using 'GDP_OLS()', store them in 'estimates'
  estimates <- replicate(1000, DGP_OLS())
  # Estimate the variance of the estimates
  est_var_OLS <- var(estimates)
  </code>
  <code data-type="sct">
  test_predefined_objects("DGP_OLS")
  test_object("estimates")
  test_object("est_var_OLS")
  </code>
  
</div>


</div>
<div class="DCexercise">
<h4 id="a-small-simulation-study-iii" class="unnumbered">15. A Small Simulation Study III</h4>
<p>The Gauss-Markov Theorem states that the OLS estimator in linear regression models is no longer the most efficient estimator (in the sense of minimum variance) among the conditionally unbiased linear estimators, that is the OLS estimator loses the BLUE property, under heteroskedasticity.</p>
<p>It turns out that OLS applied to the weighted observations <span class="math inline">\((w_i X_i, w_i Y_i)\)</span> where <span class="math inline">\(w_i=\frac{1}{\sigma_i}\)</span> yields the BLUE estimator under heteroskedasticity. This estimator is called the <em>weighted least squares</em> (WLS) estimator so that its variance is smaller than the variance of the OLS estimator.</p>
<p>The function <tt>DGP_OLS()</tt> and the estimated variance <tt>est_var_OLS</tt> from the previous exercises are available in your working environment.</p>
<p><strong>Instructions</strong></p>
<ul>
<li><p>Write a function <tt>DGP_WLS()</tt> that generates <span class="math inline">\(100\)</span> samples using the DGP introduced in exercise 13 and returns the WLS estimate of <span class="math inline">\(\beta_1\)</span>. Treat <span class="math inline">\(\sigma_i\)</span> as known, i.e. set <span class="math inline">\(w_i=\frac{1}{X_i}\)</span>.</p></li>
<li><p>Repeat exercise 14 using <tt>DGP_WLS()</tt>. Store the estimated variance in <tt>est_var_GLS</tt>.</p></li>
<li><p>Compare the estimated variances <tt>est_var_OLS</tt> and <tt>est_var_GLS</tt> using logical operators (<tt>&lt;</tt> or <tt>&gt;</tt>).</p></li>
</ul>
<p><strong>Hints</strong></p>
<ul>
<li><p><tt>DGP_WLS()</tt> can be obtained using a modified code of <tt>DGP_OLS()</tt>.</p></li>
<li><p>Remember that functions are objects and you may print the code of a function to the console.</p></li>
</ul>


<div data-datacamp-exercise data-lang="r">
  
  <code data-type="pre-exercise-code">
  set.seed(1)
  DGP_OLS <- function() {
    X <- runif(100,2,10)
    Y <- X + rnorm(100, sd = sqrt(X))
    return(
      c("beta_1_hat" = sum(X*Y)/sum(X^2))
    )
  }
  estimates <- replicate(1000, DGP_OLS())
  est_var_OLS <- var(estimates)
  </code>
  <code data-type="sample-code">
  set.seed(1)
  # Define the function 'DGP_GLS()'
  
  
  # estimate the variance, assign the value to 'var_est_GLS'
  
  
  # compare the estimated variances
  
  
  </code>
  <code data-type="solution">
  set.seed(1)
  # Define the function 'DGP_GLS()'
  DGP_GLS <- function() {
  X <- runif(100,2,10)
  Y <- X + rnorm(100, sd = sqrt(X))
  w <- 1/sqrt(X)
  return(
    c("beta_1_hat" = sum(w^2*X*Y)/sum((w*X)^2))
  )
  }
  # estimate the variance, assign the value to 'var_est_GLS'
  est_var_GLS <- var(replicate(1000, DGP_GLS()))

  # compare the estimated variances
  est_var_GLS < est_var_OLS
  </code>
  <code data-type="sct">
  test_predefined_objects(c("DGP_OLS","est_var_OLS"))
  test_function_definition("DGP_GLS",
                           function_test =
                           test_expression_result("DGP_OLS()")
  
  )
  test_object("est_var_GLS")
  test_or({
    test_student_typed("est_var_GLS < est_var_OLS")
  },{
    test_student_typed("est_var_GLS > est_var_OLS")
  },{
    test_student_typed("est_var_OLS > est_var_GLS")
  },{
    test_student_typed("est_var_OLS < est_var_GLS")
  })
  success_msg("Nice! This shows that the GLS estimator indeed has lower variance than OLS.")
  </code>
  
</div>


</div>

</div>
<!-- </div> -->
            </section>

          </div>
        </div>
      </div>
<a href="using-the-t-statistic-in-regression-when-the-sample-size-is-small.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="regression-models-with-multiple-regressors.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 1
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/05-ch5.Rmd",
"text": "Edit"
},
"download": ["URFITE.pdf"],
"toc": {
"collapse": "subsection",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
