<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Using R for Introduction to Econometrics</title>
  <meta name="description" content="Using <tt>R</tt> for Introduction to Econometrics">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Using R for Introduction to Econometrics" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="Emwikts1970/URFITE-Bookdown" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Using R for Introduction to Econometrics" />
  
  
  

<meta name="author" content="Christoph Hanck, Martin Arnold, Alexander Gerber and Martin Schmelzer">


<meta name="date" content="2018-07-26">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="using-the-t-statistic-in-regression-when-the-sample-size-is-small.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="js/hideOutput.js"></script>
<script type="text/javascript" src="MathJax-2.7.2/MathJax.js?config=default"></script>

 <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        extensions: ["tex2jax.js", "TeX/AMSmath.js"],
        tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
        jax: ["input/TeX","output/CommonHTML"]
      });
      MathJax.Hub.processSectionDelay = 0;
  </script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110299877-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110299877-1');
</script>

<!-- open review block -->

<script async defer src="https://hypothes.is/embed.js"></script>

<!-- datacamp-light-latest -->

<script src="https://cdn.datacamp.com/datacamp-light-latest.min.js"></script>


<!-- <script src="js/d3.v3.min.js"></script>
<script src="js/leastsquares.js"></script>
<script src="js/d3functions.js"></script>
<script src="d3.slider.js"></script>
<script src="slrm.js"></script> -->


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; background-color: #f8f8f8; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
pre, code { background-color: #f8f8f8; }
code > span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code > span.dt { color: #204a87; } /* DataType */
code > span.dv { color: #0000cf; } /* DecVal */
code > span.bn { color: #0000cf; } /* BaseN */
code > span.fl { color: #0000cf; } /* Float */
code > span.ch { color: #4e9a06; } /* Char */
code > span.st { color: #4e9a06; } /* String */
code > span.co { color: #8f5902; font-style: italic; } /* Comment */
code > span.ot { color: #8f5902; } /* Other */
code > span.al { color: #ef2929; } /* Alert */
code > span.fu { color: #000000; } /* Function */
code > span.er { color: #a40000; font-weight: bold; } /* Error */
code > span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #000000; } /* Constant */
code > span.sc { color: #000000; } /* SpecialChar */
code > span.vs { color: #4e9a06; } /* VerbatimString */
code > span.ss { color: #4e9a06; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #000000; } /* Variable */
code > span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code > span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code > span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code > span.ex { } /* Extension */
code > span.at { color: #c4a000; } /* Attribute */
code > span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code > span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="toc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">URFITE</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="a-very-short-introduction-to-r-and-rstudio.html"><a href="a-very-short-introduction-to-r-and-rstudio.html"><i class="fa fa-check"></i><b>1.1</b> A Very Short Introduction to <tt>R</tt> and <em>RStudio</em></a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="htaciitslrm.html"><a href="htaciitslrm.html"><i class="fa fa-check"></i><b>2</b> Hypothesis Tests and Confidence Intervals in the Simple Linear Regression Model</a><ul>
<li class="chapter" data-level="2.1" data-path="testing-two-sided-hypotheses-concerning-the-slope-coefficient.html"><a href="testing-two-sided-hypotheses-concerning-the-slope-coefficient.html"><i class="fa fa-check"></i><b>2.1</b> Testing Two-Sided Hypotheses Concerning the Slope Coefficient</a></li>
<li class="chapter" data-level="2.2" data-path="cifrc.html"><a href="cifrc.html"><i class="fa fa-check"></i><b>2.2</b> Confidence Intervals for Regression Coefficients</a><ul>
<li class="chapter" data-level="" data-path="cifrc.html"><a href="cifrc.html#simulation-study-confidence-intervals"><i class="fa fa-check"></i>Simulation Study: Confidence Intervals</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="rwxiabv.html"><a href="rwxiabv.html"><i class="fa fa-check"></i><b>2.3</b> Regression when X is a Binary Variable</a></li>
<li class="chapter" data-level="2.4" data-path="hah.html"><a href="hah.html"><i class="fa fa-check"></i><b>2.4</b> Heteroskedasticity and Homoskedasticity</a><ul>
<li class="chapter" data-level="" data-path="hah.html"><a href="hah.html#a-real-world-example-for-heteroskedasticity"><i class="fa fa-check"></i>A Real-World Example for Heteroskedasticity</a></li>
<li class="chapter" data-level="" data-path="hah.html"><a href="hah.html#should-we-care-about-heteroskedasticity"><i class="fa fa-check"></i>Should We Care About Heteroskedasticity?</a></li>
<li class="chapter" data-level="" data-path="hah.html"><a href="hah.html#computation-of-heteroskedasticity-robust-standard-errors"><i class="fa fa-check"></i>Computation of Heteroskedasticity-Robust Standard Errors</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="the-gauss-markov-theorem.html"><a href="the-gauss-markov-theorem.html"><i class="fa fa-check"></i><b>2.5</b> The Gauss-Markov Theorem</a><ul>
<li class="chapter" data-level="" data-path="the-gauss-markov-theorem.html"><a href="the-gauss-markov-theorem.html#simulation-study-blue-estimator"><i class="fa fa-check"></i>Simulation Study: BLUE Estimator</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="using-the-t-statistic-in-regression-when-the-sample-size-is-small.html"><a href="using-the-t-statistic-in-regression-when-the-sample-size-is-small.html"><i class="fa fa-check"></i><b>2.6</b> Using the t-Statistic in Regression When the Sample Size Is Small</a></li>
<li class="chapter" data-level="2.7" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>2.7</b> Exercises</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Using <tt>R</tt> for Introduction to Econometrics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div class = rmdreview>
This book is in <b>Open Review</b>. We want your feedback to make the book better for you and other students. You may annotate some text by <span style="background-color: #3297FD; color: white">selecting it with the cursor</span> and then click the <i class="h-icon-annotate"></i> on the pop-up menu. You can also see the annotations of others: click the <i class="h-icon-chevron-left"></i> in the upper right hand corner of the page <i class="fa fa-arrow-circle-right  fa-rotate-315" aria-hidden="true"></i>
</div>
<div id="exercises" class="section level2">
<h2><span class="header-section-number">2.7</span> Exercises</h2>
<div class="DCexercise">
<h4 id="testing-two-null-hypotheses-individually" class="unnumbered">1. Testing Two Null Hypotheses Individually</h4>
<p>Consider the estimated regression line</p>
<p><span class="math display">\[ \widehat{TestScore} = \underset{(23.96)}{567.43} - \underset{(0.85)}{7.15} \times STR, \, R^2 = 0.8976, \, SER=15.19 \]</span></p>
<p>with standard errors in parentheses.</p>
<p><strong>Instructions:</strong></p>
<ul>
<li>Compute the <span class="math inline">\(p\)</span>-value for a <span class="math inline">\(t\)</span>-test of the hypothesis that the intercept is zero. Save the result to <tt>p_int</tt></li>
<li>Compute the <span class="math inline">\(p\)</span>-value for a <span class="math inline">\(t\)</span>-test of the hypothesis that the coefficient of <tt>STR</tt> is zero. Save the result to <tt>p_STR</tt></li>
</ul>
<p><strong>Hint:</strong> both hypotheses can be tested individually using a two-sided test. Use <tt>pnorm()</tt> to obtain cumulated probabilities for standard normally distributed outcomes, see <tt>?pnorm</tt></p>


<div data-datacamp-exercise data-lang="r">

  <code data-type="sample-code">
  # Compute the p-value for the first significance test and save it to p_int


  # Compute the p-value for the second significance test and save it to p_cs
  
  
  </code>
  <code data-type="solution">
  t_int <- 567.43/23.9606
  p_int <- 2*(1-pnorm(abs(t_int)))
  t_STR <- 7.15/0.8536
  p_STR <- 2*(1-pnorm(abs(t_STR)))
  </code>
  <code data-type="sct">
  test_object("p_int")
  test_object("p_STR")
  </code>
  
</div>


</div>
<div class="DCexercise">
<h4 id="two-null-hypotheses-you-cannot-reject-can-you" class="unnumbered">2. Two Null Hypotheses You Cannot Reject, Can You?</h4>
<p><span class="math display">\[\widehat{TestScore} = \underset{(23.96)}{567.43} - \underset{(0.85)}{7.15} \times STR, \, R^2 = 0.8976, \,SER=15.19\]</span></p>
<p>Can you reject the null hypotheses discussed in the previous code exercise using individual <span class="math inline">\(t\)</span>-tests at the <span class="math inline">\(5\%\)</span> significance level?</p>
<p>The variables <tt>t_int</tt> and <tt>t_STR</tt> are the <span class="math inline">\(t\)</span>-statistics. Both are available in your working environment.</p>
<p><strong>Instructions</strong></p>
<ul>
<li>Gather <tt>t_int</tt> and <tt>t_STR</tt> in a vector <tt>test</tt> and use logical operators to check whether the corresponding rejection rule applies.</li>
</ul>
<p><strong>Hints:</strong></p>
<ul>
<li>Both tests are two-sided <span class="math inline">\(t\)</span>-tests. Key Concept 5.2 recaps how a two-sided <span class="math inline">\(t\)</span>-test is conducted.</li>
<li>Use <tt>qnorm()</tt> to obtain normal critical values.</li>
</ul>


<div data-datacamp-exercise data-lang="r">

  <code data-type="pre-exercise-code">
  t_int <- 567.43/23.9606
  t_STR <- 7.15/0.8536
  </code>
  <code data-type="sample-code">
  # check whether the t-tests reject
  
  
  </code>
  <code data-type="solution">
  test <- c(t_int, t_STR)
  # entry is `TRUE` if a test rejects
  abs(test) >= qnorm(0.95)
  </code>

  <code data-type="sct">
  test_or({
    test <- c(t_int,t_STR)
  },{
    test <- c(t_STR, t_int)
  })
  test_or({
    test_student_typed("abs(test) >= qnorm(0.95)")
  },{
    test_student_typed("abs(test) <= qnorm(0.95)")
  })
  </code>
  
</div>


</div>
<div class="DCexercise">
<h4 id="confidence-intervals" class="unnumbered">3. Confidence Intervals</h4>
<p><tt>mod</tt>, an object of class <tt>lm</tt> which contains the estimated model <span class="math display">\[\widehat{TestScore} = \underset{(23.96)}{567.43} - \underset{(0.85)}{7.15} \times STR, \, R^2 = 0.8976, \,SER=15.19\]</span> is available in your working environment.</p>
<p><strong>Instructions</strong></p>
<ul>
<li>Compute <span class="math inline">\(90\%\)</span> confidence intervals for both coefficients.</li>
</ul>
<p><strong>Hints:</strong></p>
<p>Use the function <tt>confint()</tt>, see <tt>?confint</tt>. The argument <tt>level</tt> sets the confidence level to be used.</p>


<div data-datacamp-exercise data-lang="r">

  <code data-type="pre-exercise-code">
    STR <- c(23, 19, 30, 22, 23, 29, 35, 36, 33, 25)
    TS <- c(430, 430, 333, 410, 390, 377, 325, 310, 328, 375)
    mod <- lm(TS ~ STR)
  </code>
  <code data-type="sample-code">
  # compute 90% confidence intervals for the model coefficients
  
  
  </code>
  <code data-type="solution">
  confint(mod, level = 0.9)
  </code>

  <code data-type="sct">
  test_function("confint", args = c("object","level"))
  </code>
  
</div>


</div>
<div class="DCexercise">
<h4 id="a-confidence-interval-for-the-mean-i" class="unnumbered">4. A Confidence Interval for the Mean I</h4>
<p>Consider the model <span class="math display">\[Y_i = \beta_1 + u_i\]</span> where <span class="math inline">\(Y_i \sim \mathcal{N}(\mu, \sigma^2)\)</span>. Following the discussion preceding equation <a href="cifrc.html#eq:KI">(2.1)</a>, a <span class="math inline">\(95\%\)</span> confidence interval for the mean of the <span class="math inline">\(Y_i\)</span> can be computed as</p>
<p><span class="math display">\[KI^{\mu}_{0.95} = \left[\hat\mu - 1.96 \times \frac{\sigma}{\sqrt{n}} \, \ \hat\mu + 1.96 \times \frac{\sigma}{\sqrt{n}} \right].\]</span></p>
<p><strong>Instructions</strong></p>
<ul>
<li>Sample <span class="math inline">\(n=100\)</span> observations from a normal distribution with variance <span class="math inline">\(100\)</span> and mean <span class="math inline">\(10\)</span>.</li>
<li>Use the sample to estimate <span class="math inline">\(\beta_1\)</span>. Save the estimate in <tt>mu_hat</tt>.</li>
<li>Assume that <span class="math inline">\(\sigma^2 = 100\)</span> is known. Replace the zeros in the code below to obtain a <span class="math inline">\(95\%\)</span> confidence interval for the mean of the <span class="math inline">\(Y_i\)</span>.</li>
</ul>
<p><strong>Hints:</strong></p>
<p>Use the function <tt>confint()</tt>, see <tt>?confint</tt>. The argument <tt>level</tt> sets the confidence level to be used.</p>


<div data-datacamp-exercise data-lang="r">

  <code data-type="sample-code">
  # random seed for reproducibility
  set.seed(1)
  
  
  # sample the observations
  
  
  # estimate the mean, assign the estimate to `mu_hat`
  
  
  # compute the 95% confidence interval using the formula above
  CI <- c(
    "lower" = 0,
    "upper" = 0
  )
  
  </code>
  <code data-type="solution">
  set.seed(1)
  mu_hat <- mean(rnorm(100, mean = 10, sd = 10))
  CI <- c(
   "lower" = mu_hat - 1.96,
   "upper" = mu_hat + 1.96
  )
  </code>
  test_object("CI")
  <code data-type="sct">
  test_object("mu_hat")
  test_object("CI")
  </code>
  
</div>


</div>
<div class="DCexercise">
<h4 id="a-confidence-interval-for-the-mean-ii" class="unnumbered">5. A Confidence Interval for the Mean II</h4>
<p>For historical reasons, some <tt>R</tt> functions that we use to obtain statistical inference on model parameters, among them <tt>confint()</tt> and <tt>summary()</tt>, rely on the <span class="math inline">\(t\)</span>-distribution instead of using the large-sample normal approximation. This is why for small sample sizes (and hence small degrees of freedom), <span class="math inline">\(p\)</span>-values and confidence intervals reported by these functions deviate from those computed using critical values or cumulative probabilities of the standard normal distribution.</p>
<p>The <span class="math inline">\(95\%\)</span> confidence interval for the mean in the previous exercise is <span class="math inline">\([9.128874, 13.048874]\)</span>.</p>
<p>100 observations sampled from a normal distribution with <span class="math inline">\(\mu=10\)</span> and <span class="math inline">\(\sigma^2=100\)</span> have been assigned to the vector <tt>s</tt> which is available in your environment.</p>
<p><strong>Instructions</strong></p>
<ul>
<li>Set up a suitable regression model to estimate the mean of the observations in <tt>s</tt>. Then use <tt>confint()</tt> to compute a <span class="math inline">\(95\%\)</span> confidence interval for the mean.</li>
</ul>
<p>(Check that the result is different from the interval reported above.)</p>


<div data-datacamp-exercise data-lang="r">

  <code data-type="pre-exercise-code">
  set.seed(1); s <- rnorm(100, mean = 10, sd = 10)
  </code>
  <code data-type="sample-code">
  # use a regression to obtain an estimate of the mean
  
  
  # compute the 95% CI
  
  
  </code>
  <code data-type="solution">
  set.seed(1)
  confint(lm(s ~ 1))
  </code>
  <code data-type="sct">
  test_predefined_objects("s")
  test_output_contains("confint(lm(s ~ 1))")
  </code>
  
</div>


</div>
<div class="DCexercise">
<h4 id="regression-on-a-dummy-i" class="unnumbered">6. Regression on a Dummy I</h4>
<p>Chapter <a href="rwxiabv.html#rwxiabv">2.3</a> discusses regression when <span class="math inline">\(X\)</span> is a dummy variables where we have used a <tt>for()</tt> loop to generate a binary variable indicating whether a schooling district in the <tt>CASchools</tt> data set has a student-teacher ratio below <span class="math inline">\(20\)</span>. Though it is instructive to use a loop for this, there are ways to achieve the same with less code.</p>
<p>A <tt>data.frame</tt> <tt>DF</tt> with <span class="math inline">\(100\)</span> observations of a variable <tt>X</tt> is available in your working environment.</p>
<p><strong>Instructions</strong></p>
<ul>
<li><p>Use <tt>ifelse()</tt> to generate a binary vector <tt>dummy</tt> indicating whether the observations in <tt>X</tt> are positive.</p></li>
<li><p>Append <tt>dummy</tt> to the <tt>data.frame</tt> <tt>DF</tt>.</p></li>
</ul>


<div data-datacamp-exercise data-lang="r">

  <code data-type="pre-exercise-code">
  set.seed(1)
  DF <- <tt>data.frame</tt>("X" = rnorm(100))
  </code>
  <code data-type="sample-code">
  # generate the dummy vector `dummy` using `ifelse()`
  
  
  # append `dummy` to `DF`
  
  
  </code>
  <code data-type="solution">
  dummy <- ifelse(DF$X > 0, 1, 0)
  DF$dummy <- dummy
  </code>
  <code data-type="sct">
  test_object("dummy")
  test_function("ifelse")
  test_object("DF")
  </code>
  
</div>


</div>
<div class="DCexercise">
<h4 id="regression-on-a-dummy-ii" class="unnumbered">7. Regression on a Dummy II</h4>
<p>A <tt>data.frame</tt> <tt>DF</tt> with 100 observations on <tt>Y</tt> and the binary variable <tt>D</tt> from the previous exercise are available in your working environment.</p>
<p><strong>Instructions</strong></p>
<ul>
<li><p>Compute the group-specific sample means of the observations in <tt>Y</tt>. Save the mean of observations in <tt>Y</tt> where <tt>dummy == 1</tt> to <tt>mu_Y_D1</tt> and assign the mean of those observations with <tt>D == 0</tt> to <tt>mu_Y_D0</tt>.</p></li>
<li><p>Use <tt>lm()</tt> to regress <tt>Y</tt> on <tt>D</tt> i.e. estimate the coefficients in the model <span class="math display">\[\widehat{Y}_i = \beta_0 + \beta_1 \times D_i + u_i.\]</span></p></li>
</ul>
<p>Check that the estimates of the coefficients <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> reflect specific sample means. Can you tell which?</p>


<div data-datacamp-exercise data-lang="r">

  <code data-type="pre-exercise-code">
  set.seed(1)
  DF <- <tt>data.frame</tt>("Y" = rnorm(100))
  DF$D <- ifelse(DF$Y > 0, 1, 0)
  </code>
  <code data-type="sample-code">
  # compute group-specific sample means of `Y`
  
  
  # Regress `Y` on `D`
  
  
  </code>
  <code data-type="solution">
   mu_Y_D1 <- mean(DF$Y[DF$D ==1])
   mu_Y_D0 <- mean(DF$Y[DF$D ==0])
   lm(Y ~ dummy, data = DF)
  </code>
  <code data-type="sct">
  test_object("mu_Y_D1")
  test_object("mu_Y_D1")
  test_or(
  {
  test_function("lm", args = "formula")
  },{
  ex() %>% override_solution("lm(DF$Y ~ DF$dummy)") %>% check_function("lm") %>% check_arg("formula")
  }
  )
  </code>
  
</div>


</div>
<div class="DCexercise">
<h4 id="regression-on-a-dummy-iii" class="unnumbered">8. Regression on a Dummy III</h4>
<p>In this exercise, you have to visualize some of the results from the dummy regression model <span class="math display">\[\widehat{Y}_i = -0.66 + 1.43 \times D_i\]</span> estimated in the previous exercise.</p>
<p>A <tt>data.frame</tt> <tt>DF</tt> with 100 observations on <tt>X</tt> and the binary variable <tt>dummy</tt> as well as the model object <tt>dummy_mod</tt> from the previous exercise are available in your working environment.</p>
<p><strong>Instructions</strong></p>
<ul>
<li><p>Start by drawing a visually appealing plot of the observations on <span class="math inline">\(Y\)</span> and <span class="math inline">\(D\)</span> based on the code chunk provided in <tt>Script.R</tt>. Replace the <tt>???</tt> by the correct expressions!</p></li>
<li><p>Add the regression line to the plot.</p></li>
</ul>


<div data-datacamp-exercise data-lang="r">

  <code data-type="pre-exercise-code">
  set.seed(1)
  DF <- <tt>data.frame</tt>("Y" = rnorm(100))
  DF$D <- ifelse(DF$Y > 0, 1, 0)
  dummy_mod <- lm(Y ~ D, data = DF)
  </code>
  <code data-type="sample-code">
  # Replace the `???` by the correct values
  plot(x = ??? , y = ???, 
     pch = 20, 
     cex = 1,
     col = "Steelblue",
     xlab = expression(D[i]), ylab = "Test Score",
     main = "Dummy Regression"
     )
  
  # add the regression line   
  
  </code>
  <code data-type="solution">
  plot(x = DF$D , y = DF$Y, 
     pch = 20, 
     cex = 1,
     col = "Steelblue",
     xlab = expression(D[i]), ylab = "Test Score",
     main = "Dummy Regression"
    )  
    abline(dummy_mod)
  </code>
  <code data-type="sct">
  test_predefined_objects(c("DF","dummy_mod"))
  test_function("abline")
  test_function("plot", args = c("x","y"))
  success_msg("Nice! Clearly, a line is not a suitable way to think of this model!")
  </code>
  
</div>


</div>
<div class="DCexercise">
<h4 id="gender-wage-gap-i" class="unnumbered">9. Gender Wage Gap I</h4>
<p><tt>CPS1985</tt> is a cross-section data set originating from the May 1985 <em>Current Population Survey</em> by the <em>US Census Bureau</em> and, among others things, contains observations on wage and gender of employees.</p>
<p><tt>CPS1985</tt> is part of the package <tt>AER</tt>.</p>
<p><strong>Instructions</strong></p>
<ul>
<li><p>Load the package <tt>AER</tt> and attach the data set <tt>CPS1985</tt>.</p></li>
<li><p>Estimate the dummy regression model <span class="math display">\[wage_i = \beta_0 + \beta_1 \cdot female_i + u_i\]</span> where</p>
<span class="math display">\[\begin{align*}
  female = 
  \begin{cases}
    1, &amp; \text{if employee is female} \\
    0, &amp; \text{if employee is male}.
  \end{cases}
\end{align*}\]</span>
<p>Save the result in <tt>wage_mod</tt>.</p></li>
</ul>


<div data-datacamp-exercise data-lang="r">

  <code data-type="sample-code">
  # Load the package and attach the data set
  
  
  # Perform the regression
  
  
  </code>
  <code data-type="solution">
  library(AER)
  data(CPS1985)
  dummy_mod <- lm(wage ~ gender, data = CPS1985)
  </code>
  <code data-type="sct">
  test_function("library")
  test_function("data")
  test_or({
    ex() %>% override_solution("attach(CPS1985); dummy_mod <- lm(wage ~ gender)") %>% check_object("dummy_mod")
  },{
    ex() %>% override_solution("dummy_mod <- lm(CPS1985$wage ~ CPS1985$gender)") %>% check_object("dummy_mod")
  },{
    ex() %>% override_solution("dummy_mod <- lm(wage ~ gender, data = CPS1985)") %>% check_object("dummy_mod")
  }
  )
  success_msg("Well done!")
  </code>
  
</div>


</div>
<div class="DCexercise">
<h4 id="gender-wage-gap-ii" class="unnumbered">10. Gender Wage Gap II</h4>
<p>The wage regression from the previous exercise yields <span class="math display">\[\widehat{wage}_i = 9.995 - 2.116 \cdot female_i.\]</span></p>
<p>The model object <tt>dummy_mod</tt> is available in your working environment.</p>
<p><strong>Instructions:</strong></p>
<ul>
<li>Test the hypothesis that the coefficient on <span class="math inline">\(female_i\)</span> is zero. This would imply that there is no gender wage gap. Use the heteroskedasticity-robust estimator proposed by <span class="citation">White (<a href="#ref-white1980">1980</a>)</span>.</li>
</ul>
<p><strong>Hint:</strong></p>
<ul>
<li><p><tt>vcovHC()</tt> computes heteroskedasticity-robust estimates of the covariance matrix of the coefficient estimators for the model supplied, see <tt>?vcovHC</tt>.</p></li>
<li><p><tt>coeftest()</tt> performs significance tests for the coefficients in model objects. A covariance matrix can be supplied using the argument <tt>vcov.</tt>.</p></li>
</ul>


<div data-datacamp-exercise data-lang="r">
  
  <code data-type="pre-exercise-code">
    library(AER)
    data(CPS1985)
    dummy_mod <- lm(wage ~ gender, data = CPS1985)
  </code>
  <code data-type="sample-code">
  # test whether the gender gap is significantly different from zero 
  # use robust standard errors
  
  
  </code>
  <code data-type="solution">
  coeftest(dummy_mod, vcov. = vcovHC(dummy_mod, type = "HC0"))
  # or
  linearHypothesis(dummy_mod, "genderfemale=0", vcov. = vcovHC(dummy_mod, type = "HC0"))
  </code>
  <code data-type="sct">
  test_predefined_objects("dummy_mod")
  test_or({
    test_function("coeftest", args = c("x", "vcov.")) 
  },{
    test_function("linearHypothesis", args = c("model", "vcov.", "hypothesis.matrix"))
  },{
    f <- ex() %>% override_solution("linearHypothesis(dummy_mod, "genderfemale", vcov. = vcovHC(dummy_mod, type = "HC0"))") %>% check_function("linearHypothesis")
    f %>% check_arg("model")
    f %>% check_arg("vcov.")
    f %>% check_arg("hypothesis.matrix")
  })
  success_msg("Right! The hypothesis that there is no wage gap is rejected at any common level.")
  </code>
  
</div>


</div>
<div class="DCexercise">
<h4 id="heteroskedasticity-robust-standard-errors" class="unnumbered">11. Heteroskedasticity-Robust Standard Errors</h4>
<p>In the simple regression model, the covariance matrix of the coefficient estimators is denoted</p>
<span class="math display">\[\begin{equation}
\text{Var}
  \begin{pmatrix}
    \hateta_0 \
    \hateta_1
  \end{pmatrix} = 
\begin{pmatrix}
  \text{Var}(\hat\beta_0) &amp; \text{Cov}(\hat\beta_0,\hat\beta_1) \\
    ext{Cov}(\hat\beta_0,\hat\beta_1) &amp; \text{Var}(\hateta_1)
\end{pmatrix}
\end{equation}\]</span>
<p>The function <tt>vcovHC</tt> can be used to obtain estimates of this matrix for a model object of interest.</p>
<p><tt>gender_mod</tt>, a model object containing the wage regression dealt with in Exercises 9 and 10 is available in your working environment.</p>
<p><strong>Instructions</strong></p>
<ul>
<li>Compute robust standard errors of the type <tt>HC0</tt> for the coefficients estimators in the model object <tt>gender_mod</tt>. Store the standard errors in a vector named <tt>rob_SEs</tt>.</li>
</ul>
<p><strong>Hint:</strong></p>
<ul>
<li><p>The standard errors we seek can be obtained by taking the square root of the diagonal elements of the estimated covariance matrix.</p></li>
<li><p><tt>diag(A)</tt> returns the diagonal elements of the matrix <tt>A</tt>.</p></li>
</ul>


<div data-datacamp-exercise data-lang="r">
  
  <code data-type="pre-exercise-code">
    library(AER)
    data(CPS1985)
    dummy_mod <- lm(wage ~ gender, data = CPS1985)
  </code>
  <code data-type="sample-code">
  # compute robust standard errors and save them in rob_SEs
  
  
  </code>
  <code data-type="solution">
  rob_SEs <- sqrt(diag(vcovHC(dummy_mod, type = "HC0")))
  </code>
  <code data-type="sct">
  test_predefined_objects("dummy_mod")
  test_object("rob_SEs")
  success_msg("Nice! ")
  </code>
  
</div>


</div>
<div class="DCexercise">
<h4 id="robust-confidence-intervals" class="unnumbered">12. Robust Confidence Intervals</h4>
<p>The function <tt>confint()</tt> computes confidence intervals for regression models using homoskedasticity-only standard errors such that this function is not an option when there is heteroskedasticity.</p>
<p>The function <tt>Rob_CI()</tt> is meant to compute and report heteroskedasticity-robust confidence intervals for both model coefficients in a simple regression model.</p>
<p><tt>gender_mod</tt>, a model object containing the wage regression dealt with in the previous exercises is available in your working environment.</p>
<p><strong>Instructions</strong></p>
<ul>
<li><p>Complete the code of <tt>Rob_CI()</tt> given in <tt>Script.R</tt> such that lower and upper bounds of <span class="math inline">\(95\%\)</span> confidence intervals are returned.</p></li>
<li><p>Use the function to obtain <span class="math inline">\(95\%\)</span> confidence intervals for the model coefficients in <tt>dummy_mod</tt>.</p></li>
</ul>


<div data-datacamp-exercise data-lang="r">
  
  <code data-type="pre-exercise-code">
    library(AER)
    data(CPS1985)
    dummy_mod <- lm(wage ~ gender, data = CPS1985)
  </code>
  <code data-type="sample-code">
  # complete the function below
  
  Rob_CI <- function(model) {
    SEs <- ???
    lower <- model$coef - ???
    upper <- model$coef + ???
    return(
      cbind("Lower" = lower, "Upper" = upper)
    )
  }
  
  </code>
  <code data-type="solution">
    Rob_CI <- function(model) {
    SEs <- sqrt(diag(vcovHC(model, type = "HC0")))
    lower <- model$coef - 1.96 * SEs
    upper <- model$coef + 1.96 * SEs
    return(
      cbind("Lower" = lower, "Upper" = upper)
    )
  }
  </code>
  <code data-type="sct">
  test_function_definition("Rob_CI",
                         function_test = test_expression_result("Rob_CI(dummy_mod)"))
  test_output_contains("Rob_CI(dummy_mod)")
  success_msg("Nice!")
  </code>
  
</div>


</div>
<div class="DCexercise">
<h4 id="a-small-simulation-study-i" class="unnumbered">13. A Small Simulation Study I</h4>
Consider the data generating process
<span class="math display">\[\begin{align*}
  X_i \sim&amp; \, \mathcal{U}[2,10],\\
  e_i \sim&amp; \, N(0, X_i),\\
  Yi =&amp; \, \beta_1 X_i + e_i  
\end{align*}\]</span>
<p>where <span class="math inline">\(\mathcal{U}[0,10]\)</span> denotes the uniform distribution on the interval <span class="math inline">\([0,10]\)</span> and <span class="math inline">\(\beta_1=2\)</span>.</p>
<p>Notice that the errors <span class="math inline">\(e_i\)</span> are heteroskedastic since the variance is a linear function of <span class="math inline">\(X_i\)</span>.</p>
<p><strong>Instructions</strong></p>
<ul>
<li>Write a function <tt>DGP_OLS</tt> that generates a sample <span class="math inline">\((X_i,Y_i)\)</span>, <span class="math inline">\(i=1,…,100\)</span> and returns the OLS estimate of <span class="math inline">\(eta_1\)</span>.</li>
</ul>
<p><strong>Hints</strong></p>
<p><tt>runif()</tt> can be used to obtain random samples form a uniform distribution, see <tt>?runif</tt></p>


<div data-datacamp-exercise data-lang="r">
  
  <code data-type="pre-exercise-code">

  </code>
  <code data-type="sample-code">
  # write the function
  </code>
  <code data-type="solution">
  set.seed(1)
  # write the function
  DGP_OLS <- function() {
  X <- runif(100,2,10)
  Y <- X + rnorm(100, sd = sqrt(X))
  return(
    c("beta_1_hat" = sum(X*Y)/sum(X^2))
  )
  }
  </code>
  <code data-type="sct">
  test_function_definition("DGP_OLS", 
                           function_test =
                           test_expression_result("DGP_OLS()")
  )
  success_msg("Well Done!")
  </code>
  
</div>


</div>
<div class="DCexercise">
<h4 id="a-small-simulation-study-ii" class="unnumbered">14. A Small Simulation Study II</h4>
<p>The function <tt>DGP_OLS()</tt> from the previous exercise is available in your working environment.</p>
<p><strong>Instructions</strong></p>
<ul>
<li><p>Use <tt>replicate()</tt> to generate a sample of <span class="math inline">\(1000\)</span> OLS estimates <span class="math inline">\(\widehat{\beta}_1\)</span> using the function <tt>DGP_OLS</tt>. Store the estimates in a vector named <tt>estimates</tt>.</p></li>
<li><p>Estimate the variance of the OLS estimates. Store the result in <tt>est_var_OLS</tt>.</p></li>
</ul>


<div data-datacamp-exercise data-lang="r">
  
  <code data-type="pre-exercise-code">
  DGP_OLS <- function() {
    X <- runif(100,2,10)
    Y <- X + rnorm(100, sd = sqrt(X))
    return(
      c("beta_1_hat" = sum(X*Y)/sum(X^2))
    )
    }
  </code>
  <code data-type="sample-code">
  set.seed(1)
  # Generate 1000 estimates of beta_1 using "GDP_OLS()", store them in "estimates"


  # Estimate the variance of the estimates
  
  
  </code>
  <code data-type="solution">
  set.seed(1)
  # Generate 1000 estimates of beta_1 using "GDP_OLS()", store them in "estimates"
  estimates <- replicate(1000, DGP_OLS())
  # Estimate the variance of the estimates
  est_var_OLS <- var(estimates)
  </code>
  <code data-type="sct">
  test_predefined_objects("DGP_OLS")
  test_object("estimates")
  test_object("est_var_OLS")
  </code>
  
</div>


</div>
<div class="DCexercise">
<h4 id="a-small-simulation-study-iii" class="unnumbered">15. A Small Simulation Study III</h4>
<p>The Gauss-Markov Theorem states that the OLS estimator in linear regression models is no longer the most efficient estimator (in the sense of minimum variance) among the conditionally unbiased linear estimators, that is, the OLS estimator loses the BLUE property, under heteroskedasticity.</p>
<p>It turns out that OLS applied to the weighted observations <span class="math inline">\((w_i X_i, w_i Y_i)\)</span> where <span class="math inline">\(w_i=\frac{1}{\sigma_i}\)</span> yields the BLUE estimator under heteroskedasticity. This estimator is called the <em>weighted least squares</em> (WLS) estimator so that its variance is smaller than the variance of the OLS estimator.</p>
<p>The function <tt>DGP_OLS()</tt> and the estimated variance <tt>est_var_OLS</tt> from the previous exercises are available in your working environment.</p>
<p><strong>Instructions</strong></p>
<ul>
<li><p>Write a function <tt>DGP_WLS()</tt> that generates <span class="math inline">\(100\)</span> samples using the DGP introduced in Exercise 13 and returns the WLS estimate of <span class="math inline">\(\beta_1\)</span>. Treat <span class="math inline">\(\sigma_i\)</span> as known, i.e. set <span class="math inline">\(w_i=\frac{1}{X_i}\)</span>.</p></li>
<li><p>Repeat exercise 14 using <tt>DGP_WLS()</tt>. Store the estimated variance in <tt>est_var_GLS</tt>.</p></li>
<li><p>Compare the estimated variances <tt>est_var_OLS</tt> and <tt>est_var_GLS</tt> using logical operators (<tt>&lt;</tt> or <tt>&gt;</tt>).</p></li>
</ul>
<p><strong>Hints</strong></p>
<ul>
<li><p><tt>DGP_WLS()</tt> can be obtained using a modified code of <tt>DGP_OLS()</tt>.</p></li>
<li><p>Remember that functions are objects and you may print the code of a function to the console.</p></li>
</ul>


<div data-datacamp-exercise data-lang="r">
  
  <code data-type="pre-exercise-code">
  set.seed(1)
  DGP_OLS <- function() {
    X <- runif(100,2,10)
    Y <- X + rnorm(100, sd = sqrt(X))
    return(
      c("beta_1_hat" = sum(X*Y)/sum(X^2))
    )
  }
  estimates <- replicate(1000, DGP_OLS())
  est_var_OLS <- var(estimates)
  </code>
  <code data-type="sample-code">
  set.seed(1)
  # Define the function "DGP_GLS()"
  
  
  # estimate the variance, assign the value to "var_est_GLS"
  
  
  # compare the estimated variances
  
  
  </code>
  <code data-type="solution">
  set.seed(1)
  # Define the function "DGP_GLS()"
  DGP_GLS <- function() {
  X <- runif(100,2,10)
  Y <- X + rnorm(100, sd = sqrt(X))
  w <- 1/sqrt(X)
  return(
    c("beta_1_hat" = sum(w^2*X*Y)/sum((w*X)^2))
  )
  }
  # estimate the variance, assign the value to "var_est_GLS"
  est_var_GLS <- var(replicate(1000, DGP_GLS()))

  # compare the estimated variances
  est_var_GLS < est_var_OLS
  </code>
  <code data-type="sct">
  test_predefined_objects(c("DGP_OLS","est_var_OLS"))
  test_function_definition("DGP_GLS",
                           function_test =
                           test_expression_result("DGP_OLS()")
  
  )
  test_object("est_var_GLS")
  test_or({
    test_student_typed("est_var_GLS < est_var_OLS")
  },{
    test_student_typed("est_var_GLS > est_var_OLS")
  },{
    test_student_typed("est_var_OLS > est_var_GLS")
  },{
    test_student_typed("est_var_OLS < est_var_GLS")
  })
  success_msg("Nice! This shows that the GLS estimator indeed has lower variance than OLS.")
  </code>
  
</div>


</div>

<div id="refs" class="references">
<div>
<p>Allaire, J., Xie, Y., McPherson, J., Luraschi, J., Ushey, K., Atkins, A., … Chang, W. (2018). <em>Rmarkdown: Dynamic documents for r</em>. Retrieved from <a href="https://CRAN.R-project.org/package=rmarkdown" class="uri">https://CRAN.R-project.org/package=rmarkdown</a></p>
</div>
<div>
<p>Heiss, F. (2016). <em>Using r for introductory econometrics</em>. CreateSpace Independent Publishing Platform.</p>
</div>
<div>
<p>Kleiber, C., &amp; Zeileis, A. (2008). <em>Applied econometrics with r</em>. Springer.</p>
</div>
<div>
<p>R Core Team. (2018). <em>R: A language and environment for statistical computing</em>. Vienna, Austria: R Foundation for Statistical Computing. Retrieved from <a href="https://www.R-project.org/" class="uri">https://www.R-project.org/</a></p>
</div>
<div>
<p>Stock, J., &amp; Watson, M. (2015). <em>Introduction to econometrics, third update, global edition</em>. Pearson Education Limited.</p>
</div>
<div>
<p>White, H. (1980). A heteroskedasticity-consistent covariance matrix estimator and a direct test for heteroskedasticity. <em>Econometrica</em>, <em>48</em>(4), pp. 817–838.</p>
</div>
<div>
<p>Wooldridge, J. (2016). <em>Introductory econometrics</em> (Sixth). Cengage Learning.</p>
</div>
<div>
<p>Xie, Y. (2018). <em>Knitr: A general-purpose package for dynamic report generation in r</em>. Retrieved from <a href="https://CRAN.R-project.org/package=knitr" class="uri">https://CRAN.R-project.org/package=knitr</a></p>
</div>
</div>
</div>
<!-- </div> -->








<h3>References</h3>
<div id="refs" class="references">
<div id="ref-white1980">
<p>White, H. (1980). A heteroskedasticity-consistent covariance matrix estimator and a direct test for heteroskedasticity. <em>Econometrica</em>, <em>48</em>(4), pp. 817–838.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="using-the-t-statistic-in-regression-when-the-sample-size-is-small.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 1
},
"edit": null,
"download": ["URFITE.pdf", "URFITE.epub"],
"toc": {
"collapse": "subsection",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
