<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Using R for Introduction to Econometrics</title>
  <meta name="description" content="Using R for Introduction to Econometrics">
  <meta name="generator" content="bookdown 0.5 and GitBook 2.6.7">

  <meta property="og:title" content="Using R for Introduction to Econometrics" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="Emwikts1970/URFITE-Bookdown" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Using R for Introduction to Econometrics" />
  
  
  

<meta name="author" content="Christoph Hanck, Martin Arnold, Alexander Gerber and Martin Schmelzer">


<meta name="date" content="2017-11-08">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="regression-models-with-multiple-regressors.html">
<link rel="next" href="nonlinear-regression-functions.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-0.9/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.7.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="libs/plotlyjs-1.29.2/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotlyjs-1.29.2/plotly-latest.min.js"></script>
<script src="js/hideOutput.js"></script>
<script type="text/javascript" src="MathJax-2.7.2/MathJax.js?config=default"></script>

 <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        extensions: ["tex2jax.js", "TeX/AMSmath.js"],
        tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
        jax: ["input/TeX","output/SVG"]
      });
      MathJax.Hub.processSectionDelay = 0;
  </script>

<!-- <script src="js/d3.v3.min.js"></script> 
<script src="js/leastsquares.js"></script>
<script src="js/d3functions.js"></script>
<script src="d3.slider.js"></script>
<script src="slrm.js"></script> -->


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; background-color: #f8f8f8; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
pre, code { background-color: #f8f8f8; }
code > span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code > span.dt { color: #204a87; } /* DataType */
code > span.dv { color: #0000cf; } /* DecVal */
code > span.bn { color: #0000cf; } /* BaseN */
code > span.fl { color: #0000cf; } /* Float */
code > span.ch { color: #4e9a06; } /* Char */
code > span.st { color: #4e9a06; } /* String */
code > span.co { color: #8f5902; font-style: italic; } /* Comment */
code > span.ot { color: #8f5902; } /* Other */
code > span.al { color: #ef2929; } /* Alert */
code > span.fu { color: #000000; } /* Function */
code > span.er { color: #a40000; font-weight: bold; } /* Error */
code > span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #000000; } /* Constant */
code > span.sc { color: #000000; } /* SpecialChar */
code > span.vs { color: #4e9a06; } /* VerbatimString */
code > span.ss { color: #4e9a06; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #000000; } /* Variable */
code > span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code > span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code > span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code > span.ex { } /* Extension */
code > span.at { color: #c4a000; } /* Attribute */
code > span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code > span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">URFITE</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a></li>
<li class="chapter" data-level="2" data-path="probability-theory.html"><a href="probability-theory.html"><i class="fa fa-check"></i><b>2</b> Probability Theory</a><ul>
<li class="chapter" data-level="" data-path="probability-theory.html"><a href="probability-theory.html#random-variables-and-probability-distributions"><i class="fa fa-check"></i>Random Variables and Probability Distributions</a><ul>
<li class="chapter" data-level="" data-path="probability-theory.html"><a href="probability-theory.html#probability-distributions-of-discrete-random-variables"><i class="fa fa-check"></i>Probability Distributions of Discrete Random Variables</a></li>
<li class="chapter" data-level="" data-path="probability-theory.html"><a href="probability-theory.html#bernoulli-trials"><i class="fa fa-check"></i>Bernoulli Trials</a></li>
<li class="chapter" data-level="" data-path="probability-theory.html"><a href="probability-theory.html#expected-values-mean-and-variance"><i class="fa fa-check"></i>Expected Values, Mean and Variance</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="probability-theory.html"><a href="probability-theory.html#probability-distributions-of-continuous-random-variables"><i class="fa fa-check"></i>Probability Distributions of Continuous Random Variables</a><ul>
<li class="chapter" data-level="" data-path="probability-theory.html"><a href="probability-theory.html#the-normal-distribution"><i class="fa fa-check"></i>The Normal Distribution</a></li>
<li class="chapter" data-level="" data-path="probability-theory.html"><a href="probability-theory.html#the-chi-squared-distribution"><i class="fa fa-check"></i>The Chi-Squared Distribution</a></li>
<li><a href="probability-theory.html#thetdist">The Student <span class="math inline">\(t\)</span> Distribution</a></li>
<li><a href="probability-theory.html#the-f-distribution">The <span class="math inline">\(F\)</span> Distribution</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="probability-theory.html"><a href="probability-theory.html#random-sampling-and-the-distribution-of-sample-averages"><i class="fa fa-check"></i>Random Sampling and the Distribution of Sample Averages</a><ul>
<li class="chapter" data-level="" data-path="probability-theory.html"><a href="probability-theory.html#mean-and-variance-of-the-sample-mean"><i class="fa fa-check"></i>Mean and Variance of the Sample Mean</a></li>
<li class="chapter" data-level="" data-path="probability-theory.html"><a href="probability-theory.html#large-sample-approximations-to-sampling-distributions"><i class="fa fa-check"></i>Large Sample Approximations to Sampling Distributions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="a-review-of-statistics-using-r.html"><a href="a-review-of-statistics-using-r.html"><i class="fa fa-check"></i><b>3</b> A Review of Statistics using R</a><ul>
<li class="chapter" data-level="" data-path="a-review-of-statistics-using-r.html"><a href="a-review-of-statistics-using-r.html#estimation-of-the-population-mean"><i class="fa fa-check"></i>Estimation of the Population Mean</a></li>
<li class="chapter" data-level="" data-path="a-review-of-statistics-using-r.html"><a href="a-review-of-statistics-using-r.html#properties-of-the-population-mean"><i class="fa fa-check"></i>Properties of the Population Mean</a></li>
<li class="chapter" data-level="" data-path="a-review-of-statistics-using-r.html"><a href="a-review-of-statistics-using-r.html#hypothesis-tests-concerning-the-population-mean"><i class="fa fa-check"></i>Hypothesis Tests Concerning the Population Mean</a><ul>
<li><a href="a-review-of-statistics-using-r.html#p-value"><span class="math inline">\(p\)</span>-Value</a></li>
<li><a href="a-review-of-statistics-using-r.html#calculating-the-p-value-when-sigma_y-is-known">Calculating the <span class="math inline">\(p\)</span>-Value When <span class="math inline">\(\sigma_Y\)</span> Is Known</a></li>
<li class="chapter" data-level="" data-path="a-review-of-statistics-using-r.html"><a href="a-review-of-statistics-using-r.html#sample-variance-sample-standard-deviation-and-standard-error"><i class="fa fa-check"></i>Sample Variance, Sample Standard Deviation and Standard Error</a></li>
<li><a href="a-review-of-statistics-using-r.html#calculating-the-p-value-when-sigma_y-is-unknown">Calculating the <span class="math inline">\(p\)</span>-value When <span class="math inline">\(\sigma_Y\)</span> is Unknown</a></li>
<li><a href="a-review-of-statistics-using-r.html#the-t-statistic">The <span class="math inline">\(t\)</span>-statistic</a></li>
<li class="chapter" data-level="" data-path="a-review-of-statistics-using-r.html"><a href="a-review-of-statistics-using-r.html#hypothesis-testing-with-a-prespecified-significance-level"><i class="fa fa-check"></i>Hypothesis Testing with a Prespecified Significance Level</a></li>
<li class="chapter" data-level="" data-path="a-review-of-statistics-using-r.html"><a href="a-review-of-statistics-using-r.html#one-sided-alternatives"><i class="fa fa-check"></i>One-sided Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="a-review-of-statistics-using-r.html"><a href="a-review-of-statistics-using-r.html#confidence-intervals-for-the-population-mean"><i class="fa fa-check"></i>Confidence intervals for the Population Mean</a></li>
<li class="chapter" data-level="" data-path="a-review-of-statistics-using-r.html"><a href="a-review-of-statistics-using-r.html#comparing-means-from-different-populations"><i class="fa fa-check"></i>Comparing Means from Different Populations</a></li>
<li class="chapter" data-level="" data-path="a-review-of-statistics-using-r.html"><a href="a-review-of-statistics-using-r.html#an-application-to-the-gender-gap-of-earnings"><i class="fa fa-check"></i>An Application to the Gender Gap of Earnings</a></li>
<li class="chapter" data-level="" data-path="a-review-of-statistics-using-r.html"><a href="a-review-of-statistics-using-r.html#scatterplots-sample-covariance-and-sample-correlation"><i class="fa fa-check"></i>Scatterplots, Sample Covariance and Sample Correlation</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="lrwor.html"><a href="lrwor.html"><i class="fa fa-check"></i><b>4</b> Linear Regression with One Regressor</a><ul>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#estimating-the-coefficients-of-the-linear-regression-model"><i class="fa fa-check"></i>Estimating the Coefficients of the Linear Regression Model</a><ul>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#the-ordinary-least-squares-estimator"><i class="fa fa-check"></i>The Ordinary Least Squares Estimator</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#measures-of-fit"><i class="fa fa-check"></i>Measures of fit</a><ul>
<li><a href="lrwor.html#the-r2">The <span class="math inline">\(R^2\)</span></a></li>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#standard-error-of-the-regression"><i class="fa fa-check"></i>Standard Error of the Regression</a></li>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#application-to-the-test-score-data"><i class="fa fa-check"></i>Application to the Test Score Data</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#the-least-squares-assumptions"><i class="fa fa-check"></i>The Least Squares Assumptions</a><ul>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#assumption-1-the-error-term-has-conditional-mean-of-zero"><i class="fa fa-check"></i>Assumption #1: The Error Term has Conditional Mean of Zero</a></li>
<li><a href="lrwor.html#assumption-2-all-x_i-y_i-are-independently-and-identically-distributed">Assumption #2: All <span class="math inline">\((X_i, Y_i)\)</span> are Independently and Identically Distributed</a></li>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#assumption-3-large-outliers-are-unlikely"><i class="fa fa-check"></i>Assumption #3: Large outliers are unlikely</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#tsdotoe"><i class="fa fa-check"></i>The Sampling Distribution of the OLS Estimator</a><ul>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#r-simulation-study-1"><i class="fa fa-check"></i>R Simulation Study 1</a></li>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#r-simulation-study-2"><i class="fa fa-check"></i>R Simulation Study 2</a></li>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#r-simulation-study-3"><i class="fa fa-check"></i>R Simulation Study 3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html"><a href="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html"><i class="fa fa-check"></i><b>5</b> Hypothesis Tests and Confidence Intervals in the Simple Linear Regression Model</a><ul>
<li><a href="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html#testing-two-sided-hypotheses-concerning-beta_1">Testing Two-Sided Hypotheses Concerning <span class="math inline">\(\beta_1\)</span></a></li>
<li class="chapter" data-level="" data-path="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html"><a href="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html#confidence-intervals-for-regression-coefficients"><i class="fa fa-check"></i>Confidence Intervals for Regression Coefficients</a><ul>
<li class="chapter" data-level="" data-path="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html"><a href="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html#r-simulation-study-5.1"><i class="fa fa-check"></i>R Simulation Study 5.1</a></li>
</ul></li>
<li><a href="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html#regression-when-x-is-a-binary-variable">Regression when <span class="math inline">\(X\)</span> is a Binary Variable</a></li>
<li class="chapter" data-level="" data-path="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html"><a href="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html#heteroskedasticity-and-homoskedasticity"><i class="fa fa-check"></i>Heteroskedasticity and Homoskedasticity</a><ul>
<li class="chapter" data-level="" data-path="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html"><a href="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html#a-real-world-example-for-heteroskedasticity"><i class="fa fa-check"></i>A Real-World Example for Heteroskedasticity</a></li>
<li class="chapter" data-level="" data-path="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html"><a href="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html#should-we-care-about-heteroskedasticity"><i class="fa fa-check"></i>Should We Care About Heteroskedasticity?</a></li>
<li class="chapter" data-level="" data-path="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html"><a href="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html#computation-of-heteroskedasticity-robust-standard-errors"><i class="fa fa-check"></i>Computation of Heteroskedasticity-Robust Standard Errors</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html"><a href="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html#the-gauss-markov-theorem"><i class="fa fa-check"></i>The Gauss-Markov Theorem</a><ul>
<li class="chapter" data-level="" data-path="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html"><a href="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html#r-simulation-study-blue-estimator"><i class="fa fa-check"></i>R Simulation Study: BLUE Estimator</a></li>
</ul></li>
<li><a href="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html#using-the-t-statistic-in-regression-when-the-sample-size-is-small">Using the <span class="math inline">\(t\)</span>-Statistic in Regression When the Sample Size Is Small</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="regression-models-with-multiple-regressors.html"><a href="regression-models-with-multiple-regressors.html"><i class="fa fa-check"></i><b>6</b> Regression Models with Multiple Regressors</a><ul>
<li class="chapter" data-level="" data-path="regression-models-with-multiple-regressors.html"><a href="regression-models-with-multiple-regressors.html#omitted-variable-bias"><i class="fa fa-check"></i>Omitted Variable Bias</a></li>
<li class="chapter" data-level="" data-path="regression-models-with-multiple-regressors.html"><a href="regression-models-with-multiple-regressors.html#the-multiple-regression-model"><i class="fa fa-check"></i>The Multiple Regression Model</a></li>
<li class="chapter" data-level="" data-path="regression-models-with-multiple-regressors.html"><a href="regression-models-with-multiple-regressors.html#measures-of-fit-in-multiple-regression"><i class="fa fa-check"></i>Measures of Fit in Multiple Regression</a></li>
<li class="chapter" data-level="" data-path="regression-models-with-multiple-regressors.html"><a href="regression-models-with-multiple-regressors.html#ols-assumptions-in-multiple-regression"><i class="fa fa-check"></i>OLS Assumptions in Multiple Regression</a><ul>
<li class="chapter" data-level="" data-path="regression-models-with-multiple-regressors.html"><a href="regression-models-with-multiple-regressors.html#multicollinearity"><i class="fa fa-check"></i>Multicollinearity</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="regression-models-with-multiple-regressors.html"><a href="regression-models-with-multiple-regressors.html#the-distribution-of-the-ols-estimators-in-multiple-regression"><i class="fa fa-check"></i>The Distribution of the OLS Estimators in Multiple Regression</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html"><a href="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html"><i class="fa fa-check"></i><b>7</b> Hypothesis Tests and Confidence intervals in Multiple Regression</a><ul>
<li class="chapter" data-level="7.1" data-path="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html"><a href="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html#hypothesis-tests-and-confidence-intervals-for-a-single-coefficient"><i class="fa fa-check"></i><b>7.1</b> Hypothesis Tests and Confidence Intervals for a Single Coefficient</a></li>
<li class="chapter" data-level="7.2" data-path="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html"><a href="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html#an-application-to-test-scores-and-the-student-teacher-ratio"><i class="fa fa-check"></i><b>7.2</b> An Application to Test Scores and the Student-Teacher Ratio</a><ul>
<li class="chapter" data-level="" data-path="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html"><a href="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html#another-augmentation-of-the-model"><i class="fa fa-check"></i>Another Augmentation of the Model</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html"><a href="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html#joint-hypothesis-testing-using-the-f-statistic"><i class="fa fa-check"></i><b>7.3</b> Joint Hypothesis Testing Using the <span class="math inline">\(F\)</span>-Statistic</a></li>
<li class="chapter" data-level="7.4" data-path="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html"><a href="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html#confidence-sets-for-multiple-coefficients"><i class="fa fa-check"></i><b>7.4</b> Confidence Sets for Multiple Coefficients</a></li>
<li class="chapter" data-level="7.5" data-path="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html"><a href="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html#model-specification-for-multiple-regression"><i class="fa fa-check"></i><b>7.5</b> Model Specification for Multiple Regression</a><ul>
<li class="chapter" data-level="" data-path="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html"><a href="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html#model-specification-in-theory-and-in-practice"><i class="fa fa-check"></i>Model Specification in Theory and in Practice</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html"><a href="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html#analysis-of-the-test-score-data-set"><i class="fa fa-check"></i><b>7.6</b> Analysis of the Test Score Data Set</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="nonlinear-regression-functions.html"><a href="nonlinear-regression-functions.html"><i class="fa fa-check"></i><b>8</b> Nonlinear Regression Functions</a><ul>
<li class="chapter" data-level="" data-path="nonlinear-regression-functions.html"><a href="nonlinear-regression-functions.html#logarithms"><i class="fa fa-check"></i>Logarithms</a></li>
<li class="chapter" data-level="8.1" data-path="nonlinear-regression-functions.html"><a href="nonlinear-regression-functions.html#interactions-between-independent-variables"><i class="fa fa-check"></i><b>8.1</b> Interactions Between Independent Variables</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Using R for Introduction to Econometrics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="hypothesis-tests-and-confidence-intervals-in-multiple-regression" class="section level1">
<h1><span class="header-section-number">7</span> Hypothesis Tests and Confidence intervals in Multiple Regression</h1>
<p>This chapter discusses methods that allow to quantify the sampling uncertainty inherent to the OLS estimator of coefficients in multiple regression models. The basis for this are standard errors, hypothesis tests and confidence intervals which, just as for the simple linear regression model, can be computed using basic <tt>R</tt> functions. We will also tackle the issue of testing joint hypothesis on coefficients of multiple regression models.</p>
<div id="hypothesis-tests-and-confidence-intervals-for-a-single-coefficient" class="section level2">
<h2><span class="header-section-number">7.1</span> Hypothesis Tests and Confidence Intervals for a Single Coefficient</h2>
<p>First, we will discuss how to compute standard errors, how to test hypotheses and how to construct confidence intervals for a single regression coefficient <span class="math inline">\(\beta_j\)</span> in a multiple regression model. The basic idea is summarized in Key Concept 7.1.</p>
<div class="keyconcept">
<h3 class="right">
Key Concept 7.1
</h3>
<h3 class="left">
Testing the Hypothesis <span class="math inline">\(\beta_j = \beta_{j,0}\)</span> <br> Against the Alternative <span class="math inline">\(\beta_j \neq \beta_{j,0}\)</span>
</h3>
<p>
<ol style="list-style-type: decimal">
<li>Compute the standard error of <span class="math inline">\(\hat{\beta_j}\)</span></li>
<li>Compute the <span class="math inline">\(t\)</span>-statistic, <span class="math display">\[t = \frac{\hat{\beta}_j - \beta_{j,0}} {SE(\hat{\beta_j})}\]</span></li>
<li>Compute the <span class="math inline">\(p\)</span>-value, <span class="math display">\[p\text{-value} = 2 \Phi(-|t^{act}|)\]</span></li>
</ol>
where <span class="math inline">\(t^{act}\)</span> is the value of the <span class="math inline">\(t\)</span>-statistic actually computed. Reject the hypothesis at the 5% significance level if the <span class="math inline">\(p\)</span>-value is less than <span class="math inline">\(0.05\)</span> or, equivalently, if <span class="math inline">\(|t^{act}| &gt; 1.96\)</span>. The standard error and (typically) the <span class="math inline">\(t\)</span>-statistic and the corresponding <span class="math inline">\(p\)</span>-value for testing <span class="math inline">\(\beta_j = 0\)</span> are computed automatically by statistical software, e.g. by <code>summary()</code>.
</p>
</div>
<p>It is straightforward to verify that principles of testing single hypothesis about the significance of coefficients in the multiple regression model are just as in in the simple regression model.</p>
<p>You can easily see this by inspecting the coefficient summary of the regression model</p>
<p><span class="math display">\[ TestScore = \beta_0 - \beta_1 \times size - \beta_2 \times english + u \]</span></p>
<p>already discussed in chapter 6. Let us review this:</p>
<div class="unfolded">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>size <span class="op">+</span><span class="st"> </span>english, <span class="dt">data =</span> CASchools)
<span class="kw">summary</span>(model)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = score ~ size + english, data = CASchools)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -48.845 -10.240  -0.308   9.815  43.461 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 686.03224    7.41131  92.566  &lt; 2e-16 ***
## size         -1.10130    0.38028  -2.896  0.00398 ** 
## english      -0.64978    0.03934 -16.516  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 14.46 on 417 degrees of freedom
## Multiple R-squared:  0.4264, Adjusted R-squared:  0.4237 
## F-statistic:   155 on 2 and 417 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<p>You may check that these quantities are computed as in the simple regression model by computing the <span class="math inline">\(t\)</span>-statistics or <span class="math inline">\(p\)</span>-values by hand using the output above and <tt>R</tt> as a calculator.</p>
<p>For example, using the definition of the <span class="math inline">\(p\)</span>-value for a two-sided test as given in Key Concept 7.1, we can confirm the <span class="math inline">\(p\)</span>-value for a test of the hypothesis that the coeffiecient <span class="math inline">\(\beta_0\)</span>, that is the coefficient on <code>(intercept)</code>, is zero to be approximatley zero.</p>
<div class="unfolded">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">2</span><span class="op">*</span>(<span class="dv">1</span><span class="op">-</span><span class="kw">pnorm</span>(<span class="kw">abs</span>(<span class="fl">92.566</span>)))</code></pre></div>
<pre><code>## [1] 0</code></pre>
</div>
<p>Remember that, given a vector of quantiles, <code>pnorm()</code> calculates associated probabilities for the standard normal distribution by default which is suitable here since we approximate with the standard normal distribution.</p>
<div class="keyconcept">
<h3 class="right">
Key Concept 7.2
</h3>
<h3 class="left">
Confidence Intervals for a Single Coefficient in Multiple Regression
</h3>
<p>
A <span class="math inline">\(95\%\)</span> two-sided confidence interval for the coefficient <span class="math inline">\(\beta_j\)</span> is an interval that contains the true value of <span class="math inline">\(\beta_j\)</span> with a <span class="math inline">\(95 \%\)</span> probability; that is, it contains the true value of <span class="math inline">\(\beta_j\)</span> in <span class="math inline">\(95 \%\)</span> of all randomly drawn samples. Equivalently, it is the set of values of <span class="math inline">\(\beta_j\)</span> that cannot be rejected by a <span class="math inline">\(5 \%\)</span> two-sided hypothesis test. When the sample size is large, the <span class="math inline">\(95 \%\)</span> confidence interval for <span class="math inline">\(\beta_j\)</span> is <span class="math display">\[\left[\hat{\beta_j}- 1.96 \times SE(\hat{\beta}_j), \hat{\beta_j} + 1.96 \times SE(\hat{\beta_j})\right].\]</span>
</p>
</div>
</div>
<div id="an-application-to-test-scores-and-the-student-teacher-ratio" class="section level2">
<h2><span class="header-section-number">7.2</span> An Application to Test Scores and the Student-Teacher Ratio</h2>
<p>Let us take a look at the regression from section 6.3 again.</p>
<p>Computing individual confidence intervals for the coefficients in the multiple regression model can be done analogously as in the simple regression model using the function <code>confint()</code>.</p>
<div class="unfolded">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>size <span class="op">+</span><span class="st"> </span>english, <span class="dt">data =</span> CASchools)
<span class="kw">confint</span>(model)</code></pre></div>
<pre><code>##                   2.5 %      97.5 %
## (Intercept) 671.4640580 700.6004311
## size         -1.8487969  -0.3537944
## english      -0.7271113  -0.5724424</code></pre>
</div>
<p>We note that <span class="math inline">\(95\%\)</span> confidence intervals for all three coefficients are computed.</p>
<p>If we want to compute confidence intervals at another level of <span class="math inline">\(\alpha=0.1\)</span> say, we just have to set the argument <code>level</code> in our call of <code>confint()</code> accordingly.</p>
<div class="unfolded">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(model, <span class="dt">level =</span> <span class="fl">0.9</span>)</code></pre></div>
<pre><code>##                     5 %        95 %
## (Intercept) 673.8145793 698.2499098
## size         -1.7281904  -0.4744009
## english      -0.7146336  -0.5849200</code></pre>
</div>
<p>The output now reports the desired <span class="math inline">\(90\%\)</span> confidence intervals for all model coefficients.</p>
<p>Knowing how to use <ttR</tt> to make inference about the coefficients in multiple regression models, You can now answer the following question:</p>
<p>Can the null hypothesis that a change in the student-teacher ratio, <code>size</code>, has no significant influence on test scores, <code>scores</code>, — if we control for the percentage of students learning English in the district, <code>english</code>, — be rejected at the <span class="math inline">\(10\%\)</span> and the <span class="math inline">\(5\%\)</span> level of significance?</p>
<p>The outputs above tell us that zero is not an element of the computed confidence intervals for the coefficient of <code>size</code> such that we can reject the null hypothesis at significance levels of <span class="math inline">\(5\%\)</span> and <span class="math inline">\(10\%\)</span>.</p>
<p>Note that rejection at the <span class="math inline">\(5\%\)</span>-level implies rejection at the <span class="math inline">\(10\%\)</span> level (why?).</p>
<p>The same conclusion can be made when beholding the <span class="math inline">\(p\)</span>-value for <code>size</code>: <span class="math inline">\(0.00398 &lt; 0.05 = \alpha\)</span>.</p>
<p>The <span class="math inline">\(95\%\)</span> confidence interval tells us that we can be <span class="math inline">\(95\%\)</span> confident that a one-unit decrease in the student-teacher ratio has an effect on test scores that lies in the interval with a lower bound of <span class="math inline">\(-1.8488\)</span> and an upper bound of <span class="math inline">\(-0.3538\)</span>.</p>
<div id="another-augmentation-of-the-model" class="section level3 unnumbered">
<h3>Another Augmentation of the Model</h3>
<p>What is the average effect on test scores of reducing the student-teacher ratio when the expenditures per pupil and the percentage of english learning pupils are held constant?</p>
<p>We can pursue this question by augmenting our model equation by an additional regressor that is a measure for spendings per pupil. Using <code>?CASchools</code> we find that <code>CASchools</code> contains the variable <tt>expenditure</tt> which provides expenditures per student.</p>
<p>The model we want the estimate now is</p>
<p><span class="math display">\[ TestScore = \beta_0 + \beta_1 \times size + \beta_2 \times english + \beta_3 \times expenditure + u \]</span></p>
<p>with <span class="math inline">\(expenditure\)</span> the total amount of expenditures per pupil in the district (thousands of dollars).</p>
<p>Let us now estimate the model:</p>
<div class="unfolded">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Scale expenditure to thousands of dollars</span>
CASchools<span class="op">$</span>expenditure &lt;-<span class="st"> </span>CASchools<span class="op">$</span>expenditure<span class="op">/</span><span class="dv">1000</span>

<span class="co"># estimate the model</span>
model &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>size <span class="op">+</span><span class="st"> </span>english <span class="op">+</span><span class="st"> </span>expenditure, <span class="dt">data =</span> CASchools)
<span class="kw">summary</span>(model)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = score ~ size + english + expenditure, data = CASchools)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -51.340 -10.111   0.293  10.318  43.181 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 649.57795   15.20572  42.719  &lt; 2e-16 ***
## size         -0.28640    0.48052  -0.596  0.55149    
## english      -0.65602    0.03911 -16.776  &lt; 2e-16 ***
## expenditure   3.86790    1.41212   2.739  0.00643 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 14.35 on 416 degrees of freedom
## Multiple R-squared:  0.4366, Adjusted R-squared:  0.4325 
## F-statistic: 107.5 on 3 and 416 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<p>We see that the estimated effect of a one unit change in the student-teacher ratio on test scores with expenditures per pupil and the share of english learning pupils held constant is rather small (<span class="math inline">\(-0.29\)</span>). What is more, the coefficient on <span class="math inline">\(size\)</span> is not significantly different from zero anymore even at the level of <span class="math inline">\(10\%\)</span> since <span class="math inline">\(p\text{-value}=0.55\)</span>. Can You come up with an interpretation for these findings (see chapter 7.1 of the book)? Mathematically, the insignificance of <span class="math inline">\(\beta_1\)</span> could be due to a larger standard error of <span class="math inline">\(\hat{\beta}_1\)</span> resulting from adding <span class="math inline">\(expenditure\)</span> to the model so that we are estimating the true coefficent on <span class="math inline">\(size\)</span> less precisely. This illustrates the issue of strongly correlated regressors (imperfect multicollinearity). The correlation between <span class="math inline">\(size\)</span> and <span class="math inline">\(expenditures\)</span> can be computed using <code>cor()</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor</span>(CASchools<span class="op">$</span>size, CASchools<span class="op">$</span>expenditure)</code></pre></div>
<pre><code>## [1] -0.6199822</code></pre>
<p>Altogether we conclude that the new model provides no evidence that changing the student-teacher ratio, e.g. by hiring new teachers, has any effect on the test scores while keeping expenditures per student and the share of english learners constant at the same time.</p>
</div>
</div>
<div id="joint-hypothesis-testing-using-the-f-statistic" class="section level2">
<h2><span class="header-section-number">7.3</span> Joint Hypothesis Testing Using the <span class="math inline">\(F\)</span>-Statistic</h2>
<p>The estimated model is</p>
<p><span class="math display">\[ \widehat{TestScore} = 649.58 -0.29 \times size - 0.66 \times english + 3.87 \times expenditure. \]</span></p>
<p>Now, can we reject the hypothesis that the coefficient on <span class="math inline">\(size\)</span> <b>and</b> and the coefficient on <span class="math inline">\(expenditure\)</span> are zero? To answer this question, we have to resort to methods that allow joint hypothesis testing. A joint hypothesis imposes restrictions on multiple regression coefficients. This is different from conducting individual <span class="math inline">\(t\)</span>-tests where a single resitriction is imposed on a single coefficient. Chapter 7.2 of the book explains why testing the individual coefficients one at a time is different from testing them jointly.</p>
<p>The homoskedasticity-only <span class="math inline">\(F\)</span>-Statistic is given by</p>
<p><span class="math display">\[ F = \frac{(SSR_{restricted} - SSR_{unrestricted})/q}{SSR_{unrestricted} / (n-k_{unrestricted}-1)} \]</span></p>
<p>with <span class="math inline">\(SSR_{restricted}\)</span> the sum of squared residuals from the restricted regression, i.e. the regression where we impose the restriction. <span class="math inline">\(SSR_{unrestricted}\)</span> is the sum of squared residuals from the full model, <span class="math inline">\(q\)</span> is the number of restriction under the null and <span class="math inline">\(k\)</span> is the number of regressors in the unrestricted regression.</p>
<p>Luckily, it is fairly easy to conduct <span class="math inline">\(F\)</span>-tests in <tt>R</tt>. We can use the function <code>linearHypothesis()</code> which is contained in the <code>car</code> package.</p>
<div class="unfolded">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># estimate the multiple regression model</span>
model &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>size <span class="op">+</span><span class="st"> </span>english <span class="op">+</span><span class="st"> </span>expenditure, <span class="dt">data =</span> CASchools)

<span class="co"># execute the function on the model object and provide both linear restrictions </span>
<span class="co"># to be tested as strings</span>
<span class="kw">linearHypothesis</span>(model, <span class="kw">c</span>(<span class="st">&quot;size=0&quot;</span>, <span class="st">&quot;expenditure=0&quot;</span>))</code></pre></div>
<pre><code>## Linear hypothesis test
## 
## Hypothesis:
## size = 0
## expenditure = 0
## 
## Model 1: restricted model
## Model 2: score ~ size + english + expenditure
## 
##   Res.Df   RSS Df Sum of Sq      F   Pr(&gt;F)    
## 1    418 89000                                 
## 2    416 85700  2    3300.3 8.0101 0.000386 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<p>From the output we can infer that the <span class="math inline">\(F\)</span>-statistic for this joint hypothesis test is about <span class="math inline">\(8.01\)</span> and the corresponding <span class="math inline">\(p\)</span>-value is <span class="math inline">\(0.0004\)</span>. Thus we can reject the null hypothesis that both coefficients are zero at any level of significance commonly used in practice.</p>
<p><b>Note</b>:</p>
<p>The standard output of a model summary also reports an <span class="math inline">\(F\)</span>-statistic and the corresponding <span class="math inline">\(p\)</span>-value. The null hypothesis belonging to this <span class="math inline">\(F\)</span>-test is that <b>all</b> of the population coefficients in the model except for the intercept are zero, so the hypotheses pair is</p>
<p><span class="math display">\[H_0: \beta_1=0, \ \beta_2 =0, \ \beta_3 =0 \quad \text{vs.} \quad H_1: \beta_j \neq 0 \ \text{for at least one} \ j=1,2,3.\]</span></p>
<p>This is also called the “overall” regression <span class="math inline">\(F\)</span>-statistic and the null hypothesis is obviously different from testing if only <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_3\)</span> are zero.</p>
<p>We will now check that the <span class="math inline">\(F\)</span>-statistic belonging to the <span class="math inline">\(p\)</span>-value listed in the model’s summary coincides with the result reported by <code>linearHypothesis()</code>.</p>
<div class="unfolded">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># execute the function on the model object and provide the linear restriction </span>
<span class="co"># to be tested as strings</span>
<span class="kw">linearHypothesis</span>(model, <span class="kw">c</span>(<span class="st">&quot;size=0&quot;</span>,<span class="st">&quot;english=0&quot;</span>,<span class="st">&quot;expenditure=0&quot;</span>))</code></pre></div>
<pre><code>## Linear hypothesis test
## 
## Hypothesis:
## size = 0
## english = 0
## expenditure = 0
## 
## Model 1: restricted model
## Model 2: score ~ size + english + expenditure
## 
##   Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    
## 1    419 152110                                  
## 2    416  85700  3     66410 107.45 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Access the F-statistic from the model&#39;s summary</span>
<span class="kw">summary</span>(model)<span class="op">$</span>fstatistic</code></pre></div>
<pre><code>##    value    numdf    dendf 
## 107.4547   3.0000 416.0000</code></pre>
</div>
<p>The test rejects the null hypothesis that the model has no power in explaining test scores rather clearly.</p>
</div>
<div id="confidence-sets-for-multiple-coefficients" class="section level2">
<h2><span class="header-section-number">7.4</span> Confidence Sets for Multiple Coefficients</h2>
<p>Based on the <span class="math inline">\(F\)</span>-statistic that we have previously encountered, we can specify confidence sets. Confidence sets are analogous to confidence intervals for single coefficients. As such, confidence sets consist of combinations of coefficients that contain the true combination of coefficients in, <span class="math inline">\(95\%\)</span> say, of all cases if we could infinitely draw random samples, just as in the univariate case. Put differently, a confidence set is the set of coefficient combinations for which we cannot reject a joint null hypothesis tested using a <span class="math inline">\(F\)</span>-test.</p>
<p>If we consider two coefficients, their confidence set is an ellipse which is centered around the point defined by both coefficient estimates. Again, there is a very convenient way to plot the confidence set for two coefficients of model objects, namely the function <code>confidenceEllipse()</code> which is also coming with the <code>car</code> package.</p>
<p>In the following, we plot the <span class="math inline">\(95\%\)</span> confidence ellipse for the coefficients on <code>size</code> and <code>expenditure</code> from the regression conducted above. By specifying the additional argument <code>fill</code>, the confidence set is colored which gives us a better impression which set of coefficients is meant.</p>
<div class="unfolded">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Draw the 95% confidence set for coefficients on size and expenditure</span>
<span class="kw">confidenceEllipse</span>(model, 
                  <span class="dt">fill =</span> T, 
                  <span class="dt">which.coef =</span> <span class="kw">c</span>(<span class="st">&quot;size&quot;</span>,<span class="st">&quot;expenditure&quot;</span>),
                  <span class="dt">main =</span> <span class="st">&quot;95% Confidence Set&quot;</span>
                  )</code></pre></div>
<p><img src="URFITE_files/figure-html/unnamed-chunk-150-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<p>We see that the ellipse is centered around <span class="math inline">\((-0.29, 3.87)\)</span> i.e. the pair of coefficients estimates on <span class="math inline">\(size\)</span> and <span class="math inline">\(expenditure\)</span>. What is more, <span class="math inline">\((0,0)\)</span> is not element of the <span class="math inline">\(95\%\)</span> confidence set so that we can reject <span class="math inline">\(H_0: \beta_1 = 0, \ \beta_3 = 0\)</span>.</p>
</div>
<div id="model-specification-for-multiple-regression" class="section level2">
<h2><span class="header-section-number">7.5</span> Model Specification for Multiple Regression</h2>
<p>Choosing a regression specifaction i.e. selecting the variables to be included in a regression model can be quite cumbersome. However, there are some guidelines how to do this. The goal is clear: obtaining an unbiased estimation of the causal effect of interest. As a starting point, one should think about omitted variables, that is to avoid a possible estimation bias by using suitable control variables (omitted variables bias in the context of multiple regression is explained in Key Concept 7.3). A second step could be to compare different regression model specifications by measures of fit. However, as we shall see one should not rely solely on <span class="math inline">\(\overline{R^2}\)</span>.</p>
<div class="keyconcept">
<h3 class="right">
Key Concept 7.3
</h3>
<h3 class="left">
Omitted Variable Bias in Multiple Regression
</h3>
<p>
<p>Omitted variable bias is the bias in the OLS estimator that arises when one or more included regressors are correlated with an omitted variable. For omitted variable bias to arise, two things must be true:</p>
<ol style="list-style-type: decimal">
<li>At least one of the included regressors must be correlated with the omitted variable.</li>
<li>The omitted variable must be a determinant of the dependent variable, <span class="math inline">\(Y\)</span>.</li>
</ol>
</p>
</div>
<p>We will now discuss an example were we face a potential omitted variable bias in a multiple regression model:</p>
<p>Consider again the estimated regression equation</p>
<p><span class="math display">\[ \widehat{TestScore} = \underset{(8.7)}{686.0} - \underset{(0.43)}{1.10} \times size - \underset{(0.031)}{0.650} \times english. \]</span></p>
<p>We are interested in estimated the causal effect of class size on test score. In this estimation, there might be a bias due to omitting “outside learning opportunities” from our regression sice a measure like this could be a determinant of the students test scores and could also be correlated with both regressors already included in the model (so that both conditions of Key Concept 7.3 are fulfilled). “outside learning opportunities” is a complicated concept that is difficult to quantify. A surrogate we can consider instead is the students’ economic backgroud which should be strongly related to the outside learning opportunities: think of wealthy parents that are able to provide time and/or money for private tuition of there children. We thus augment the model with the variable <code>lunch</code>, the percentage of students that qualify for a free or subsidized lunch in school due to family incomes below a certain threshold, and estimate the model again.</p>
<div class="unfolded">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># estimate the model and print summary to console</span>
model &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>size <span class="op">+</span><span class="st"> </span>english <span class="op">+</span><span class="st"> </span>lunch, <span class="dt">data =</span> CASchools)
<span class="kw">summary</span>(model)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = score ~ size + english + lunch, data = CASchools)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -32.849  -5.151  -0.308   5.243  31.501 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 700.14996    4.68569 149.423  &lt; 2e-16 ***
## size         -0.99831    0.23875  -4.181 3.54e-05 ***
## english      -0.12157    0.03232  -3.762 0.000193 ***
## lunch        -0.54735    0.02160 -25.341  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 9.08 on 416 degrees of freedom
## Multiple R-squared:  0.7745, Adjusted R-squared:  0.7729 
## F-statistic: 476.3 on 3 and 416 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<p>Thus, the estimated regression line is</p>
<p><span class="math display">\[ \widehat{TestScore} = \underset{(4.7)}{700.15} - \underset{(0.24)}{1.00} \times size - \underset{(0.032)}{0.12} \times english + \underset{(0.022)}{0.55} \times lunch. \]</span></p>
<p>We observe no substantial changes in the conclusion about the effect of <code>size</code>: the coefficient changes by only <span class="math inline">\(0.1\)</span> and keeps its significance.</p>
<p>Although the difference in estimated coefficients is not big in this case, it might be a good idea to keep <code>lunch</code> in the model to make the assumption of conditional mean independence more credible (see chapter 7.5 of the book).</p>
<div id="model-specification-in-theory-and-in-practice" class="section level3 unnumbered">
<h3>Model Specification in Theory and in Practice</h3>
<div class="keyconcept">
<h3 class="right">
Key Concept 7.4
</h3>
<h3 class="left">
<span class="math inline">\(R^2\)</span> and <span class="math inline">\(\overline{R^2}\)</span>: What They Tell You — and What They Don’t
</h3>
<p>
<p><b><i>The <span class="math inline">\(R^2\)</span> and <span class="math inline">\(\overline{R^2}\)</span> tell you</i></b> whether the regressors are good at predicting, or “explaining” the values of the independent variable in the sample of data at hand. if the <span class="math inline">\(R^2\)</span> (or <span class="math inline">\(\overline{R^2}\)</span>) is nearly <span class="math inline">\(1\)</span>, then the regressors produce good prediction of the dependent variable in that sample, in the sense that the variance of OLS residuals is small compared to the variance of the dependent variable. If the <span class="math inline">\(R^2\)</span> (or <span class="math inline">\(\overline{R^2}\)</span>) is nearly <span class="math inline">\(0\)</span>, the opposite is true.</p>
<p><b><i>The <span class="math inline">\(R^2\)</span> and <span class="math inline">\(\overline{R^2}\)</span> do <u>not</u> tell you </i></b> whether:</p>
<ol style="list-style-type: decimal">
<li>An included variable is statistically significant.</li>
<li>The regressors are true cause of the movements in the dependent variable</li>
<li>There is omitted variable bias, or</li>
<li>You have chosen the most appropriate set of regressors.</li>
</ol>
</p>
</div>
<p>Key Concept 7.4 names some common pitfalls when using <span class="math inline">\(R^2\)</span> and <span class="math inline">\(\overline{R^2}\)</span> to evaluate the predictive ability of regression models.</p>
<p>For example, think of regressing <span class="math inline">\(TestScore\)</span> on <span class="math inline">\(PLS\)</span> which measures the available parking lot space in thousand square feet. You are likely to observe a significant coefficient of reasonable magnitude and moderate to high values for <span class="math inline">\(R^2\)</span> and <span class="math inline">\(\overline{R^2}\)</span>. The reason for this is that parking lot space is correlated with many determinants of the test score like location, class size, financial endowment and so on. Although we don not have observations on <span class="math inline">\(PLS\)</span>, we can use <tt>R</tt> to generate some relatively realistic data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Generate observations for parking lot space</span>
CASchools<span class="op">$</span>PLS &lt;-<span class="st"> </span><span class="dv">5</span> <span class="op">+</span><span class="st"> </span><span class="fl">0.6</span><span class="op">*</span>CASchools<span class="op">$</span>expenditure <span class="op">+</span><span class="st"> </span><span class="fl">0.6</span><span class="op">*</span>CASchools<span class="op">$</span>income <span class="op">+</span><span class="st"> </span>CASchools<span class="op">$</span>size<span class="op">/</span><span class="dv">100</span> <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(<span class="kw">nrow</span>(CASchools), <span class="dt">sd =</span> <span class="dv">1</span>)

<span class="co"># plot parking lot space against test score</span>
<span class="kw">plot</span>(CASchools<span class="op">$</span>PLS, 
     CASchools<span class="op">$</span>score,
     <span class="dt">xlab =</span> <span class="st">&quot;Parking Lot Space&quot;</span>,
     <span class="dt">ylab =</span> <span class="st">&quot;Test Score&quot;</span>,
     <span class="dt">pch =</span> <span class="dv">20</span>,
     <span class="dt">col =</span> <span class="st">&quot;steelblue&quot;</span>
     )</code></pre></div>
<p><img src="URFITE_files/figure-html/unnamed-chunk-152-1.png" width="672" style="display: block; margin: auto;" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># regress test score or PLS</span>
<span class="kw">summary</span>(<span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>PLS, <span class="dt">data =</span> CASchools))</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = score ~ PLS, data = CASchools)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -50.16 -14.25   0.65  13.56  49.88 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 6.224e+02  7.715e+00  80.679  &lt; 2e-16 ***
## PLS         9.915e-03  2.393e-03   4.144 4.13e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 18.7 on 418 degrees of freedom
## Multiple R-squared:  0.03946,    Adjusted R-squared:  0.03717 
## F-statistic: 17.17 on 1 and 418 DF,  p-value: 4.131e-05</code></pre>
<span class="math inline">\(PLS\)</span> is generated as a linear function of <span class="math inline">\(expenditure\)</span>, <span class="math inline">\(income\)</span>, <span class="math inline">\(size\)</span> and random disturbances. Therfore the data suggest that there is some postive relationship between parking lot space and test score. In fact, estimating the model
<span class="math display" id="eq:plsmod">\[\begin{align}
\widehat{TestScore} = \beta_0 + \beta_1 \times PLS + u \tag{7.1} 
\end{align}\]</span>
<p>using <code>lm</code> we find that the coefficient on <span class="math inline">\(PLS\)</span> is positive and significantly different from zero. Also <span class="math inline">\(R^2\)</span> and <span class="math inline">\(\overline{R^2}\)</span> are about <span class="math inline">\(0.47\)</span> which is a lot more than the roughly <span class="math inline">\(0.05\)</span> observed when regressing test score on class size.</p>
<p>This suggests that increasing the parking lot space boosts a school’s test scores and that the model <a href="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html#eq:plsmod">(7.1)</a> does even better in explaining heterogeneity in the dependent variable than a model with <span class="math inline">\(size\)</span> as the regressor. Keeping in mind how <span class="math inline">\(PLS\)</span> is constructed this comes of no surprise. It is evident that the high <span class="math inline">\(R^2\)</span> <it>cannot</it> be used to the conclude that the estimated relation between parking lot space and test scores is causal: the observed <span class="math inline">\(R^2\)</span> is due to correlation between <span class="math inline">\(PLS\)</span> and other determinantes and/or control variables such that increasing parking lot space <it>is not</it> an appropriate measure to generate more learning successes.</p>
</div>
</div>
<div id="analysis-of-the-test-score-data-set" class="section level2">
<h2><span class="header-section-number">7.6</span> Analysis of the Test Score Data Set</h2>
<p>Chapter 6 and some of the previous sections have stressed that it is important to include control variables in regression models if it is plausible that there are omitted factors that cannot be measured directly. Recall that in our example of test scores, we are interested in estimating the causal effect of a change in the student-teacher ratio on test scores. In what follows, we will provide an example how to use multiple regression models in order to alleviate omitted variable bias and we will demonstrate how to report results using <tt>R</tt>.</p>
<p>So far we have considered two variables that control for unobservable student characteristics which correlate with the student-teacher ratio <it>and</it> are assumed to have an impact on test scores:</p>
<ul>
<li><p><span class="math inline">\(english\)</span>, the percentage of english learning students</p></li>
<li><p><span class="math inline">\(lunch\)</span>, the share of students that qualify for a subsidized or even a free lunch at school</p></li>
</ul>
<p>Another new variable provided with <code>CASchools</code> is <span class="math inline">\(calworks\)</span>, the percentage of students that qualify for the <it>CalWorks</it> income assistance programm. Students eligible for <it>CalWorks</it> live in families with a total income below the threshold for the subsidized lunch programm so both variables are indicators for the share of economically disadvantaged children. Using <tt>R</tt> we can confirm that both indicators are highly correlated:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># estimate correlation between calworks and lunch</span>
<span class="kw">cor</span>(CASchools<span class="op">$</span>calworks, CASchools<span class="op">$</span>lunch)</code></pre></div>
<pre><code>## [1] 0.7394218</code></pre>
<p>There is no unabigious way to proceed when deciding which variable to use. In any case it is not a good idea to use both variables as regressors having in mind consequences of colinearity. Therefore, we will also consider alternative model specifications.</p>
<p>For a start, we plot student characteristics against test scores.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">3</span>))

m &lt;-<span class="st"> </span><span class="kw">rbind</span>(<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">0</span>))
<span class="kw">layout</span>(m)

<span class="kw">plot</span>(score <span class="op">~</span><span class="st"> </span>english, 
     <span class="dt">data =</span> CASchools, 
     <span class="dt">col =</span> <span class="st">&quot;steelblue&quot;</span>, 
     <span class="dt">pch =</span> <span class="dv">20</span>, 
     <span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">100</span>), 
     <span class="dt">main =</span> <span class="st">&quot;Percentage of English language learners&quot;</span>)

<span class="kw">plot</span>(score <span class="op">~</span><span class="st"> </span>lunch, 
     <span class="dt">data =</span> CASchools, 
     <span class="dt">col =</span> <span class="st">&quot;steelblue&quot;</span>, 
     <span class="dt">pch =</span> <span class="dv">20</span>,
     <span class="dt">main =</span> <span class="st">&quot;Percentage qualifying for reduced price lunch&quot;</span>)

<span class="kw">plot</span>(score <span class="op">~</span><span class="st"> </span>calworks, 
     <span class="dt">data =</span> CASchools, 
     <span class="dt">col =</span> <span class="st">&quot;steelblue&quot;</span>, 
     <span class="dt">pch =</span> <span class="dv">20</span>, 
     <span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">100</span>), 
     <span class="dt">main =</span> <span class="st">&quot;Percentage qualifying for income assistance&quot;</span>)</code></pre></div>
<p><img src="URFITE_files/figure-html/unnamed-chunk-154-1.png" width="672" /></p>
<p>We see that all relationships are negative. We can use <tt>R</tt> to estimate the correlation coefficients.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># estimate correlation between student characteristics and test scores</span>
<span class="kw">cor</span>(CASchools<span class="op">$</span>score, CASchools<span class="op">$</span>english)</code></pre></div>
<pre><code>## [1] -0.6441238</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor</span>(CASchools<span class="op">$</span>score, CASchools<span class="op">$</span>lunch)</code></pre></div>
<pre><code>## [1] -0.868772</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor</span>(CASchools<span class="op">$</span>score, CASchools<span class="op">$</span>calworks)</code></pre></div>
<pre><code>## [1] -0.6268533</code></pre>
<p>We will consider <span class="math inline">\(5\)</span> different model equations:</p>
<span class="math display">\[\begin{align*}
  (I) \quad \widehat{TestScore} =&amp; \, \beta_0 + \beta_1 \times size + u \\
  (II) \quad \widehat{TestScore} =&amp; \, \beta_0 + \beta_1 \times size + \beta_2 \times english + u \\
  (III) \quad \widehat{TestScore} =&amp; \, \beta_0 + \beta_1 \times size + \beta_2 \times english + \beta_3 \times lunch + u \\
  (IV) \quad \widehat{TestScore} =&amp; \, \beta_0 + \beta_1 \times size + \beta_2 \times english + \beta_4 \times calworks + u \\
  (V) \quad \widehat{TestScore} =&amp; \, \beta_0 + \beta_1 \times size + \beta_2 \times english + \beta_3 \times lunch + \beta_4 \times calworks + u
\end{align*}\]</span>
<p>The best way to communicate regression results is in a table. The <code>stargazer</code> package is very convenient for this purpose. It provides a function that generates professionally looking HTML and <span class="math inline">\(\LaTeX\)</span> tables that satisfy scienctific standards. One simply has to provide one or multiple object(s) of class <code>lm</code> and the rest is done by the function <code>stargazer()</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># load the stargazer library</span>
<span class="kw">library</span>(stargazer)

<span class="co"># estimate different model specifications</span>
spec1 &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>size , <span class="dt">data =</span> CASchools)
spec2 &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>size <span class="op">+</span><span class="st"> </span>english, <span class="dt">data =</span> CASchools)
spec3 &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>size <span class="op">+</span><span class="st"> </span>english <span class="op">+</span><span class="st"> </span>lunch, <span class="dt">data =</span> CASchools)
spec4 &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>size <span class="op">+</span><span class="st"> </span>english <span class="op">+</span><span class="st"> </span>calworks, <span class="dt">data =</span> CASchools)
spec5 &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>size <span class="op">+</span><span class="st"> </span>english <span class="op">+</span><span class="st"> </span>lunch <span class="op">+</span><span class="st"> </span>calworks, <span class="dt">data =</span> CASchools)

<span class="co"># generate a Latex table using stargazer</span>
<span class="kw">stargazer</span>(spec1, spec2, spec3, spec4, spec5, 
          <span class="dt">column.labels =</span> <span class="kw">c</span>(<span class="st">&quot;(I)&quot;</span>, <span class="st">&quot;(II)&quot;</span>, <span class="st">&quot;(III)&quot;</span>, <span class="st">&quot;(IV)&quot;</span>, <span class="st">&quot;(V)&quot;</span>)
          )</code></pre></div>



<table style="text-align:center"><tr><td colspan="6" style="border-bottom: 1px solid black"></td></tr><tr><td style="text-align:left"></td><td colspan="5"><em>Dependent variable:</em></td></tr>
<tr><td></td><td colspan="5" style="border-bottom: 1px solid black"></td></tr>
<tr><td style="text-align:left"></td><td colspan="5">score</td></tr>
<tr><td style="text-align:left"></td><td>(I)</td><td>(II)</td><td>(III)</td><td>(IV)</td><td>(V)</td></tr>
<tr><td style="text-align:left"></td><td>spec1</td><td>spec2</td><td>spec3</td><td>spec4</td><td>spec5</td></tr>
<tr><td colspan="6" style="border-bottom: 1px solid black"></td></tr><tr><td style="text-align:left">size</td><td>-2.280<sup>***</sup></td><td>-1.101<sup>***</sup></td><td>-0.998<sup>***</sup></td><td>-1.308<sup>***</sup></td><td>-1.014<sup>***</sup></td></tr>
<tr><td style="text-align:left"></td><td>(0.480)</td><td>(0.380)</td><td>(0.239)</td><td>(0.307)</td><td>(0.240)</td></tr>
<tr><td style="text-align:left"></td><td></td><td></td><td></td><td></td><td></td></tr>
<tr><td style="text-align:left">english</td><td></td><td>-0.650<sup>***</sup></td><td>-0.122<sup>***</sup></td><td>-0.488<sup>***</sup></td><td>-0.130<sup>***</sup></td></tr>
<tr><td style="text-align:left"></td><td></td><td>(0.039)</td><td>(0.032)</td><td>(0.033)</td><td>(0.034)</td></tr>
<tr><td style="text-align:left"></td><td></td><td></td><td></td><td></td><td></td></tr>
<tr><td style="text-align:left">lunch</td><td></td><td></td><td>-0.547<sup>***</sup></td><td></td><td>-0.529<sup>***</sup></td></tr>
<tr><td style="text-align:left"></td><td></td><td></td><td>(0.022)</td><td></td><td>(0.032)</td></tr>
<tr><td style="text-align:left"></td><td></td><td></td><td></td><td></td><td></td></tr>
<tr><td style="text-align:left">calworks</td><td></td><td></td><td></td><td>-0.790<sup>***</sup></td><td>-0.048</td></tr>
<tr><td style="text-align:left"></td><td></td><td></td><td></td><td>(0.053)</td><td>(0.061)</td></tr>
<tr><td style="text-align:left"></td><td></td><td></td><td></td><td></td><td></td></tr>
<tr><td style="text-align:left">Constant</td><td>698.933<sup>***</sup></td><td>686.032<sup>***</sup></td><td>700.150<sup>***</sup></td><td>697.999<sup>***</sup></td><td>700.392<sup>***</sup></td></tr>
<tr><td style="text-align:left"></td><td>(9.467)</td><td>(7.411)</td><td>(4.686)</td><td>(6.024)</td><td>(4.698)</td></tr>
<tr><td style="text-align:left"></td><td></td><td></td><td></td><td></td><td></td></tr>
<tr><td colspan="6" style="border-bottom: 1px solid black"></td></tr><tr><td style="text-align:left">Observations</td><td>420</td><td>420</td><td>420</td><td>420</td><td>420</td></tr>
<tr><td style="text-align:left">R<sup>2</sup></td><td>0.051</td><td>0.426</td><td>0.775</td><td>0.629</td><td>0.775</td></tr>
<tr><td style="text-align:left">Adjusted R<sup>2</sup></td><td>0.049</td><td>0.424</td><td>0.773</td><td>0.626</td><td>0.773</td></tr>
<tr><td style="text-align:left">Residual Std. Error</td><td>18.581 (df = 418)</td><td>14.464 (df = 417)</td><td>9.080 (df = 416)</td><td>11.654 (df = 416)</td><td>9.084 (df = 415)</td></tr>
<tr><td style="text-align:left">F Statistic</td><td>22.575<sup>***</sup> (df = 1; 418)</td><td>155.014<sup>***</sup> (df = 2; 417)</td><td>476.306<sup>***</sup> (df = 3; 416)</td><td>234.638<sup>***</sup> (df = 3; 416)</td><td>357.054<sup>***</sup> (df = 4; 415)</td></tr>
<tr><td colspan="6" style="border-bottom: 1px solid black"></td></tr><tr><td style="text-align:left"><em>Note:</em></td><td colspan="5" style="text-align:right"><sup>*</sup>p<0.1; <sup>**</sup>p<0.05; <sup>***</sup>p<0.01</td></tr>
</table>


<p>The table states that <span class="math inline">\(scores\)</span> is the dependent variable and that we consider <span class="math inline">\(5\)</span> models. We see that the coloumns of Table 7.1 contain all the information provided by <code>summary()</code> for the regression models <code>spec1</code> to <code>spec5</code>: the coefficient section of the table presents coefficients estimates equipped with signifiance codes (asterisks) and standard errors in parantheses below. Although there a no <span class="math inline">\(t\)</span>-statistics, it is straightforward for the reader to compute them simply by dividing a coefficient estimate by the correspondung standard error. In the botton of the table we find summary statistics for each model and a legend. For an in-depth discussion of the tabular presentation of regression results, see chapter 7.6 of the book.</p>
<p>What can we conclude from the model comparison?</p>
<ol style="list-style-type: decimal">
<li><p>We see that adding control variables roughly halves the coefficient on <code>size</code>. Also the coefficient is not very sensitive to the set of control variables used. The conclusion is that decreasing the student-teacher ratio ceteris paribus by one unit leads to an estimated average increase in test scores of about <span class="math inline">\(1\)</span> point.</p></li>
<li><p>Adding student characteristics as controls boosts <span class="math inline">\(R^2\)</span> and <span class="math inline">\(\overline{R^2}\)</span> from <span class="math inline">\(0.049\)</span> (<code>spec1</code>) up to <span class="math inline">\(0.773\)</span> (<code>spec3</code> and <code>spec5</code>), so we can consider these variables as suitable predictors for test scores. Morever, the estimated coefficients on all control variables are consistent with the impressions gained from figure 7.2.</p></li>
<li><p>We see that the control variables are not always individually statistically significant: for example in <code>spec5</code> we see that the coefficient on <span class="math inline">\(calworks\)</span> is not significantly different from zero at the level of <span class="math inline">\(5\%\)</span> since <span class="math inline">\(\lvert-0.048/0.061\rvert=0.79 &lt; 1.64\)</span>. We also observe that the effect on the estimate (and its standard error) of the coefficient on <span class="math inline">\(size\)</span> of adding <span class="math inline">\(calworks\)</span> to the base specification <code>spec3</code> is negligible. We can therefore consider <code>calworks</code> as a redundant control variable in this setting.</p></li>
</ol>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="regression-models-with-multiple-regressors.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="nonlinear-regression-functions.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 1
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/07-ch7.Rmd",
"text": "Edit"
},
"download": ["URFITE.pdf", "URFITE.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
