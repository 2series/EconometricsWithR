<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Using R for Introduction to Econometrics</title>
  <meta name="description" content="Using R for Introduction to Econometrics">
  <meta name="generator" content="bookdown 0.5 and GitBook 2.6.7">

  <meta property="og:title" content="Using R for Introduction to Econometrics" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="Emwikts1970/URFITE-Bookdown" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Using R for Introduction to Econometrics" />
  
  
  

<meta name="author" content="Christoph Hanck, Martin Arnold, Alexander Gerber and Martin Schmelzer">


<meta name="date" content="2017-11-07">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html">
<link rel="next" href="placeholder.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="js/hideOutput.js"></script>
<script type="text/javascript" src="MathJax-2.7.2/MathJax.js?config=default"></script>

 <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        extensions: ["tex2jax.js", "TeX/AMSmath.js"],
        tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
        jax: ["input/TeX","output/SVG"]
      });
      MathJax.Hub.processSectionDelay = 0;
  </script>

<!-- <script src="js/d3.v3.min.js"></script> 
<script src="js/leastsquares.js"></script>
<script src="js/d3functions.js"></script>
<script src="d3.slider.js"></script>
<script src="slrm.js"></script> -->


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; background-color: #f8f8f8; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
pre, code { background-color: #f8f8f8; }
code > span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code > span.dt { color: #204a87; } /* DataType */
code > span.dv { color: #0000cf; } /* DecVal */
code > span.bn { color: #0000cf; } /* BaseN */
code > span.fl { color: #0000cf; } /* Float */
code > span.ch { color: #4e9a06; } /* Char */
code > span.st { color: #4e9a06; } /* String */
code > span.co { color: #8f5902; font-style: italic; } /* Comment */
code > span.ot { color: #8f5902; } /* Other */
code > span.al { color: #ef2929; } /* Alert */
code > span.fu { color: #000000; } /* Function */
code > span.er { color: #a40000; font-weight: bold; } /* Error */
code > span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #000000; } /* Constant */
code > span.sc { color: #000000; } /* SpecialChar */
code > span.vs { color: #4e9a06; } /* VerbatimString */
code > span.ss { color: #4e9a06; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #000000; } /* Variable */
code > span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code > span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code > span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code > span.ex { } /* Extension */
code > span.at { color: #c4a000; } /* Attribute */
code > span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code > span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">URFITE</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a></li>
<li class="chapter" data-level="2" data-path="probability-theory.html"><a href="probability-theory.html"><i class="fa fa-check"></i><b>2</b> Probability Theory</a><ul>
<li class="chapter" data-level="" data-path="probability-theory.html"><a href="probability-theory.html#random-variables-and-probability-distributions"><i class="fa fa-check"></i>Random Variables and Probability Distributions</a><ul>
<li class="chapter" data-level="" data-path="probability-theory.html"><a href="probability-theory.html#probability-distributions-of-discrete-random-variables"><i class="fa fa-check"></i>Probability Distributions of Discrete Random Variables</a></li>
<li class="chapter" data-level="" data-path="probability-theory.html"><a href="probability-theory.html#bernoulli-trials"><i class="fa fa-check"></i>Bernoulli Trials</a></li>
<li class="chapter" data-level="" data-path="probability-theory.html"><a href="probability-theory.html#expected-values-mean-and-variance"><i class="fa fa-check"></i>Expected Values, Mean and Variance</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="probability-theory.html"><a href="probability-theory.html#probability-distributions-of-continuous-random-variables"><i class="fa fa-check"></i>Probability Distributions of Continuous Random Variables</a><ul>
<li class="chapter" data-level="" data-path="probability-theory.html"><a href="probability-theory.html#the-normal-distribution"><i class="fa fa-check"></i>The Normal Distribution</a></li>
<li class="chapter" data-level="" data-path="probability-theory.html"><a href="probability-theory.html#the-chi-squared-distribution"><i class="fa fa-check"></i>The Chi-Squared Distribution</a></li>
<li><a href="probability-theory.html#thetdist">The Student <span class="math inline">\(t\)</span> Distribution</a></li>
<li><a href="probability-theory.html#the-f-distribution">The <span class="math inline">\(F\)</span> Distribution</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="probability-theory.html"><a href="probability-theory.html#random-sampling-and-the-distribution-of-sample-averages"><i class="fa fa-check"></i>Random Sampling and the Distribution of Sample Averages</a><ul>
<li class="chapter" data-level="" data-path="probability-theory.html"><a href="probability-theory.html#mean-and-variance-of-the-sample-mean"><i class="fa fa-check"></i>Mean and Variance of the Sample Mean</a></li>
<li class="chapter" data-level="" data-path="probability-theory.html"><a href="probability-theory.html#large-sample-approximations-to-sampling-distributions"><i class="fa fa-check"></i>Large Sample Approximations to Sampling Distributions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="a-review-of-statistics-using-r.html"><a href="a-review-of-statistics-using-r.html"><i class="fa fa-check"></i><b>3</b> A Review of Statistics using R</a><ul>
<li class="chapter" data-level="" data-path="a-review-of-statistics-using-r.html"><a href="a-review-of-statistics-using-r.html#estimation-of-the-population-mean"><i class="fa fa-check"></i>Estimation of the Population Mean</a></li>
<li class="chapter" data-level="" data-path="a-review-of-statistics-using-r.html"><a href="a-review-of-statistics-using-r.html#properties-of-the-population-mean"><i class="fa fa-check"></i>Properties of the Population Mean</a></li>
<li class="chapter" data-level="" data-path="a-review-of-statistics-using-r.html"><a href="a-review-of-statistics-using-r.html#hypothesis-tests-concerning-the-population-mean"><i class="fa fa-check"></i>Hypothesis Tests Concerning the Population Mean</a><ul>
<li><a href="a-review-of-statistics-using-r.html#p-value"><span class="math inline">\(p\)</span>-Value</a></li>
<li><a href="a-review-of-statistics-using-r.html#calculating-the-p-value-when-sigma_y-is-known">Calculating the <span class="math inline">\(p\)</span>-Value When <span class="math inline">\(\sigma_Y\)</span> Is Known</a></li>
</ul></li>
<li class="chapter" data-level="3.1" data-path="a-review-of-statistics-using-r.html"><a href="a-review-of-statistics-using-r.html#shade-p-value2-region-in-right-tail"><i class="fa fa-check"></i><b>3.1</b> shade p-value/2 region in right tail</a><ul>
<li class="chapter" data-level="" data-path="a-review-of-statistics-using-r.html"><a href="a-review-of-statistics-using-r.html#sample-variance-sample-standard-deviation-and-standard-error"><i class="fa fa-check"></i>Sample Variance, Sample Standard Deviation and Standard Error</a></li>
<li><a href="a-review-of-statistics-using-r.html#calculating-the-p-value-when-sigma_y-is-unknown">Calculating the <span class="math inline">\(p\)</span>-value When <span class="math inline">\(\sigma_Y\)</span> is Unknown</a></li>
<li><a href="a-review-of-statistics-using-r.html#the-t-statistic">The <span class="math inline">\(t\)</span>-statistic</a></li>
<li class="chapter" data-level="" data-path="a-review-of-statistics-using-r.html"><a href="a-review-of-statistics-using-r.html#hypothesis-testing-with-a-prespecified-significance-level"><i class="fa fa-check"></i>Hypothesis Testing with a Prespecified Significance Level</a></li>
<li class="chapter" data-level="" data-path="a-review-of-statistics-using-r.html"><a href="a-review-of-statistics-using-r.html#one-sided-alternatives"><i class="fa fa-check"></i>One-sided Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="a-review-of-statistics-using-r.html"><a href="a-review-of-statistics-using-r.html#confidence-intervals-for-the-population-mean"><i class="fa fa-check"></i>Confidence intervals for the Population Mean</a></li>
<li class="chapter" data-level="" data-path="a-review-of-statistics-using-r.html"><a href="a-review-of-statistics-using-r.html#comparing-means-from-different-populations"><i class="fa fa-check"></i>Comparing Means from Different Populations</a></li>
<li class="chapter" data-level="" data-path="a-review-of-statistics-using-r.html"><a href="a-review-of-statistics-using-r.html#an-application-to-the-gender-gap-of-earnings"><i class="fa fa-check"></i>An Application to the Gender Gap of Earnings</a></li>
<li class="chapter" data-level="" data-path="a-review-of-statistics-using-r.html"><a href="a-review-of-statistics-using-r.html#scatterplots-sample-covariance-and-sample-correlation"><i class="fa fa-check"></i>Scatterplots, Sample Covariance and Sample Correlation</a></li>
<li class="chapter" data-level="3.2" data-path="a-review-of-statistics-using-r.html"><a href="a-review-of-statistics-using-r.html#plots"><i class="fa fa-check"></i><b>3.2</b> Plots</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="lrwor.html"><a href="lrwor.html"><i class="fa fa-check"></i><b>4</b> Linear Regression with One Regressor</a><ul>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#estimating-the-coefficients-of-the-linear-regression-model"><i class="fa fa-check"></i>Estimating the Coefficients of the Linear Regression Model</a><ul>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#the-ordinary-least-squares-estimator"><i class="fa fa-check"></i>The Ordinary Least Squares Estimator</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#measures-of-fit"><i class="fa fa-check"></i>Measures of fit</a><ul>
<li><a href="lrwor.html#the-r2">The <span class="math inline">\(R^2\)</span></a></li>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#standard-error-of-the-regression"><i class="fa fa-check"></i>Standard Error of the Regression</a></li>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#application-to-the-test-score-data"><i class="fa fa-check"></i>Application to the Test Score Data</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#the-least-squares-assumptions"><i class="fa fa-check"></i>The Least Squares Assumptions</a><ul>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#assumption-1-the-error-term-has-conditional-mean-of-zero"><i class="fa fa-check"></i>Assumption #1: The Error Term has Conditional Mean of Zero</a></li>
</ul></li>
<li class="chapter" data-level="4.1" data-path="lrwor.html"><a href="lrwor.html#the-true-relation"><i class="fa fa-check"></i><b>4.1</b> the true relation</a><ul>
<li><a href="lrwor.html#assumption-2-all-x_i-y_i-are-independently-and-identically-distributed">Assumption #2: All <span class="math inline">\((X_i, Y_i)\)</span> are Independently and Identically Distributed</a></li>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#assumption-3-large-outliers-are-unlikely"><i class="fa fa-check"></i>Assumption #3: Large outliers are unlikely</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#tsdotoe"><i class="fa fa-check"></i>The Sampling Distribution of the OLS Estimator</a><ul>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#r-simulation-study-1"><i class="fa fa-check"></i>R Simulation Study 1</a></li>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#r-simulation-study-2"><i class="fa fa-check"></i>R Simulation Study 2</a></li>
<li class="chapter" data-level="" data-path="lrwor.html"><a href="lrwor.html#r-simulation-study-3"><i class="fa fa-check"></i>R Simulation Study 3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html"><a href="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html"><i class="fa fa-check"></i><b>5</b> Hypothesis Tests and Confidence Intervals in the Simple Linear Regression Model</a><ul>
<li><a href="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html#testing-two-sided-hypotheses-concerning-beta_1">Testing Two-Sided Hypotheses Concerning <span class="math inline">\(\beta_1\)</span></a></li>
<li class="chapter" data-level="5.1" data-path="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html"><a href="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html#critical-region-in-left-tail"><i class="fa fa-check"></i><b>5.1</b> critical region in left tail</a></li>
<li class="chapter" data-level="5.2" data-path="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html"><a href="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html#critical-region-in-right-tail"><i class="fa fa-check"></i><b>5.2</b> critical region in right tail</a></li>
<li class="chapter" data-level="" data-path="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html"><a href="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html#confidence-intervals-for-regression-coefficients"><i class="fa fa-check"></i>Confidence Intervals for Regression Coefficients</a><ul>
<li class="chapter" data-level="" data-path="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html"><a href="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html#r-simulation-study-5.1"><i class="fa fa-check"></i>R Simulation Study 5.1</a></li>
</ul></li>
<li><a href="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html#regression-when-x-is-a-binary-variable">Regression when <span class="math inline">\(X\)</span> is a Binary Variable</a></li>
<li class="chapter" data-level="" data-path="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html"><a href="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html#heteroskedasticity-and-homoskedasticity"><i class="fa fa-check"></i>Heteroskedasticity and Homoskedasticity</a><ul>
<li class="chapter" data-level="" data-path="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html"><a href="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html#a-real-world-example-for-heteroskedasticity"><i class="fa fa-check"></i>A Real-World Example for Heteroskedasticity</a></li>
<li class="chapter" data-level="" data-path="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html"><a href="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html#should-we-care-about-heteroskedasticity"><i class="fa fa-check"></i>Should We Care About Heteroskedasticity?</a></li>
<li class="chapter" data-level="" data-path="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html"><a href="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html#computation-of-heteroskedasticity-robust-standard-errors"><i class="fa fa-check"></i>Computation of Heteroskedasticity-Robust Standard Errors</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html"><a href="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html#the-gauss-markov-theorem"><i class="fa fa-check"></i>The Gauss-Markov Theorem</a><ul>
<li class="chapter" data-level="" data-path="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html"><a href="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html#r-simulation-study-blue-estimator"><i class="fa fa-check"></i>R Simulation Study: BLUE Estimator</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html"><a href="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html#ols"><i class="fa fa-check"></i><b>5.3</b> OLS</a></li>
<li class="chapter" data-level="5.4" data-path="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html"><a href="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html#weighted"><i class="fa fa-check"></i><b>5.4</b> Weighted</a></li>
<li class="chapter" data-level="5.5" data-path="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html"><a href="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html#add-a-dashed-line-at-0-and-a-legend-to-the-plot"><i class="fa fa-check"></i><b>5.5</b> Add a dashed line at 0 and a legend to the plot</a></li>
<li><a href="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html#using-the-t-statistic-in-regression-when-the-sample-size-is-small">Using the <span class="math inline">\(t\)</span>-Statistic in Regression When the Sample Size Is Small</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="regression-models-with-multiple-regressors.html"><a href="regression-models-with-multiple-regressors.html"><i class="fa fa-check"></i><b>6</b> Regression Models with Multiple Regressors</a><ul>
<li class="chapter" data-level="" data-path="regression-models-with-multiple-regressors.html"><a href="regression-models-with-multiple-regressors.html#omitted-variable-bias"><i class="fa fa-check"></i>Omitted Variable Bias</a></li>
<li class="chapter" data-level="" data-path="regression-models-with-multiple-regressors.html"><a href="regression-models-with-multiple-regressors.html#the-multiple-regression-model"><i class="fa fa-check"></i>The Multiple Regression Model</a></li>
<li class="chapter" data-level="" data-path="regression-models-with-multiple-regressors.html"><a href="regression-models-with-multiple-regressors.html#measures-of-fit-in-multiple-regression"><i class="fa fa-check"></i>Measures of Fit in Multiple Regression</a></li>
<li class="chapter" data-level="" data-path="regression-models-with-multiple-regressors.html"><a href="regression-models-with-multiple-regressors.html#ols-assumptions-in-multiple-regression"><i class="fa fa-check"></i>OLS Assumptions in Multiple Regression</a><ul>
<li class="chapter" data-level="" data-path="regression-models-with-multiple-regressors.html"><a href="regression-models-with-multiple-regressors.html#multicollinearity"><i class="fa fa-check"></i>Multicollinearity</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="regression-models-with-multiple-regressors.html"><a href="regression-models-with-multiple-regressors.html#the-distribution-of-the-ols-estimators-in-multiple-regression"><i class="fa fa-check"></i>The Distribution of the OLS Estimators in Multiple Regression</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html"><a href="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html"><i class="fa fa-check"></i><b>7</b> Hypothesis Tests and Confidence intervals in Multiple Regression</a><ul>
<li class="chapter" data-level="7.1" data-path="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html"><a href="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html#hypothesis-tests-and-confidence-intervals-for-a-single-coefficient"><i class="fa fa-check"></i><b>7.1</b> Hypothesis Tests and Confidence Intervals for a Single Coefficient</a></li>
<li class="chapter" data-level="7.2" data-path="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html"><a href="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html#an-application-to-test-scores-and-the-student-teacher-ratio"><i class="fa fa-check"></i><b>7.2</b> An Application to Test Scores and the Student-Teacher Ratio</a><ul>
<li class="chapter" data-level="" data-path="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html"><a href="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html#another-augmentation-of-the-model"><i class="fa fa-check"></i>Another Augmentation of the Model</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html"><a href="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html#joint-hypothesis-testing-using-the-f-statistic"><i class="fa fa-check"></i><b>7.3</b> Joint Hypothesis Testing Using the <span class="math inline">\(F\)</span>-Statistic</a></li>
<li class="chapter" data-level="7.4" data-path="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html"><a href="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html#confidence-sets-for-multiple-coefficients"><i class="fa fa-check"></i><b>7.4</b> Confidence Sets for Multiple Coefficients</a></li>
<li class="chapter" data-level="7.5" data-path="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html"><a href="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html#model-specification-for-multiple-regression"><i class="fa fa-check"></i><b>7.5</b> Model Specification for Multiple Regression</a><ul>
<li class="chapter" data-level="" data-path="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html"><a href="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html#model-specification-in-theory-and-in-practice"><i class="fa fa-check"></i>Model Specification in Theory and in Practice</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html"><a href="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html#analysis-of-the-test-score-data-set"><i class="fa fa-check"></i><b>7.6</b> Analysis of the Test Score Data Set</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="nonlinear-regression-functions.html"><a href="nonlinear-regression-functions.html"><i class="fa fa-check"></i><b>8</b> Nonlinear Regression Functions</a><ul>
<li class="chapter" data-level="" data-path="nonlinear-regression-functions.html"><a href="nonlinear-regression-functions.html#logarithms"><i class="fa fa-check"></i>Logarithms</a></li>
<li class="chapter" data-level="8.1" data-path="nonlinear-regression-functions.html"><a href="nonlinear-regression-functions.html#interactions-between-independent-variables"><i class="fa fa-check"></i><b>8.1</b> Interactions Between Independent Variables</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="placeholder.html"><a href="placeholder.html"><i class="fa fa-check"></i><b>9</b> Placeholder</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Using R for Introduction to Econometrics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="nonlinear-regression-functions" class="section level1">
<h1><span class="header-section-number">8</span> Nonlinear Regression Functions</h1>
<p>Until now we assumed the regression function to be linear, i.e. we have treated the slope of the regression function as a constant. This implies that the effect on <span class="math inline">\(Y\)</span> of a one unit change in <span class="math inline">\(X\)</span> does not depend on the level of <span class="math inline">\(X\)</span>. If however the effect of a change in <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span> does depend on the value of <span class="math inline">\(X\)</span>, we have to use a nonlinear regression function.</p>
<p>Let us have a look at an example where using a nonlinear regression function might be better suited to describe the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>: the relation between district income and test scores.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Preparing the data</span>
<span class="kw">library</span>(AER)                                                     
<span class="kw">data</span>(CASchools)
CASchools<span class="op">$</span>size &lt;-<span class="st"> </span>CASchools<span class="op">$</span>students<span class="op">/</span>CASchools<span class="op">$</span>teachers
CASchools<span class="op">$</span>score &lt;-<span class="st"> </span>(CASchools<span class="op">$</span>read <span class="op">+</span><span class="st"> </span>CASchools<span class="op">$</span>math)<span class="op">/</span><span class="dv">2</span>       </code></pre></div>
<p>We start our analysis by computing the correlation between the two variables.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor</span>(CASchools<span class="op">$</span>income, CASchools<span class="op">$</span>score)</code></pre></div>
<pre><code>## [1] 0.7124308</code></pre>
<p>The correlation coefficient is about <span class="math inline">\(0.71\)</span>. This means that income and test scores are positively correlated. In other words, children whose parents have an above average income tend to achieve above average test scores. Can we use the correlation coefficient to assess whether a linear regression model does fit the data adequately? To answer this question we visualize the data and add a linear regression line to the plot.</p>
<div class="unfolded">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Fit linear model</span>
linear_model&lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>income, <span class="dt">data =</span> CASchools)

<span class="co"># Plot observations</span>
<span class="kw">plot</span>(CASchools<span class="op">$</span>income, CASchools<span class="op">$</span>score,
     <span class="dt">col =</span> <span class="st">&quot;steelblue&quot;</span>,
     <span class="dt">pch =</span> <span class="dv">20</span>,
     <span class="dt">xlab =</span> <span class="st">&quot;District Income (thousands of dollars)&quot;</span>, 
     <span class="dt">ylab =</span> <span class="st">&quot;Test Score&quot;</span>,
     <span class="dt">main =</span> <span class="st">&quot;Test Score vs. District Income and a Linear OLS Regression Function&quot;</span>)

<span class="co"># Add the regression line to the plot</span>
<span class="kw">abline</span>(linear_model, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>)</code></pre></div>
<p><img src="URFITE_files/figure-html/unnamed-chunk-2-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<p>As Stock and Watson point out, the linear regression line seems to overestimate the true relationship when income is very high or very low and underestimates it in the midrange.</p>
<p>Fortunately, usage of the OLS is not restricted to linear functions of the regressors. Thus we can for example model test scores as a function of income and the square of income. The corresponding regression model is</p>
<p><span class="math display">\[TestScore_i = \beta_0 + \beta_1 Income_i + \beta_2 Income_i^2 + u_i.\]</span></p>
<p>This equation is called the <em>quadratic regression model</em>. Note, that <span class="math inline">\(Income^2\)</span> is treated as an additional explanatory variable. Hence, the quadratic model is a special case of a multivariate regression model. When fitting the model with <code>lm()</code> we have to use the <code>^</code> operator in conjunction with the function <code>I()</code> to add the quadratic term as an additional regressor to the <code>formula</code> argument.</p>
<div class="unfolded">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Fit the quadratic Model</span>
quadratic_model &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>income <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(income<span class="op">^</span><span class="dv">2</span>), <span class="dt">data =</span> CASchools)

<span class="co"># Generate model summary</span>
<span class="kw">summary</span>(quadratic_model)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = score ~ income + I(income^2), data = CASchools)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -44.416  -9.048   0.440   8.347  31.639 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 607.30174    3.04622 199.362  &lt; 2e-16 ***
## income        3.85099    0.30426  12.657  &lt; 2e-16 ***
## I(income^2)  -0.04231    0.00626  -6.758 4.71e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 12.72 on 417 degrees of freedom
## Multiple R-squared:  0.5562, Adjusted R-squared:  0.554 
## F-statistic: 261.3 on 2 and 417 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<p>The output tells us that the estimated model equation is</p>
<p><span class="math display">\[ \widehat{TestScore}_i = \underset{(3.05)}{607.3} + \underset{(0.30)}{3.85} \times Income_i - \underset{(0.01)}{0.0423} \times Income_i^2. \]</span></p>
<p>Notice that this estimated model equation allows us to test the hypothesis that the relationship between test scores and district income is linear against the alternative hypothesis that it is nonlinear. This corresponds to testing</p>
<p><span class="math display">\[ H_0: \beta_2 = 0 \ \ \text{vs.} \ \  H_1: \beta_2\neq0,\]</span></p>
<p>since <span class="math inline">\(\beta_2=0\)</span> corresponds to a simple linear equation and and <span class="math inline">\(\beta_2\neq0\)</span> implies a quadratic relationship. We find that <span class="math inline">\(t=(\hat\beta_2 - 0)/SE(\hat\beta_2) = -0.0423/0.01 = -4.23\)</span> so the null is rejected at any common level of significance and we conclude that the relationship is nonlinear. This is consistent with our informal inspection of the plotted data.</p>
<p>We can now draw the same scatterplot as for the linear model and add the regression line for the quadratic model. Because <code>abline()</code> can only draw straight lines, it cannot be used for this task. A function which can be used to draw lines without being restricted to straight lines is <code>lines()</code>, see <code>?lines</code>. The most basic call of <code>lines()</code> is <code>lines(x_values, y_values)</code> where <code>x_values</code> and <code>y_values</code> are vectors of the same length that provide coordinates of the points to be <it>sequentially</it> connected by a line. This makes it necessary to sort the coordinate pairs according to the X-values. Otherwise You will not get the desired result! In this example we use the function <code>order()</code> to sort the fitted values of <span class="math inline">\(TestScore\)</span> according to the observations for <span class="math inline">\(income\)</span>.</p>
<div class="unfolded">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Scatterplot of observatuib for income and TestScore</span>
<span class="kw">plot</span>(CASchools<span class="op">$</span>income, CASchools<span class="op">$</span>score,
     <span class="dt">col  =</span> <span class="st">&quot;steelblue&quot;</span>,
     <span class="dt">pch =</span> <span class="dv">20</span>,
     <span class="dt">xlab =</span> <span class="st">&quot;District Income (thousands of dollars)&quot;</span>,
     <span class="dt">ylab =</span> <span class="st">&quot;Test Score&quot;</span>,
     <span class="dt">main =</span> <span class="st">&quot;Linear and Quadratic OLS Regression Functions&quot;</span>)

<span class="co">#Add linear function to the plot</span>
<span class="kw">abline</span>(linear_model , <span class="dt">col=</span><span class="st">&quot;black&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>)

<span class="co">#Add quatratic function to the plot</span>
order_id &lt;-<span class="st"> </span><span class="kw">order</span>(CASchools<span class="op">$</span>income)

<span class="kw">lines</span>(<span class="dt">x =</span> CASchools<span class="op">$</span>income[order_id], 
      <span class="dt">y =</span> <span class="kw">fitted</span>(quadratic_model)[order_id],
      <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, 
      <span class="dt">lwd=</span><span class="dv">2</span>) </code></pre></div>
<p><img src="URFITE_files/figure-html/unnamed-chunk-4-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<p>We see that the quadratic model does much better in fitting the data than the linear model.</p>
<p>The approach we used to obtain a quadratic model can be generalized to polynomial models of arbitrary order <span class="math inline">\(r\)</span>. <span class="math display">\[Y_i = \beta_0 + \beta_1 X_i + \beta_2 X_i^2 + \ldots + \beta_r X_i^r + u_i\]</span></p>
<p>A cubic model (<span class="math inline">\(r=3\)</span>) for instance can be estimated in the same way as the quadratic model — we just have to add <code>I(income^3)</code> to the <code>formula</code> argument in our call of <code>lm()</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cubic_model &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>income <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(income<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(income<span class="op">^</span><span class="dv">3</span>), <span class="dt">data =</span> CASchools)</code></pre></div>
<p>In practice the question will arise which polynomial order should be chosen. First note that, similarly as for <span class="math inline">\(r=2\)</span>, we can test the null hypothesis that the true relation is linear against the alternative hypothesis that the relationship is a polynomial of degree <span class="math inline">\(r\)</span>:</p>
<p><span class="math display">\[ H_0: \beta_2=0, \ \beta_3=0,\dots,\beta_r=0 \ \ \ \text{vs.} \ \ \ H_1: \text{at least one} \ \beta_j\neq0, \ j=2,\dots,r \]</span></p>
<p>This is a joint null hypothesis with <span class="math inline">\(r-1\)</span> restrictions so it can be tested using the <span class="math inline">\(F\)</span>-test presented in chapter 7. Remember that the function <code>linearHypothesis()</code> can compute such test statistics. If, for example, we would like to test the null hypothesis of a linear model against the alternative of a polynomial of a maximal degree <span class="math inline">\(r=3\)</span> we could simply do the following:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(car)

<span class="co"># test the hypothesis</span>
<span class="kw">linearHypothesis</span>(cubic_model, 
                 <span class="kw">c</span>(<span class="st">&quot;I(income^2)=0&quot;</span>, <span class="st">&quot;I(income^3)=0&quot;</span>)
)</code></pre></div>
<pre><code>## Linear hypothesis test
## 
## Hypothesis:
## I(income^2) = 0
## I(income^3) = 0
## 
## Model 1: restricted model
## Model 2: score ~ income + I(income^2) + I(income^3)
## 
##   Res.Df   RSS Df Sum of Sq      F    Pr(&gt;F)    
## 1    418 74905                                  
## 2    416 67170  2    7735.5 23.954 1.424e-10 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The <span class="math inline">\(p\)</span>-value for this test is very small so that we reject the null hypothesis. However, this does not tell us which <span class="math inline">\(r\)</span> to choose. In practice, one approach to determine degree of the polynomial is to use <it>sequential testing</it>:</p>
<ol style="list-style-type: decimal">
<li>Estimate a polynomial model for some maximum value <span class="math inline">\(r\)</span>.</li>
<li>Use a <span class="math inline">\(t\)</span>-test to test whether <span class="math inline">\(\beta_r = 0\)</span>. <b>Rejection</b> of the null means that <span class="math inline">\(X^r\)</span> belongs in the regression equation.</li>
<li><b>Acceptance</b> of the null in step 2 means that <span class="math inline">\(X^r\)</span> can be eliminated from the model. Continue by repeating step 1 with order <span class="math inline">\(r-1\)</span> and test whether <span class="math inline">\(\beta_{r-1}=0\)</span>. If the test rejects, use a polynomial model of order <span class="math inline">\(r-1\)</span>.</li>
<li>If the tests from step 3 rejects, continue with the procedure until the coefficient on the highest power is statistically significant.</li>
</ol>
<p>There is no unambigous guideline how to choose <span class="math inline">\(r\)</span> in step one. However as Stock and Watson point out, economic data is often smooth such that it is appropriate to choose small orders like <span class="math inline">\(2\)</span>, <span class="math inline">\(3\)</span>, or <span class="math inline">\(4\)</span>.</p>
<p>We will now demonstrate how to apply <it>sequential testing</it> in the example of a cubic model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(cubic_model)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = score ~ income + I(income^2) + I(income^3), data = CASchools)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -44.28  -9.21   0.20   8.32  31.16 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  6.001e+02  5.830e+00 102.937  &lt; 2e-16 ***
## income       5.019e+00  8.595e-01   5.839 1.06e-08 ***
## I(income^2) -9.581e-02  3.736e-02  -2.564   0.0107 *  
## I(income^3)  6.855e-04  4.720e-04   1.452   0.1471    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 12.71 on 416 degrees of freedom
## Multiple R-squared:  0.5584, Adjusted R-squared:  0.5552 
## F-statistic: 175.4 on 3 and 416 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>The estimated cubic model stored in <code>cubic_model</code> is</p>
<p><span class="math display">\[ \widehat{TestScore}_i = \underset{(5.83)}{600.1} + \underset{(0.86)}{5.02} \times Income + \underset{(0.03)}{-0.96} \times Income^2 + \underset{(-0.00047)}{0.00069}  \times Income^3. \]</span></p>
<p>Summary tells us that the <span class="math inline">\(t\)</span>-statistic on <span class="math inline">\(Income^3\)</span> is <span class="math inline">\(1.42\)</span> so the null that the relationship is quadratic cannot be rejected, even at the <span class="math inline">\(10\%\)</span> level. This is contrary to the result of the book which reports robust standard errors throughout so we will also use robust variance-covariance estimation to reproduce these results.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># load the lmtest package for coeftest()</span>
<span class="kw">library</span>(lmtest)

<span class="co"># test the hypothesis using robust standard errors</span>
<span class="kw">coeftest</span>(cubic_model, <span class="dt">vcov. =</span> <span class="kw">vcovHC</span>(cubic_model, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>))</code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##                Estimate  Std. Error  t value  Pr(&gt;|t|)    
## (Intercept)  6.0008e+02  5.1021e+00 117.6150 &lt; 2.2e-16 ***
## income       5.0187e+00  7.0735e-01   7.0950 5.606e-12 ***
## I(income^2) -9.5805e-02  2.8954e-02  -3.3089  0.001018 ** 
## I(income^3)  6.8549e-04  3.4706e-04   1.9751  0.048918 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Notice that the reported standard errors have changed. Furthermore, the coefficient for <code>income^3</code> is now significant at the <span class="math inline">\(5\%\)</span> level. This means we reject the hypothesis that the regression function is quadratic against the alternative that it is cubic. Furthermore, we can also test if the coefficients for <code>income^2</code> and <code>income^3</code> are jointly significant using a robust version of the <span class="math inline">\(F\)</span>-test.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># robust F-test for </span>
<span class="kw">linearHypothesis</span>(cubic_model, 
                 <span class="dt">vcov. =</span> <span class="kw">vcovHC</span>(cubic_model, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>),
                 <span class="kw">c</span>(<span class="st">&quot;I(income^2)=0&quot;</span>, <span class="st">&quot;I(income^3)=0&quot;</span>)
                 )</code></pre></div>
<pre><code>## Linear hypothesis test
## 
## Hypothesis:
## I(income^2) = 0
## I(income^3) = 0
## 
## Model 1: restricted model
## Model 2: score ~ income + I(income^2) + I(income^3)
## 
## Note: Coefficient covariance matrix supplied.
## 
##   Res.Df Df      F    Pr(&gt;F)    
## 1    418                        
## 2    416  2 37.691 9.043e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>With a <span class="math inline">\(p\)</span>-value of <code>9.043e-16</code>, i.e. much less than <span class="math inline">\(0.05\)</span>, the null hypothesis of linearity is rejected in favour of the alternative that the relationship is quadratic <it>or</it> cubic.</p>
<div id="interpretation-of-coefficients-in-nonlinear-regression-models" class="section level4 unnumbered">
<h4>Interpretation of Coefficients in Nonlinear Regression Models</h4>
<p>The coefficients in polynomial regression do not have a simple interpretation. Think of a quadratic model. It is not helpful to think of the coefficient on <span class="math inline">\(X\)</span> as the expected change in <span class="math inline">\(Y\)</span> associated with a change in <span class="math inline">\(X\)</span> holding the other regressors constant because one other is <span class="math inline">\(X^2\)</span> which changes as <span class="math inline">\(X\)</span> is varied. This is also the case for other deviations from linearity, for example in models where regressors and/or the dependent variable are log-transformed. The best way to approach this is to calculate the estimated effect on <span class="math inline">\(Y\)</span> associated with a change in <span class="math inline">\(X\)</span> for one or more values of <span class="math inline">\(X\)</span>. This idea is summarized in Key Concept 8.1.</p>
<div class="keyconcept">
<h3 class="right">
Key Concept 8.1
</h3>
<h3 class="left">
The Expected Effect on <span class="math inline">\(Y\)</span> of a Change in <span class="math inline">\(X_1\)</span> in a Nonlinear Regression Model
</h3>
<p>Consider the nonlinear population regression model</p>
<p><span class="math display">\[ Y_i = f(X_{1i}, X_{2i}, \dots, X_{ki}) + u_i \ , \ i=1,\dots,n,\]</span></p>
<p>where <span class="math inline">\(f(X_{1i}, X_{2i}, \dots, X_{ki})\)</span> is the population regression function and <span class="math inline">\(u_i\)</span> is the error term.</p>
<p>
<p>The expected change in <span class="math inline">\(Y\)</span>, <span class="math inline">\(\Delta Y\)</span>, associated with the change in <span class="math inline">\(X_1\)</span>, <span class="math inline">\(\Delta X_1\)</span>, holding <span class="math inline">\(X_2, \cdots , X_k\)</span> constant. That is, the expected change in <span class="math inline">\(Y\)</span> is the difference:</p>
<p><span class="math display">\[\Delta Y = f(X_1 + \Delta X_1, X_2, \cdots, X_k) - f(X_1, X_2, \cdots, X_k).\]</span></p>
<p>The estimator of this unknown population difference is the difference between the predicted values for these two cases. Let <span class="math inline">\(\hat{f}(X_1, X_2, \cdots, X_k)\)</span> be the predicted value of of <span class="math inline">\(Y\)</span> based on the estimator <span class="math inline">\(\hat{f}\)</span> of the population regression function. Then the predicted change in <span class="math inline">\(Y\)</span> is</p>
<span class="math display">\[\Delta \hat{Y} = \hat{f}(X_1 + \Delta X_1, X_2, \cdots, X_k) - \hat{f}(X_1, X_2, \cdots, X_k).\]</span>
</p>
</div>
<p>For example, we may ask the following: what is the predicted change in test scores associated with a one unit change (i.e. <span class="math inline">\(\$1000\)</span>), based on the estimated quadratic regression function</p>
<p><span class="math display">\[\widehat{TestScore} = 607.3 + 3.85 \times Income - 0.0423 \times Income^2\ ?\]</span></p>
<p>Because the regression function is quadratic, this effect depends on the initial district income. We therefore consider two cases: an increase in district income form <span class="math inline">\(10\)</span> to <span class="math inline">\(11\)</span> (i.e. from <span class="math inline">\(\$10000\)</span> per capita to <span class="math inline">\(\$11000\)</span>) and an increase in district income from <span class="math inline">\(40\)</span> to <span class="math inline">\(41\)</span> (that is from <span class="math inline">\(\$40000\)</span> to <span class="math inline">\(\$41000\)</span>).</p>
<p>In order to obtain the <span class="math inline">\(\Delta \hat{Y}\)</span> associated with a change in income form <span class="math inline">\(10\)</span> to <span class="math inline">\(11\)</span>, we use the following formula:</p>
<p><span class="math display">\[\Delta \hat{Y} = \left(\hat{\beta}_0 + \hat{\beta}_1 \times 11 + \hat{\beta}_2 \times 11^2\right) - \left(\hat{\beta}_0 + \hat{\beta}_1 \times 10 + \hat{\beta}_2 \times 10^2\right) \]</span> To compute <span class="math inline">\(\hat{Y}\)</span> using <tt>R</tt> we may use <code>predict()</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compute and assign the quadratic model</span>
quadriatic_model &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>income <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(income<span class="op">^</span><span class="dv">2</span>), <span class="dt">data =</span> CASchools)

<span class="co"># set up data to predict</span>
new_data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">income =</span> <span class="kw">c</span>(<span class="dv">10</span>, <span class="dv">11</span>))

<span class="co"># do the prediction</span>
Y_hat &lt;-<span class="st"> </span><span class="kw">predict</span>(quadriatic_model, <span class="dt">newdata =</span> new_data)

<span class="co"># compute the difference</span>
<span class="kw">diff</span>(Y_hat)</code></pre></div>
<pre><code>##        2 
## 2.962517</code></pre>
<p>Analogously we can compute the effect of a change in <span class="math inline">\(income\)</span> from <span class="math inline">\(40\)</span> to <span class="math inline">\(11\)</span>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># set up data to predict</span>
new_data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">income =</span> <span class="kw">c</span>(<span class="dv">40</span>, <span class="dv">41</span>))

<span class="co"># do the prediction</span>
Y_hat &lt;-<span class="st"> </span><span class="kw">predict</span>(quadriatic_model, <span class="dt">newdata =</span> new_data)

<span class="co"># compute the difference</span>
<span class="kw">diff</span>(Y_hat)</code></pre></div>
<pre><code>##         2 
## 0.4240097</code></pre>
<p>So for the quadratic model, the expected change in <span class="math inline">\(TestScore\)</span> induced by an increase in <span class="math inline">\(income\)</span> from <span class="math inline">\(10\)</span> to <span class="math inline">\(11\)</span> is about <span class="math inline">\(2.96\)</span> points but an increase in <span class="math inline">\(income\)</span> from <span class="math inline">\(40\)</span> to <span class="math inline">\(41\)</span> increases the predicted score by only <span class="math inline">\(0.42\)</span>. Hence the slope of the estimated quadratic regression function is <it>steeper</it> at low levels of income than at the higher levels.</p>
</div>
<div id="logarithms" class="section level3 unnumbered">
<h3>Logarithms</h3>
<p>Another way to specify a nonlinear regression function is to use the natural logarithm of <span class="math inline">\(Y\)</span> and/or <span class="math inline">\(X\)</span>. Logarithms convert changes in variables into percentage changes which is convenient as many relationships are naturally expressed in terms of percentages.</p>
<p>There are three different cases in which logarithms might be used.</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(X\)</span> could be transformed by taking its logarithm but <span class="math inline">\(Y\)</span> is not.</p></li>
<li><p>We could transform <span class="math inline">\(Y\)</span> to its logarithm but leave <span class="math inline">\(X\)</span> at level.</p></li>
<li><p>A third case is that both <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> are transformed to their logarithms. The interpretation of the regression coefficients is different in each case.</p></li>
</ol>
<div id="case-i-x-is-in-logarithm-y-is-not." class="section level4 unnumbered">
<h4>Case I: <span class="math inline">\(X\)</span> is in logarithm, <span class="math inline">\(Y\)</span> is not.</h4>
<p>The regression model then is</p>
<p><span class="math display">\[Y_i = \beta_0 + \beta_1 \times \ln(X_i) + u_i \text{, } i=1,...,n. \]</span> Similar as for polynomial regression we do not have to create a new variable by computing <span class="math inline">\(\ln(X)\)</span>. We can simply adjust the <code>formula</code> argument of <code>lm()</code> to tell <tt>R</tt> that the log-transformation of a variable should be used.</p>
<div class="unfolded">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># estimate a level-log model</span>
LinearLog_model &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span><span class="kw">log</span>(income), <span class="dt">data =</span> CASchools)

<span class="co"># compute robust summary</span>
<span class="kw">coeftest</span>(LinearLog_model, 
         <span class="dt">vcov =</span> <span class="kw">vcovHC</span>(LinearLog_model, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>)
         )</code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##             Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept) 557.8323     3.8399 145.271 &lt; 2.2e-16 ***
## log(income)  36.4197     1.3969  26.071 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<p>According to the output the estimated regression function is:</p>
<p><span class="math display">\[\widehat{TestScore} = 557.8 + 36.42 \times \ln(Income).\]</span></p>
<p>Let us draw a plot of this function.</p>
<div class="unfolded">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># draw scatterplot</span>
<span class="kw">plot</span>(score <span class="op">~</span><span class="st"> </span>income, 
     <span class="dt">col =</span> <span class="st">&quot;steelblue&quot;</span>,
     <span class="dt">pch =</span> <span class="dv">20</span>,
     <span class="dt">data =</span> CASchools,
     <span class="dt">main =</span> <span class="st">&quot;Linear-Log Regression Line&quot;</span>)

<span class="co"># add Linear-Log regression line</span>
order_id  &lt;-<span class="st"> </span><span class="kw">order</span>(CASchools<span class="op">$</span>income)

<span class="kw">lines</span>(CASchools<span class="op">$</span>income[order_id],
      <span class="kw">fitted</span>(LinearLog_model)[order_id], 
      <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, 
      <span class="dt">lwd =</span> <span class="dv">2</span>)</code></pre></div>
<p><img src="URFITE_files/figure-html/unnamed-chunk-10-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<p>We can interpret <span class="math inline">\(\hat{\beta}_1\)</span> as follows: a <span class="math inline">\(1\%\)</span> increase in income is associated with an increase in test scores of <span class="math inline">\(0.01 \times 36.42 = 0.36\)</span> points. In order to get the estimated effect of <it>a one unit </it> change in income (that is a change in the original units,thousands of dollars, not in logarithms) on test scores, the method presented in Key Concept 8.1 can be used.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># set up new data</span>
new_data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">income =</span> <span class="kw">c</span>(<span class="dv">10</span>, <span class="dv">11</span>, <span class="dv">40</span>, <span class="dv">41</span>))

<span class="co"># predict outcomes </span>
Y_hat &lt;-<span class="st"> </span><span class="kw">predict</span>(LinearLog_model, <span class="dt">newdata =</span> new_data)

<span class="co"># compute expected difference</span>
changes &lt;-<span class="st"> </span><span class="kw">matrix</span>(Y_hat, <span class="dt">nrow =</span> <span class="dv">2</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>)
changes[ ,<span class="dv">2</span>] <span class="op">-</span><span class="st"> </span>changes[ ,<span class="dv">1</span>]</code></pre></div>
<pre><code>## [1] 3.471166 0.899297</code></pre>
<p>The estimated model states that for an income increase from <span class="math inline">\(\$10,000\)</span> to <span class="math inline">\(\$11,000\)</span>, test scores increase by an expected amount of <span class="math inline">\(3.47\)</span> points. When income increases from <span class="math inline">\(\$40,000\)</span> to <span class="math inline">\(\$41,000\)</span>, the expected increase in test scores is only about <span class="math inline">\(0.90\)</span> points.</p>
</div>
<div id="case-ii-y-is-in-logarithm-x-is-not" class="section level4 unnumbered">
<h4>Case II: <span class="math inline">\(Y\)</span> is in logarithm, <span class="math inline">\(X\)</span> is not</h4>
<p>If You want to learn about the absolute impact of an explanatory variable on Your dependent variable, it is not recommended to log-transform the latter. There are, however, cases where we want to learn about <span class="math inline">\(\ln(Y)\)</span> instead of <span class="math inline">\(Y\)</span>.</p>
<p>The corresponding regression then model is</p>
<p><span class="math display">\[ \ln(Y_i) = \beta_0 + \beta_1 \times X_i + u_i \ \ , \ \ i=1,...,n. \]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># estimate a log-linear model </span>
LogLinear_model &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(score) <span class="op">~</span><span class="st"> </span>income, <span class="dt">data =</span> CASchools)

<span class="co"># compute a robust summary</span>
<span class="kw">coeftest</span>(LogLinear_model, 
         <span class="dt">vcov =</span> <span class="kw">vcovHC</span>(LogLinear_model, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>)
         )</code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##               Estimate Std. Error  t value  Pr(&gt;|t|)    
## (Intercept) 6.43936234 0.00289382 2225.210 &lt; 2.2e-16 ***
## income      0.00284407 0.00017509   16.244 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The estimated regression function is <span class="math display">\[\widehat{\ln(TestScore)} = 6.439 + 0.00284 \times income.\]</span> Since we are interested in <span class="math inline">\(\ln(Y)\)</span> rather than <span class="math inline">\(Y\)</span>, we <it>do not</it> retransform the dependent variable.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># scatterplot</span>
<span class="kw">plot</span>(<span class="kw">log</span>(score) <span class="op">~</span><span class="st"> </span>income, 
     <span class="dt">col=</span><span class="st">&quot;steelblue&quot;</span>, 
     <span class="dt">pch=</span><span class="dv">20</span>, 
     <span class="dt">data =</span> CASchools,
     <span class="dt">main =</span> <span class="st">&quot;Log-Linear Regression Function&quot;</span>
     )

<span class="co"># add the Log-Linear regression line</span>
order_id  &lt;-<span class="st"> </span><span class="kw">order</span>(CASchools<span class="op">$</span>income)

<span class="kw">lines</span>(CASchools<span class="op">$</span>income[order_id], 
      <span class="kw">fitted</span>(LogLinear_model)[order_id], 
      <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, 
      <span class="dt">lwd =</span> <span class="dv">2</span>)</code></pre></div>
<p><img src="URFITE_files/figure-html/unnamed-chunk-13-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Note that the <span class="math inline">\(Y\)</span>-Axis is now log-transformed.</p>
<p>In a log-linear model, a one-unit change in <span class="math inline">\(X\)</span> is associated with an estimated <span class="math inline">\(100 \times \hat\beta_1 \%\)</span> change in <span class="math inline">\(Y\)</span>. This time we left the <span class="math inline">\(X\)</span> values unchanged.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># do predictions</span>
Y_hat &lt;-<span class="st"> </span><span class="kw">predict</span>(LogLinear_model, <span class="dt">newdata =</span> new_data)

<span class="co"># calculate changes</span>
changes &lt;-<span class="st"> </span><span class="kw">matrix</span>(Y_hat, <span class="dt">nrow =</span> <span class="dv">2</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>)
changes[ ,<span class="dv">2</span>] <span class="op">-</span><span class="st"> </span>changes[ ,<span class="dv">1</span>]</code></pre></div>
<pre><code>## [1] 0.00284407 0.00284407</code></pre>
</div>
<div id="case-iii-x-and-y-are-in-logarithms" class="section level4 unnumbered">
<h4>Case III: <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are in logarithms</h4>
<p>The log-log regression model is</p>
<p><span class="math display">\[\ln(Y_i) = \beta_0 + \beta_1 \times \ln(X_i) + u_i \ \ , \ \ i=1,...,n. \]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Estimate the log-log model</span>
LogLog_model &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(score) <span class="op">~</span><span class="st"> </span><span class="kw">log</span>(income), <span class="dt">data =</span> CASchools)

<span class="co"># print robust summary to the console</span>
<span class="kw">coeftest</span>(LogLog_model, 
         <span class="dt">vcov =</span> <span class="kw">vcovHC</span>(LogLog_model, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>)
         )</code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##              Estimate Std. Error  t value  Pr(&gt;|t|)    
## (Intercept) 6.3363494  0.0059246 1069.501 &lt; 2.2e-16 ***
## log(income) 0.0554190  0.0021446   25.841 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The estimated regression function hence is <span class="math display">\[\widehat{\ln(TestScore)} = 6.336 + 0.0554 \times income.\]</span></p>
<div class="unfolded">
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># scatterplot</span>
<span class="kw">plot</span>(<span class="kw">log</span>(score) <span class="op">~</span><span class="st"> </span>income, 
     <span class="dt">data =</span> CASchools,
     <span class="dt">col =</span> <span class="st">&quot;steelblue&quot;</span>, 
     <span class="dt">pch =</span> <span class="dv">20</span>,
     <span class="dt">main =</span> <span class="st">&quot;Log-Log Regression Function&quot;</span>)

<span class="co"># plot the estimate log-log regression line</span>
<span class="kw">lines</span>(<span class="kw">sort</span>(CASchools<span class="op">$</span>income), 
      <span class="kw">fitted</span>(LogLog_model)[<span class="kw">order</span>(CASchools<span class="op">$</span>income)], 
      <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, 
      <span class="dt">lwd =</span> <span class="dv">2</span>)</code></pre></div>
<p><img src="URFITE_files/figure-html/unnamed-chunk-15-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<p>In a log-log model, a <span class="math inline">\(1\%\)</span> change in <span class="math inline">\(X\)</span> is associated with an estimated <span class="math inline">\(\hat\beta_1 \%\)</span> change in <span class="math inline">\(Y\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># predict Y</span>
Y_hat &lt;-<span class="st"> </span><span class="kw">predict</span>(LogLog_model, <span class="dt">newdata =</span> new_data)

<span class="co"># compute changes</span>
changes &lt;-<span class="st"> </span><span class="kw">matrix</span>(Y_hat, <span class="dt">nrow =</span> <span class="dv">2</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>)
changes[ ,<span class="dv">2</span>] <span class="op">-</span><span class="st"> </span>changes[ ,<span class="dv">1</span>]</code></pre></div>
<pre><code>## [1] 0.005281992 0.001368439</code></pre>
<p>Key Concept 8.2 summarizes the three logarithmic regression models.</p>
<div class="keyconcept">
<h3 class="right">
Key Concept 8.2
</h3>
<h3 class="left">
Logarithms in Regression: Three Cases
</h3>
<p>
<p>Logarithms can be used to transform the dependent variable <span class="math inline">\(Y\)</span> or the independent variable <span class="math inline">\(X\)</span>, or both (the variable being transformed must be positive). The following table summarizes these three cases and the interpretation of the regression coefficient <span class="math inline">\(\beta_1\)</span>. In each case, <span class="math inline">\(\beta_1\)</span>, can be estimated by applying OLS after taking the logarithm(s) of the dependent and/or the independent variable.</p>
<table>
<thead>
<tr class="header">
<th align="left">
Case
</th>
<th align="left">
Model Specification
</th>
<th align="left">
Interpretation of <span class="math inline">\(\beta_1\)</span>
</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">
<span class="math inline">\((I)\)</span>
</td>
<td align="left">
<span class="math inline">\(Y_i = \beta_0 + \beta_1 \ln{X_i} + u_i\)</span>
</td>
<td align="left">
A <span class="math inline">\(1 \%\)</span> change in <span class="math inline">\(X\)</span> is associated with a change in <span class="math inline">\(Y\)</span> of <span class="math inline">\(0.01 \times \beta_1\)</span>.
</td>
</tr>
<tr class="even">
<td align="left">
<span class="math inline">\((II)\)</span>
</td>
<td align="left">
<span class="math inline">\(\ln(Y_i) = \beta_0 + \beta_1 X_i + u_i\)</span>
</td>
<td align="left">
A change in <span class="math inline">\(X\)</span> by one unit (<span class="math inline">\(\Delta X = 1\)</span>) is associated with a <span class="math inline">\(100 \times \beta_1 \%\)</span> change in <span class="math inline">\(Y\)</span>.
</td>
</tr>
<tr class="odd">
<td align="left">
<span class="math inline">\((III)\)</span>
</td>
<td align="left">
<span class="math inline">\(\ln(Y_i) = \beta_0 + \beta_1 \ln(X_i) + u_i\)</span>
</td>
<td align="left">
A <span class="math inline">\(1 \%\)</span> change in <span class="math inline">\(X\)</span> is associated with a <span class="math inline">\(100 \times \beta_1 \%\)</span> change in <span class="math inline">\(Y\)</span>, so <span class="math inline">\(\beta_1\)</span> is the elasticity of <span class="math inline">\(Y\)</span> with respect to <span class="math inline">\(X\)</span>.
</td>
</tr>
</tbody>
</table>
</p>
</div>
<p>Of course we can also estimate a <it>polylog</it> model like</p>
<p><span class="math display">\[ TestScore_i = \beta_0 + \beta_1 \times \ln(income_i) + \beta_2 \times \ln(income_i)^2 + \beta_3 \times \ln(income_i)^3 + u_i \]</span></p>
<p>which models the dependent variable <span class="math inline">\(TestScore\)</span> by a third-degree polynomial of the log-transformed regressor <span class="math inline">\(income\)</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># estimate the polylog model</span>
polyLog_model &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span><span class="kw">log</span>(income) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(<span class="kw">log</span>(income)<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(<span class="kw">log</span>(income)<span class="op">^</span><span class="dv">3</span>), 
                    <span class="dt">data =</span> CASchools)

<span class="co"># print robust summary to the console</span>
<span class="kw">coeftest</span>(polyLog_model, 
         <span class="dt">vcov =</span> <span class="kw">vcovHC</span>(polyLog_model, <span class="dt">type =</span> <span class="st">&quot;HC1&quot;</span>))</code></pre></div>
<pre><code>## 
## t test of coefficients:
## 
##                  Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)      486.1341    79.3825  6.1239 2.115e-09 ***
## log(income)      113.3820    87.8837  1.2901    0.1977    
## I(log(income)^2) -26.9111    31.7457 -0.8477    0.3971    
## I(log(income)^3)   3.0632     3.7369  0.8197    0.4128    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Which of the models presented here is the most suitable? Comparing by <span class="math inline">\(\overline{R^2}\)</span> we find that, leaving out the log-linear model, all models have a similar fit. In the class of polynomial models, the cubic specification has the highest <span class="math inline">\(\overline{R^2}\)</span> whereas the linear-log specification is the best of the log-models (check this!). Let us first compare both models graphically by plotting the corresponding estimated regression functions</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># scatter plot</span>
<span class="kw">plot</span>(score <span class="op">~</span><span class="st"> </span>income, 
     <span class="dt">data =</span> CASchools,
     <span class="dt">col =</span> <span class="st">&quot;steelblue&quot;</span>, 
     <span class="dt">pch =</span> <span class="dv">20</span>,
     <span class="dt">main =</span> <span class="st">&quot;Linear-Log and Cubic Regression Functions&quot;</span>)

<span class="co"># add Linear-Log regression line</span>
order_id  &lt;-<span class="st"> </span><span class="kw">order</span>(CASchools<span class="op">$</span>income)

<span class="kw">lines</span>(CASchools<span class="op">$</span>income[order_id],
      <span class="kw">fitted</span>(LinearLog_model)[order_id], 
      <span class="dt">col =</span> <span class="st">&quot;darkgreen&quot;</span>, 
      <span class="dt">lwd =</span> <span class="dv">2</span>)

<span class="co"># add cubic regression line</span>
<span class="kw">lines</span>(<span class="dt">x =</span> CASchools<span class="op">$</span>income[order_id], 
      <span class="dt">y =</span> <span class="kw">fitted</span>(cubic_model)[order_id],
      <span class="dt">col=</span><span class="st">&quot;darkred&quot;</span>, 
      <span class="dt">lwd=</span><span class="dv">2</span>) </code></pre></div>
<p><img src="URFITE_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>We see that both regression lines are nearly identical. Here the linear-log model is preferable since it has a slightly higher <span class="math inline">\(\overline{R^2}\)</span> and is more parsimonious in terms of regressors: it does not need higher-degree polynomials.</p>
</div>
</div>
<div id="interactions-between-independent-variables" class="section level2">
<h2><span class="header-section-number">8.1</span> Interactions Between Independent Variables</h2>
<p>There are research questions where it is interesting to know how the effect on <span class="math inline">\(Y\)</span> of a change in one independent variables dependends on the value of another independent variable. For example, we could ask if districts with many english learners benefit differentially from a decrease in class sizes than those with few english learning students. To answer this, we need to include an interaction term into a multiple regression model. We will consider three cases:</p>
<ol style="list-style-type: decimal">
<li><p>Interactions between two binary variables</p></li>
<li><p>Interactions between a binary and a continuous variable</p></li>
<li><p>Interactions between two continuous variables</p></li>
</ol>
<p>The following subsections discuss those cases briefly and demonstrate how to perform such regressions using <tt>R</tt>.</p>
<div id="interactions-between-two-binary-variables" class="section level4 unnumbered">
<h4>Interactions Between Two Binary Variables</h4>
<p>Take two binary variables <span class="math inline">\(D_1\)</span> and <span class="math inline">\(D_2\)</span> and the population regression</p>
<p><span class="math display">\[ Y_i = \beta_0 + \beta_1 \times D_{1i} + \beta_2 \times D_{2i} + u_i. \]</span></p>
<p>Now assume</p>
<span class="math display">\[\begin{align}
  Y_i=&amp; \, \ln(Earnings_i),\\
  \\
  D_{1i} =&amp; \,
   \begin{cases}
      1 &amp; \text{if $i^{th}$ person has a college degree} \\
      0 &amp; \text{else},
    \end{cases} \\
    \\
  D_{2i} =&amp; \, 
    \begin{cases}
      1 &amp; \text{if $i^{th}$ person is female} \\
      0 &amp; \text{if $i^{th}$ person is male}.
    \end{cases}\\
\end{align}\]</span>
<p>By now You should know that <span class="math inline">\(\beta_1\)</span> measures the average difference in <span class="math inline">\(\ln(Earnings)\)</span> between individuals with and without a college degree and <span class="math inline">\(\beta_2\)</span> is the gender differential in <span class="math inline">\(\ln(Earnings)\)</span>, ceteris paribus. This model <it>does not</it> allow us to determine if there is a geneder specific effect of heaving a college degree and, if so, how strong this is. Luckily it is easy to come up with a model specification that allows to investigate this:</p>
<p><span class="math display">\[ Y_i = \beta_0 + \beta_1 \times D_{1i} + \beta_2 \times D_{2i} + \beta_3 \times (D_{1i} \times D_{2i}) + u_i \]</span></p>
<p><span class="math inline">\((D_{1i} \times D_{2i})\)</span> is called an interaction term and <span class="math inline">\(\beta_3\)</span> measures the difference in the effect of having a college degree for women versus men.</p>
<div class="keyconcept">
<h3 class="right">
Key Concept 8.3
</h3>
<h3 class="left">
A Method for Interpreting Coefficients in Regression with Binary Variables
</h3>
<p>Compute expected values of <span class="math inline">\(Y\)</span> for each possible set described by the set of binary variables. Compare the expected values. The coefficients can be expressed either as expected values or as the difference between at least two expected values.</p>
</div>
<p>Following Key Concepts 8.1 we have</p>
<span class="math display">\[\begin{align*}
  E(Y_i\vert D_{1i}=0, D_{2i} = d_2) =&amp; \, \beta_0 + \beta_1 \times 0 + \beta_2 \times d_2 + \beta_3 \times (0 \times d_2) \\
  =&amp; \, \beta_0 + \beta_2 \times d_2.
\end{align*}\]</span>
<p>Changing <span class="math inline">\(D_{1i}\)</span> from <span class="math inline">\(0\)</span> to <span class="math inline">\(1\)</span> we obtain</p>
<span class="math display">\[\begin{align*}
  E(Y_i\vert D_{1i}=1, D_{2i} = d_2) =&amp; \, \beta_0 + \beta_1 \times 1 + \beta_2 \times d_2 + \beta_3 \times (1 \times d_2) \\
  =&amp; \, \beta_0 + \beta_1 + \beta_2 \times d_2 + \beta_3 d_2
\end{align*}\]</span>
<p>and hence the overall effect is</p>
<p><span class="math display">\[ E(Y_i\vert D_{1i}=1, D_{2i} = d_2) - E(Y_i\vert D_{1i}=0, D_{2i} = d_2) = \beta_1 + \beta_3 d_2 \]</span> so the effect is a difference of expected values.</p>
<div id="application-to-the-student-teacher-ratio-and-the-percentage-of-english-learners" class="section level5 unnumbered">
<h5>Application to the student-teacher ratio and the percentage of English learners</h5>
<p>Now let</p>
<span class="math display">\[\begin{align*}
  HiSTR =&amp; \, 
    \begin{cases}
      1, &amp; \text{if $STR \geq 20$} \\
      0, &amp; \text{else},
    \end{cases} \\
  \\
  HiEL =&amp; \,
    \begin{cases}
      1, &amp; \text{if $PctEL \geq 10\%$} \\
      0, &amp; \text{else}.
    \end{cases}
\end{align*}\]</span>
<p>We may use <tt>R</tt> construct the variables above.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Add HiSTR to CASchools</span>
CASchools<span class="op">$</span>HiSTR &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(CASchools<span class="op">$</span>size <span class="op">&gt;=</span><span class="st"> </span><span class="dv">20</span>)

<span class="co"># Add HiEL to CASchools</span>
CASchools<span class="op">$</span>HiEL &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(CASchools<span class="op">$</span>english <span class="op">&gt;=</span><span class="st"> </span><span class="dv">10</span>)</code></pre></div>
<p>We proceed by estimating the model</p>
<p><span class="math display">\[ TestScore_i = \beta_0 + \beta_1 \times HiSTR + \beta_2 \times HiEL + \beta_3 \times (HiSTR \times HiEL) + u_i \]</span></p>
<p>using <code>lm()</code>. There are several ways to add an interaction term to the model <code>formula</code> argument of <code>lm()</code> but the most intuitive is to use the product of both variables <code>HiEL * HiSTR</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># estimate the model with binary interaction term</span>
bi_model &lt;-<span class="st"> </span><span class="kw">lm</span>(score <span class="op">~</span><span class="st"> </span>HiSTR <span class="op">+</span><span class="st"> </span>HiEL <span class="op">+</span><span class="st"> </span>HiSTR <span class="op">*</span><span class="st"> </span>HiEL, <span class="dt">data =</span> CASchools)

<span class="co"># print summary</span>
<span class="kw">summary</span>(bi_model)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = score ~ HiSTR + HiEL + HiSTR * HiEL, data = CASchools)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -39.078 -10.679  -1.282   9.665  45.522 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  664.143      1.316 504.852  &lt; 2e-16 ***
## HiSTR         -1.908      2.235  -0.854    0.394    
## HiEL         -18.316      2.144  -8.544 2.49e-16 ***
## HiSTR:HiEL    -3.260      3.223  -1.012    0.312    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 16.06 on 416 degrees of freedom
## Multiple R-squared:  0.2948, Adjusted R-squared:  0.2897 
## F-statistic: 57.97 on 3 and 416 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>The estimated regression model is</p>
<p><span class="math display">\[ \widehat{TestScore} = 664.1 - 1.9 \times HiSTR - 18.3 \times HiEL - 3.3 \times (HiSTR \times HiEL) \]</span></p>
<p>and it predicts that the effect of moving from a school district with a low student-teacher ratio to a district with a high student-teacher ratio, depending on high or low percentage of english learners is <span class="math inline">\(-1.9-3.3\times HiEL\)</span>. So for districts with a low share of english learners (<span class="math inline">\(HiEL = 0\)</span>), the estimated effect is a decrease of <span class="math inline">\(1.9\)</span> points in test scores while for districts with a big fraction of english learner (<span class="math inline">\(HiEL = 1\)</span>), the predicted decrease in test scores amounts to <span class="math inline">\(1.9 + 3.3 = 5.2\)</span> points.</p>
<p>We can also use the model to estimate the mean test score for each combination of binary variables.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># estimate means for all combinations</span>
<span class="kw">predict</span>(bi_model, <span class="dt">newdata =</span> <span class="kw">data.frame</span>(<span class="st">&quot;HiSTR&quot;</span>=<span class="dv">0</span>, <span class="st">&quot;HiEL&quot;</span>=<span class="dv">0</span>))</code></pre></div>
<pre><code>##        1 
## 664.1433</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(bi_model, <span class="dt">newdata =</span> <span class="kw">data.frame</span>(<span class="st">&quot;HiSTR&quot;</span>=<span class="dv">0</span>, <span class="st">&quot;HiEL&quot;</span>=<span class="dv">1</span>))</code></pre></div>
<pre><code>##        1 
## 645.8278</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(bi_model, <span class="dt">newdata =</span> <span class="kw">data.frame</span>(<span class="st">&quot;HiSTR&quot;</span>=<span class="dv">1</span>, <span class="st">&quot;HiEL&quot;</span>=<span class="dv">0</span>))</code></pre></div>
<pre><code>##        1 
## 662.2354</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(bi_model, <span class="dt">newdata =</span> <span class="kw">data.frame</span>(<span class="st">&quot;HiSTR&quot;</span>=<span class="dv">1</span>, <span class="st">&quot;HiEL&quot;</span>=<span class="dv">1</span>))</code></pre></div>
<pre><code>##        1 
## 640.6598</code></pre>
</div>
</div>
<div id="interactions-between-a-continuous-and-a-binary-variable" class="section level4 unnumbered">
<h4>Interactions Between a Continuous and a Binary Variable</h4>
</div>
<div id="interactions-between-two-continuous-variables" class="section level4 unnumbered">
<h4>Interactions Between Two Continuous Variables</h4>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="placeholder.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 1
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/08-ch8.Rmd",
"text": "Edit"
},
"download": ["URFITE.pdf", "URFITE.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
