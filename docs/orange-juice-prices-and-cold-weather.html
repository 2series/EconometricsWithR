<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Using R for Introduction to Econometrics</title>
  <meta name="description" content="Using R for Introduction to Econometrics">
  <meta name="generator" content="bookdown 0.7.1 and GitBook 2.6.7">

  <meta property="og:title" content="Using R for Introduction to Econometrics" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="Emwikts1970/URFITE-Bookdown" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Using R for Introduction to Econometrics" />
  
  
  

<meta name="author" content="Christoph Hanck, Martin Arnold, Alexander Gerber and Martin Schmelzer">


<meta name="date" content="2018-03-19">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="estimation-of-dynamic-causal-effects-with-strictly-exogeneous-regressors.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.0/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.7.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="libs/plotlyjs-1.29.2/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotlyjs-1.29.2/plotly-latest.min.js"></script>
<script src="js/hideOutput.js"></script>
<script type="text/javascript" src="MathJax-2.7.2/MathJax.js?config=default"></script>

 <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        extensions: ["tex2jax.js", "TeX/AMSmath.js"],
        tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
        jax: ["input/TeX","output/CommonHTML"]
      });
      MathJax.Hub.processSectionDelay = 0;
  </script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110299877-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110299877-1');
</script>

<!-- open review block -->

<script async defer src="https://hypothes.is/embed.js"></script>

<!-- datacamp-light-latest -->

<script src="https://cdn.datacamp.com/datacamp-light-latest.min.js"></script>


<!-- <script src="js/d3.v3.min.js"></script>
<script src="js/leastsquares.js"></script>
<script src="js/d3functions.js"></script>
<script src="d3.slider.js"></script>
<script src="slrm.js"></script> -->


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; background-color: #f8f8f8; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
pre, code { background-color: #f8f8f8; }
code > span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code > span.dt { color: #204a87; } /* DataType */
code > span.dv { color: #0000cf; } /* DecVal */
code > span.bn { color: #0000cf; } /* BaseN */
code > span.fl { color: #0000cf; } /* Float */
code > span.ch { color: #4e9a06; } /* Char */
code > span.st { color: #4e9a06; } /* String */
code > span.co { color: #8f5902; font-style: italic; } /* Comment */
code > span.ot { color: #8f5902; } /* Other */
code > span.al { color: #ef2929; } /* Alert */
code > span.fu { color: #000000; } /* Function */
code > span.er { color: #a40000; font-weight: bold; } /* Error */
code > span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #000000; } /* Constant */
code > span.sc { color: #000000; } /* SpecialChar */
code > span.vs { color: #4e9a06; } /* VerbatimString */
code > span.ss { color: #4e9a06; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #000000; } /* Variable */
code > span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code > span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code > span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code > span.ex { } /* Extension */
code > span.at { color: #c4a000; } /* Attribute */
code > span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code > span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="toc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">URFITE</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="probability-theory.html"><a href="probability-theory.html"><i class="fa fa-check"></i><b>2</b> Probability Theory</a><ul>
<li class="chapter" data-level="2.1" data-path="random-variables-and-probability-distributions.html"><a href="random-variables-and-probability-distributions.html"><i class="fa fa-check"></i><b>2.1</b> Random Variables and Probability Distributions</a><ul>
<li class="chapter" data-level="" data-path="random-variables-and-probability-distributions.html"><a href="random-variables-and-probability-distributions.html#probability-distributions-of-discrete-random-variables"><i class="fa fa-check"></i>Probability Distributions of Discrete Random Variables</a></li>
<li class="chapter" data-level="" data-path="random-variables-and-probability-distributions.html"><a href="random-variables-and-probability-distributions.html#bernoulli-trials"><i class="fa fa-check"></i>Bernoulli Trials</a></li>
<li class="chapter" data-level="" data-path="random-variables-and-probability-distributions.html"><a href="random-variables-and-probability-distributions.html#expected-values-mean-and-variance"><i class="fa fa-check"></i>Expected Values, Mean and Variance</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="probability-distributions-of-continuous-random-variables.html"><a href="probability-distributions-of-continuous-random-variables.html"><i class="fa fa-check"></i><b>2.2</b> Probability Distributions of Continuous Random Variables</a><ul>
<li class="chapter" data-level="" data-path="probability-distributions-of-continuous-random-variables.html"><a href="probability-distributions-of-continuous-random-variables.html#the-normal-distribution"><i class="fa fa-check"></i>The Normal Distribution</a></li>
<li class="chapter" data-level="" data-path="probability-distributions-of-continuous-random-variables.html"><a href="probability-distributions-of-continuous-random-variables.html#the-chi-squared-distribution"><i class="fa fa-check"></i>The Chi-Squared Distribution</a></li>
<li><a href="probability-distributions-of-continuous-random-variables.html#thetdist">The Student <span class="math inline">\(t\)</span> Distribution</a></li>
<li><a href="probability-distributions-of-continuous-random-variables.html#the-f-distribution">The <span class="math inline">\(F\)</span> Distribution</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="random-sampling-and-the-distribution-of-sample-averages.html"><a href="random-sampling-and-the-distribution-of-sample-averages.html"><i class="fa fa-check"></i><b>2.3</b> Random Sampling and the Distribution of Sample Averages</a><ul>
<li class="chapter" data-level="" data-path="random-sampling-and-the-distribution-of-sample-averages.html"><a href="random-sampling-and-the-distribution-of-sample-averages.html#mean-and-variance-of-the-sample-mean"><i class="fa fa-check"></i>Mean and Variance of the Sample Mean</a></li>
<li class="chapter" data-level="" data-path="random-sampling-and-the-distribution-of-sample-averages.html"><a href="random-sampling-and-the-distribution-of-sample-averages.html#large-sample-approximations-to-sampling-distributions"><i class="fa fa-check"></i>Large Sample Approximations to Sampling Distributions</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="exercises.html"><a href="exercises.html"><i class="fa fa-check"></i><b>2.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="a-review-of-statistics-using-r.html"><a href="a-review-of-statistics-using-r.html"><i class="fa fa-check"></i><b>3</b> A Review of Statistics using R</a><ul>
<li class="chapter" data-level="3.1" data-path="estimation-of-the-population-mean.html"><a href="estimation-of-the-population-mean.html"><i class="fa fa-check"></i><b>3.1</b> Estimation of the Population Mean</a></li>
<li class="chapter" data-level="3.2" data-path="properties-of-the-sample-mean.html"><a href="properties-of-the-sample-mean.html"><i class="fa fa-check"></i><b>3.2</b> Properties of the Sample Mean</a></li>
<li class="chapter" data-level="3.3" data-path="hypothesis-tests-concerning-the-population-mean.html"><a href="hypothesis-tests-concerning-the-population-mean.html"><i class="fa fa-check"></i><b>3.3</b> Hypothesis Tests Concerning the Population Mean</a><ul>
<li><a href="hypothesis-tests-concerning-the-population-mean.html#p-value"><span class="math inline">\(p\)</span>-Value</a></li>
<li><a href="hypothesis-tests-concerning-the-population-mean.html#calculating-the-p-value-when-sigma_y-is-known">Calculating the <span class="math inline">\(p\)</span>-Value When <span class="math inline">\(\sigma_Y\)</span> Is Known</a></li>
<li class="chapter" data-level="" data-path="hypothesis-tests-concerning-the-population-mean.html"><a href="hypothesis-tests-concerning-the-population-mean.html#sample-variance-sample-standard-deviation-and-standard-error"><i class="fa fa-check"></i>Sample Variance, Sample Standard Deviation and Standard Error</a></li>
<li><a href="hypothesis-tests-concerning-the-population-mean.html#calculating-the-p-value-when-sigma_y-is-unknown">Calculating the <span class="math inline">\(p\)</span>-value When <span class="math inline">\(\sigma_Y\)</span> is Unknown</a></li>
<li><a href="hypothesis-tests-concerning-the-population-mean.html#the-t-statistic">The <span class="math inline">\(t\)</span>-statistic</a></li>
<li class="chapter" data-level="" data-path="hypothesis-tests-concerning-the-population-mean.html"><a href="hypothesis-tests-concerning-the-population-mean.html#hypothesis-testing-with-a-prespecified-significance-level"><i class="fa fa-check"></i>Hypothesis Testing with a Prespecified Significance Level</a></li>
<li class="chapter" data-level="" data-path="hypothesis-tests-concerning-the-population-mean.html"><a href="hypothesis-tests-concerning-the-population-mean.html#one-sided-alternatives"><i class="fa fa-check"></i>One-sided Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="confidence-intervals-for-the-population-mean.html"><a href="confidence-intervals-for-the-population-mean.html"><i class="fa fa-check"></i><b>3.4</b> Confidence intervals for the Population Mean</a></li>
<li class="chapter" data-level="3.5" data-path="comparing-means-from-different-populations.html"><a href="comparing-means-from-different-populations.html"><i class="fa fa-check"></i><b>3.5</b> Comparing Means from Different Populations</a></li>
<li class="chapter" data-level="3.6" data-path="an-application-to-the-gender-gap-of-earnings.html"><a href="an-application-to-the-gender-gap-of-earnings.html"><i class="fa fa-check"></i><b>3.6</b> An Application to the Gender Gap of Earnings</a></li>
<li class="chapter" data-level="3.7" data-path="scatterplots-sample-covariance-and-sample-correlation.html"><a href="scatterplots-sample-covariance-and-sample-correlation.html"><i class="fa fa-check"></i><b>3.7</b> Scatterplots, Sample Covariance and Sample Correlation</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="lrwor.html"><a href="lrwor.html"><i class="fa fa-check"></i><b>4</b> Linear Regression with One Regressor</a><ul>
<li class="chapter" data-level="4.1" data-path="estimating-the-coefficients-of-the-linear-regression-model.html"><a href="estimating-the-coefficients-of-the-linear-regression-model.html"><i class="fa fa-check"></i><b>4.1</b> Estimating the Coefficients of the Linear Regression Model</a><ul>
<li class="chapter" data-level="" data-path="estimating-the-coefficients-of-the-linear-regression-model.html"><a href="estimating-the-coefficients-of-the-linear-regression-model.html#the-ordinary-least-squares-estimator"><i class="fa fa-check"></i>The Ordinary Least Squares Estimator</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="measures-of-fit.html"><a href="measures-of-fit.html"><i class="fa fa-check"></i><b>4.2</b> Measures of Fit</a><ul>
<li><a href="measures-of-fit.html#the-r2">The <span class="math inline">\(R^2\)</span></a></li>
<li class="chapter" data-level="" data-path="measures-of-fit.html"><a href="measures-of-fit.html#standard-error-of-the-regression"><i class="fa fa-check"></i>Standard Error of the Regression</a></li>
<li class="chapter" data-level="" data-path="measures-of-fit.html"><a href="measures-of-fit.html#application-to-the-test-score-data"><i class="fa fa-check"></i>Application to the Test Score Data</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="the-least-squares-assumptions.html"><a href="the-least-squares-assumptions.html"><i class="fa fa-check"></i><b>4.3</b> The Least Squares Assumptions</a><ul>
<li class="chapter" data-level="" data-path="the-least-squares-assumptions.html"><a href="the-least-squares-assumptions.html#assumption-1-the-error-term-has-conditional-mean-of-zero"><i class="fa fa-check"></i>Assumption #1: The Error Term has Conditional Mean of Zero</a></li>
<li><a href="the-least-squares-assumptions.html#assumption-2-all-x_i-y_i-are-independently-and-identically-distributed">Assumption #2: All <span class="math inline">\((X_i, Y_i)\)</span> are Independently and Identically Distributed</a></li>
<li class="chapter" data-level="" data-path="the-least-squares-assumptions.html"><a href="the-least-squares-assumptions.html#assumption-3-large-outliers-are-unlikely"><i class="fa fa-check"></i>Assumption #3: Large outliers are unlikely</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="tsdotoe.html"><a href="tsdotoe.html"><i class="fa fa-check"></i><b>4.4</b> The Sampling Distribution of the OLS Estimator</a><ul>
<li class="chapter" data-level="" data-path="tsdotoe.html"><a href="tsdotoe.html#r-simulation-study-1"><i class="fa fa-check"></i>R Simulation Study 1</a></li>
<li class="chapter" data-level="" data-path="tsdotoe.html"><a href="tsdotoe.html#r-simulation-study-2"><i class="fa fa-check"></i>R Simulation Study 2</a></li>
<li class="chapter" data-level="" data-path="tsdotoe.html"><a href="tsdotoe.html#r-simulation-study-3"><i class="fa fa-check"></i>R Simulation Study 3</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="exercises-1.html"><a href="exercises-1.html"><i class="fa fa-check"></i><b>4.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html"><a href="hypothesis-tests-and-confidence-intervals-in-the-simple-linear-regression-model.html"><i class="fa fa-check"></i><b>5</b> Hypothesis Tests and Confidence Intervals in the Simple Linear Regression Model</a><ul>
<li class="chapter" data-level="5.1" data-path="testing-two-sided-hypotheses-concerning-beta-1.html"><a href="testing-two-sided-hypotheses-concerning-beta-1.html"><i class="fa fa-check"></i><b>5.1</b> Testing Two-Sided Hypotheses Concerning <span class="math inline">\(\beta_1\)</span></a></li>
<li class="chapter" data-level="5.2" data-path="confidence-intervals-for-regression-coefficients.html"><a href="confidence-intervals-for-regression-coefficients.html"><i class="fa fa-check"></i><b>5.2</b> Confidence Intervals for Regression Coefficients</a><ul>
<li class="chapter" data-level="" data-path="confidence-intervals-for-regression-coefficients.html"><a href="confidence-intervals-for-regression-coefficients.html#r-simulation-study-5.1"><i class="fa fa-check"></i>R Simulation Study 5.1</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="regression-when-x-is-a-binary-variable.html"><a href="regression-when-x-is-a-binary-variable.html"><i class="fa fa-check"></i><b>5.3</b> Regression when <span class="math inline">\(X\)</span> is a Binary Variable</a></li>
<li class="chapter" data-level="5.4" data-path="heteroskedasticity-and-homoskedasticity.html"><a href="heteroskedasticity-and-homoskedasticity.html"><i class="fa fa-check"></i><b>5.4</b> Heteroskedasticity and Homoskedasticity</a><ul>
<li class="chapter" data-level="" data-path="heteroskedasticity-and-homoskedasticity.html"><a href="heteroskedasticity-and-homoskedasticity.html#a-real-world-example-for-heteroskedasticity"><i class="fa fa-check"></i>A Real-World Example for Heteroskedasticity</a></li>
<li class="chapter" data-level="" data-path="heteroskedasticity-and-homoskedasticity.html"><a href="heteroskedasticity-and-homoskedasticity.html#should-we-care-about-heteroskedasticity"><i class="fa fa-check"></i>Should We Care About Heteroskedasticity?</a></li>
<li class="chapter" data-level="" data-path="heteroskedasticity-and-homoskedasticity.html"><a href="heteroskedasticity-and-homoskedasticity.html#computation-of-heteroskedasticity-robust-standard-errors"><i class="fa fa-check"></i>Computation of Heteroskedasticity-Robust Standard Errors</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="the-gauss-markov-theorem.html"><a href="the-gauss-markov-theorem.html"><i class="fa fa-check"></i><b>5.5</b> The Gauss-Markov Theorem</a><ul>
<li class="chapter" data-level="" data-path="the-gauss-markov-theorem.html"><a href="the-gauss-markov-theorem.html#r-simulation-study-blue-estimator"><i class="fa fa-check"></i>R Simulation Study: BLUE Estimator</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="using-the-t-statistic-in-regression-when-the-sample-size-is-small.html"><a href="using-the-t-statistic-in-regression-when-the-sample-size-is-small.html"><i class="fa fa-check"></i><b>5.6</b> Using the <span class="math inline">\(t\)</span>-Statistic in Regression When the Sample Size Is Small</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="regression-models-with-multiple-regressors.html"><a href="regression-models-with-multiple-regressors.html"><i class="fa fa-check"></i><b>6</b> Regression Models with Multiple Regressors</a><ul>
<li class="chapter" data-level="6.1" data-path="omitted-variable-bias.html"><a href="omitted-variable-bias.html"><i class="fa fa-check"></i><b>6.1</b> Omitted Variable Bias</a></li>
<li class="chapter" data-level="6.2" data-path="the-multiple-regression-model.html"><a href="the-multiple-regression-model.html"><i class="fa fa-check"></i><b>6.2</b> The Multiple Regression Model</a></li>
<li class="chapter" data-level="6.3" data-path="measures-of-fit-in-multiple-regression.html"><a href="measures-of-fit-in-multiple-regression.html"><i class="fa fa-check"></i><b>6.3</b> Measures of Fit in Multiple Regression</a></li>
<li class="chapter" data-level="6.4" data-path="ols-assumptions-in-multiple-regression.html"><a href="ols-assumptions-in-multiple-regression.html"><i class="fa fa-check"></i><b>6.4</b> OLS Assumptions in Multiple Regression</a><ul>
<li class="chapter" data-level="" data-path="ols-assumptions-in-multiple-regression.html"><a href="ols-assumptions-in-multiple-regression.html#multicollinearity"><i class="fa fa-check"></i>Multicollinearity</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="the-distribution-of-the-ols-estimators-in-multiple-regression.html"><a href="the-distribution-of-the-ols-estimators-in-multiple-regression.html"><i class="fa fa-check"></i><b>6.5</b> The Distribution of the OLS Estimators in Multiple Regression</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html"><a href="hypothesis-tests-and-confidence-intervals-in-multiple-regression.html"><i class="fa fa-check"></i><b>7</b> Hypothesis Tests and Confidence intervals in Multiple Regression</a><ul>
<li class="chapter" data-level="7.1" data-path="hypothesis-tests-and-confidence-intervals-for-a-single-coefficient.html"><a href="hypothesis-tests-and-confidence-intervals-for-a-single-coefficient.html"><i class="fa fa-check"></i><b>7.1</b> Hypothesis Tests and Confidence Intervals for a Single Coefficient</a></li>
<li class="chapter" data-level="7.2" data-path="an-application-to-test-scores-and-the-student-teacher-ratio.html"><a href="an-application-to-test-scores-and-the-student-teacher-ratio.html"><i class="fa fa-check"></i><b>7.2</b> An Application to Test Scores and the Student-Teacher Ratio</a><ul>
<li class="chapter" data-level="" data-path="an-application-to-test-scores-and-the-student-teacher-ratio.html"><a href="an-application-to-test-scores-and-the-student-teacher-ratio.html#another-augmentation-of-the-model"><i class="fa fa-check"></i>Another Augmentation of the Model</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="joint-hypothesis-testing-using-the-f-statistic.html"><a href="joint-hypothesis-testing-using-the-f-statistic.html"><i class="fa fa-check"></i><b>7.3</b> Joint Hypothesis Testing Using the <span class="math inline">\(F\)</span>-Statistic</a></li>
<li class="chapter" data-level="7.4" data-path="confidence-sets-for-multiple-coefficients.html"><a href="confidence-sets-for-multiple-coefficients.html"><i class="fa fa-check"></i><b>7.4</b> Confidence Sets for Multiple Coefficients</a></li>
<li class="chapter" data-level="7.5" data-path="model-specification-for-multiple-regression.html"><a href="model-specification-for-multiple-regression.html"><i class="fa fa-check"></i><b>7.5</b> Model Specification for Multiple Regression</a><ul>
<li class="chapter" data-level="" data-path="model-specification-for-multiple-regression.html"><a href="model-specification-for-multiple-regression.html#model-specification-in-theory-and-in-practice"><i class="fa fa-check"></i>Model Specification in Theory and in Practice</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="analysis-of-the-test-score-data-set.html"><a href="analysis-of-the-test-score-data-set.html"><i class="fa fa-check"></i><b>7.6</b> Analysis of the Test Score Data Set</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="nonlinear-regression-functions.html"><a href="nonlinear-regression-functions.html"><i class="fa fa-check"></i><b>8</b> Nonlinear Regression Functions</a><ul>
<li class="chapter" data-level="8.1" data-path="a-general-strategy-for-modeling-nonlinear-regression-functions.html"><a href="a-general-strategy-for-modeling-nonlinear-regression-functions.html"><i class="fa fa-check"></i><b>8.1</b> A General Strategy for Modeling Nonlinear Regression Functions</a></li>
<li class="chapter" data-level="8.2" data-path="nonlinear-functions-of-a-single-independent-variable.html"><a href="nonlinear-functions-of-a-single-independent-variable.html"><i class="fa fa-check"></i><b>8.2</b> Nonlinear Functions of a Single Independent Variable</a><ul>
<li class="chapter" data-level="" data-path="nonlinear-functions-of-a-single-independent-variable.html"><a href="nonlinear-functions-of-a-single-independent-variable.html#polynomials"><i class="fa fa-check"></i>Polynomials</a></li>
<li class="chapter" data-level="" data-path="nonlinear-functions-of-a-single-independent-variable.html"><a href="nonlinear-functions-of-a-single-independent-variable.html#logarithms"><i class="fa fa-check"></i>Logarithms</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="interactions-between-independent-variables.html"><a href="interactions-between-independent-variables.html"><i class="fa fa-check"></i><b>8.3</b> Interactions Between Independent Variables</a></li>
<li class="chapter" data-level="8.4" data-path="nonlinear-effects-on-test-scores-of-the-student-teacher-ratio.html"><a href="nonlinear-effects-on-test-scores-of-the-student-teacher-ratio.html"><i class="fa fa-check"></i><b>8.4</b> Nonlinear Effects on Test Scores of the Student-Teacher Ratio</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="assessing-studies-based-on-multiple-regression.html"><a href="assessing-studies-based-on-multiple-regression.html"><i class="fa fa-check"></i><b>9</b> Assessing Studies Based on Multiple Regression</a><ul>
<li class="chapter" data-level="9.1" data-path="internal-and-external-validity.html"><a href="internal-and-external-validity.html"><i class="fa fa-check"></i><b>9.1</b> Internal and External Validity</a></li>
<li class="chapter" data-level="9.2" data-path="threats-to-internal-validity-of-multiple-regression-analysis.html"><a href="threats-to-internal-validity-of-multiple-regression-analysis.html"><i class="fa fa-check"></i><b>9.2</b> Threats to Internal Validity of Multiple Regression Analysis</a></li>
<li class="chapter" data-level="9.3" data-path="internal-and-external-validity-when-the-regression-is-used-for-forecasting.html"><a href="internal-and-external-validity-when-the-regression-is-used-for-forecasting.html"><i class="fa fa-check"></i><b>9.3</b> Internal and External Validity When the Regression is Used for Forecasting</a></li>
<li class="chapter" data-level="9.4" data-path="example-test-scores-and-class-size.html"><a href="example-test-scores-and-class-size.html"><i class="fa fa-check"></i><b>9.4</b> Example: Test Scores and Class Size</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="regression-with-panel-data.html"><a href="regression-with-panel-data.html"><i class="fa fa-check"></i><b>10</b> Regression with Panel Data</a><ul>
<li class="chapter" data-level="10.1" data-path="panel-data.html"><a href="panel-data.html"><i class="fa fa-check"></i><b>10.1</b> Panel Data</a></li>
<li class="chapter" data-level="10.2" data-path="PDWTTP.html"><a href="PDWTTP.html"><i class="fa fa-check"></i><b>10.2</b> Panel Data with Two Time Periods: “Before and Afer” Comparisons</a></li>
<li class="chapter" data-level="10.3" data-path="fixed-effects-regression.html"><a href="fixed-effects-regression.html"><i class="fa fa-check"></i><b>10.3</b> Fixed Effects Regression</a><ul>
<li class="chapter" data-level="" data-path="fixed-effects-regression.html"><a href="fixed-effects-regression.html#estimation-and-inference"><i class="fa fa-check"></i>Estimation and Inference</a></li>
<li class="chapter" data-level="" data-path="fixed-effects-regression.html"><a href="fixed-effects-regression.html#application-to-traffic-deaths"><i class="fa fa-check"></i>Application to Traffic Deaths</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="regression-with-time-fixed-effects.html"><a href="regression-with-time-fixed-effects.html"><i class="fa fa-check"></i><b>10.4</b> Regression with Time Fixed Effects</a></li>
<li class="chapter" data-level="10.5" data-path="the-fixed-effects-regression-assumptions-and-standard-errors-for-fixed-effects-regression.html"><a href="the-fixed-effects-regression-assumptions-and-standard-errors-for-fixed-effects-regression.html"><i class="fa fa-check"></i><b>10.5</b> The Fixed Effects Regression Assumptions and Standard Errors for Fixed Effects Regression</a></li>
<li class="chapter" data-level="10.6" data-path="drunk-driving-laws-and-traffic-deaths.html"><a href="drunk-driving-laws-and-traffic-deaths.html"><i class="fa fa-check"></i><b>10.6</b> Drunk Driving Laws and Traffic Deaths</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="regression-with-a-binary-dependent-variable.html"><a href="regression-with-a-binary-dependent-variable.html"><i class="fa fa-check"></i><b>11</b> Regression with a Binary Dependent Variable</a><ul>
<li class="chapter" data-level="11.1" data-path="binary-dependent-variables-and-the-linear-probability-model.html"><a href="binary-dependent-variables-and-the-linear-probability-model.html"><i class="fa fa-check"></i><b>11.1</b> Binary Dependent Variables and the Linear Probability Model</a></li>
<li class="chapter" data-level="11.2" data-path="probit-and-logit-regression.html"><a href="probit-and-logit-regression.html"><i class="fa fa-check"></i><b>11.2</b> Probit and Logit Regression</a><ul>
<li class="chapter" data-level="" data-path="probit-and-logit-regression.html"><a href="probit-and-logit-regression.html#probit-regression"><i class="fa fa-check"></i>Probit Regression</a></li>
<li class="chapter" data-level="" data-path="probit-and-logit-regression.html"><a href="probit-and-logit-regression.html#logit-regression"><i class="fa fa-check"></i>Logit Regression</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="estimation-and-inference-in-the-logit-and-probit-models.html"><a href="estimation-and-inference-in-the-logit-and-probit-models.html"><i class="fa fa-check"></i><b>11.3</b> Estimation and Inference in the Logit and Probit Models</a></li>
<li class="chapter" data-level="11.4" data-path="application-to-the-boston-hmda-data.html"><a href="application-to-the-boston-hmda-data.html"><i class="fa fa-check"></i><b>11.4</b> Application to the Boston HMDA Data</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="instrumental-variables-regression.html"><a href="instrumental-variables-regression.html"><i class="fa fa-check"></i><b>12</b> Instrumental Variables Regression</a><ul>
<li class="chapter" data-level="12.1" data-path="TIVEWASRAASI.html"><a href="TIVEWASRAASI.html"><i class="fa fa-check"></i><b>12.1</b> The IV Estimator with a Single Regressor and a Single Instrument</a></li>
<li class="chapter" data-level="12.2" data-path="TGIVRM.html"><a href="TGIVRM.html"><i class="fa fa-check"></i><b>12.2</b> The General IV Regression Model</a></li>
<li class="chapter" data-level="12.3" data-path="checking-instrument-validity.html"><a href="checking-instrument-validity.html"><i class="fa fa-check"></i><b>12.3</b> Checking Instrument Validity</a></li>
<li class="chapter" data-level="12.4" data-path="application-to-the-demand-for-cigarettes-2.html"><a href="application-to-the-demand-for-cigarettes-2.html"><i class="fa fa-check"></i><b>12.4</b> Application to the Demand for Cigarettes</a></li>
<li class="chapter" data-level="12.5" data-path="where-do-valid-instruments-come-from.html"><a href="where-do-valid-instruments-come-from.html"><i class="fa fa-check"></i><b>12.5</b> Where Do Valid Instruments Come From?</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="experiments-and-quasi-experiments.html"><a href="experiments-and-quasi-experiments.html"><i class="fa fa-check"></i><b>13</b> Experiments and Quasi-Experiments</a><ul>
<li class="chapter" data-level="13.1" data-path="potential-outcomes-causal-effects-and-idealized-experiments.html"><a href="potential-outcomes-causal-effects-and-idealized-experiments.html"><i class="fa fa-check"></i><b>13.1</b> Potential Outcomes, Causal Effects and Idealized Experiments</a></li>
<li class="chapter" data-level="13.2" data-path="threats-to-validity-of-experiments.html"><a href="threats-to-validity-of-experiments.html"><i class="fa fa-check"></i><b>13.2</b> Threats to Validity of Experiments</a></li>
<li class="chapter" data-level="13.3" data-path="experimental-estimates-of-the-effect-of-class-size-reductions.html"><a href="experimental-estimates-of-the-effect-of-class-size-reductions.html"><i class="fa fa-check"></i><b>13.3</b> Experimental Estimates of the Effect of Class Size Reductions</a><ul>
<li class="chapter" data-level="" data-path="experimental-estimates-of-the-effect-of-class-size-reductions.html"><a href="experimental-estimates-of-the-effect-of-class-size-reductions.html#experimental-design-and-the-data-set"><i class="fa fa-check"></i>Experimental Design and the Data Set</a></li>
<li class="chapter" data-level="" data-path="experimental-estimates-of-the-effect-of-class-size-reductions.html"><a href="experimental-estimates-of-the-effect-of-class-size-reductions.html#analysis-of-the-star-data"><i class="fa fa-check"></i>Analysis of the STAR Data</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="quasi-experiments.html"><a href="quasi-experiments.html"><i class="fa fa-check"></i><b>13.4</b> Quasi Experiments</a><ul>
<li class="chapter" data-level="" data-path="quasi-experiments.html"><a href="quasi-experiments.html#the-differences-in-differences-estimator"><i class="fa fa-check"></i>The Differences-in-Differences Estimator</a></li>
<li class="chapter" data-level="" data-path="quasi-experiments.html"><a href="quasi-experiments.html#regression-discontinuity-estimators"><i class="fa fa-check"></i>Regression Discontinuity Estimators</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="introduction-to-time-series-regression-and-forecasting.html"><a href="introduction-to-time-series-regression-and-forecasting.html"><i class="fa fa-check"></i><b>14</b> Introduction to Time Series Regression and Forecasting</a><ul>
<li class="chapter" data-level="14.1" data-path="using-regression-models-for-forecasting.html"><a href="using-regression-models-for-forecasting.html"><i class="fa fa-check"></i><b>14.1</b> Using Regression Models for Forecasting</a></li>
<li class="chapter" data-level="14.2" data-path="time-series-data-and-serial-correlation.html"><a href="time-series-data-and-serial-correlation.html"><i class="fa fa-check"></i><b>14.2</b> Time Series Data and Serial Correlation</a><ul>
<li class="chapter" data-level="" data-path="time-series-data-and-serial-correlation.html"><a href="time-series-data-and-serial-correlation.html#notation-lags-differences-logarithms-and-growth-rates"><i class="fa fa-check"></i>Notation, Lags, Differences, Logarithms and Growth Rates</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="autoregressions.html"><a href="autoregressions.html"><i class="fa fa-check"></i><b>14.3</b> Autoregressions</a><ul>
<li><a href="autoregressions.html#the-pth-order-autoregressive-model">The <span class="math inline">\(p^{th}\)</span>-Order Autoregressive Model</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="can-you-beat-the-market-part-i.html"><a href="can-you-beat-the-market-part-i.html"><i class="fa fa-check"></i><b>14.4</b> Can You Beat the Market? (Part I)</a></li>
<li class="chapter" data-level="14.5" data-path="additional-predictors-and-the-adl-model.html"><a href="additional-predictors-and-the-adl-model.html"><i class="fa fa-check"></i><b>14.5</b> Additional Predictors and The ADL Model</a><ul>
<li class="chapter" data-level="" data-path="additional-predictors-and-the-adl-model.html"><a href="additional-predictors-and-the-adl-model.html#forecast-uncertainty-and-forecast-intervals"><i class="fa fa-check"></i>Forecast Uncertainty and Forecast Intervals</a></li>
</ul></li>
<li class="chapter" data-level="14.6" data-path="lag-length-selection-using-information-criteria.html"><a href="lag-length-selection-using-information-criteria.html"><i class="fa fa-check"></i><b>14.6</b> Lag Length Selection Using Information Criteria</a></li>
<li class="chapter" data-level="14.7" data-path="nonstationarity-i-trends.html"><a href="nonstationarity-i-trends.html"><i class="fa fa-check"></i><b>14.7</b> Nonstationarity I: Trends</a></li>
<li class="chapter" data-level="14.8" data-path="nonstationarity-ii-breaks.html"><a href="nonstationarity-ii-breaks.html"><i class="fa fa-check"></i><b>14.8</b> Nonstationarity II: Breaks</a></li>
<li class="chapter" data-level="14.9" data-path="can-you-beat-the-market-part-ii.html"><a href="can-you-beat-the-market-part-ii.html"><i class="fa fa-check"></i><b>14.9</b> Can You Beat the Market? Part II</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="estimation-of-dynamic-causal-effects.html"><a href="estimation-of-dynamic-causal-effects.html"><i class="fa fa-check"></i><b>15</b> Estimation of Dynamic Causal Effects</a><ul>
<li class="chapter" data-level="15.1" data-path="the-orange-juice-data.html"><a href="the-orange-juice-data.html"><i class="fa fa-check"></i><b>15.1</b> The Orange Juice Data</a></li>
<li class="chapter" data-level="15.2" data-path="dynamic-causal-effects.html"><a href="dynamic-causal-effects.html"><i class="fa fa-check"></i><b>15.2</b> Dynamic Causal Effects</a></li>
<li class="chapter" data-level="15.3" data-path="dynamic-multipliers-and-cumulative-dynamic-multipliers.html"><a href="dynamic-multipliers-and-cumulative-dynamic-multipliers.html"><i class="fa fa-check"></i><b>15.3</b> Dynamic Multipliers and Cumulative Dynamic Multipliers</a></li>
<li class="chapter" data-level="15.4" data-path="hac-standard-errors.html"><a href="hac-standard-errors.html"><i class="fa fa-check"></i><b>15.4</b> HAC Standard Errors</a></li>
<li class="chapter" data-level="15.5" data-path="estimation-of-dynamic-causal-effects-with-strictly-exogeneous-regressors.html"><a href="estimation-of-dynamic-causal-effects-with-strictly-exogeneous-regressors.html"><i class="fa fa-check"></i><b>15.5</b> Estimation of Dynamic Causal Effects with Strictly Exogeneous Regressors</a></li>
<li class="chapter" data-level="15.6" data-path="orange-juice-prices-and-cold-weather.html"><a href="orange-juice-prices-and-cold-weather.html"><i class="fa fa-check"></i><b>15.6</b> Orange Juice Prices and Cold Weather</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Using R for Introduction to Econometrics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div class = rmdreview>
This book is in <b>Open Review</b>. We want your feedback to make the book better for you and other students. You may annotate some text by <span style="background-color: #3297FD; color: white">selecting it with the cursor</span> and then click the <i class="h-icon-annotate"></i> on the pop-up menu. You can also see the annotations of others: click the <i class="h-icon-chevron-left"></i> in the upper right hand corner of the page <i class="fa fa-arrow-circle-right  fa-rotate-315" aria-hidden="true"></i>
</div>
<div id="orange-juice-prices-and-cold-weather" class="section level2">
<h2><span class="header-section-number">15.6</span> Orange Juice Prices and Cold Weather</h2>
<p>In this section we investigate the following two questions using the time series regression methods discussed before:</p>
<ul>
<li><p>How persistent is the effect of a single freeze on prices?</p></li>
<li><p>Has this effect been stable over the whole time span considered?</p></li>
</ul>
<p>We start by estimating dynamic causal effects with a distributed lag model where <span class="math inline">\(\%ChgOJC_t\)</span> is regressed on <span class="math inline">\(FDD_t\)</span> and 18 lags of it. A second model specification is a transformation of the the distributed lag model which allows to estimate the 19 cumulative dynamic multipliers using OLS. In a third model, we add 11 binary variables (one for each of the months from February to December) to adjust for a possible omitted variable bias arising from correllation of <span class="math inline">\(FDD_t\)</span> and seasons by adding <code>season(FDD)</code> to the right hand side of the formula of the second model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># estimate distributed lag models of frozen orange juice price changes</span>
FOJC_mod_DM &lt;-<span class="st"> </span><span class="kw">dynlm</span>(FOJC_pctc <span class="op">~</span><span class="st"> </span><span class="kw">L</span>(FDD, <span class="dv">0</span><span class="op">:</span><span class="dv">18</span>))
FOJC_mod_CM1 &lt;-<span class="st"> </span><span class="kw">dynlm</span>(FOJC_pctc <span class="op">~</span><span class="st"> </span><span class="kw">L</span>(<span class="kw">d</span>(FDD), <span class="dv">0</span><span class="op">:</span><span class="dv">17</span>) <span class="op">+</span><span class="st"> </span><span class="kw">L</span>(FDD, <span class="dv">18</span>))
FOJC_mod_CM2 &lt;-<span class="st"> </span><span class="kw">dynlm</span>(FOJC_pctc <span class="op">~</span><span class="st"> </span><span class="kw">L</span>(<span class="kw">d</span>(FDD), <span class="dv">0</span><span class="op">:</span><span class="dv">17</span>) <span class="op">+</span><span class="st"> </span><span class="kw">L</span>(FDD, <span class="dv">18</span>) <span class="op">+</span><span class="st"> </span><span class="kw">season</span>(FDD))</code></pre></div>
<p>The models above include a large number of lags with default labels that correspond to the degree of differencing and the lag orders which makes it somewhat cumbersome to read the outcomes. The regressor labels of a model object may be altered by overriding the attribute <code>names</code> of the coefficient section using the function <code>attr()</code>. Thus, for better readability we use the lag orders as regressor labels.</p>
<p>Next, we compute HAC standard errors standard errors for each model using <span class="math inline">\(NeweyWest()\)</span> and gather the results in a list which is then supplied as the argument <code>se</code> to the function <code>stargazer()</code>, see below. Note that the sample consists of 612 observations.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">length</span>(FDD)</code></pre></div>
<pre><code>## [1] 612</code></pre>
<p>According to <a href="hac-standard-errors.html#eq:hactruncrot">(15.6)</a>, the rule of thumb for choosing the HAC standard error truncation parameter <span class="math inline">\(m\)</span>, we choose <span class="math display">\[m = \left\lceil0.75 \cdot 612^{1/3} \right\rceil = \lceil6.37\rceil = 7.\]</span> To check for sensitivity of the standard errors to different choices of the truncation parameter in the model that is used to estimate the cumulative multipliers, we also compute the Newey and West estimator for <span class="math inline">\(m=14\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># gather hAC standard error errors in a list</span>
SEs &lt;-<span class="st"> </span><span class="kw">list</span>(
  <span class="kw">sqrt</span>(
    <span class="kw">diag</span>(
      <span class="kw">NeweyWest</span>(FOJC_mod_DM, <span class="dt">lag =</span> <span class="dv">7</span>, <span class="dt">prewhite =</span> F)
    )  
  ), 
  <span class="kw">sqrt</span>(
    <span class="kw">diag</span>(
      <span class="kw">NeweyWest</span>(FOJC_mod_CM1, <span class="dt">lag =</span> <span class="dv">7</span>, <span class="dt">prewhite =</span> F)
    )  
  ), 
   <span class="kw">sqrt</span>(
    <span class="kw">diag</span>(
      <span class="kw">NeweyWest</span>(FOJC_mod_CM1, <span class="dt">lag =</span> <span class="dv">14</span>, <span class="dt">prewhite =</span> F)
    )  
  ),
  <span class="kw">sqrt</span>(
    <span class="kw">diag</span>(
      <span class="kw">NeweyWest</span>(FOJC_mod_CM2, <span class="dt">lag =</span> <span class="dv">7</span>, <span class="dt">prewhite =</span> F)
    )  
  )
)</code></pre></div>
<p>The results are then used to reproduce the outcomes presented in Table 15.1 of the book.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">stargazer</span>(FOJC_mod_DM , FOJC_mod_CM1, FOJC_mod_CM1, FOJC_mod_CM2,
  <span class="dt">title =</span> <span class="st">&quot;Dynamic Effects of a Freezing Degree Day on the Price of Orange Juice&quot;</span>,
  <span class="dt">header =</span> <span class="ot">FALSE</span>, 
  <span class="dt">digits =</span> <span class="dv">2</span>, 
  <span class="dt">column.labels =</span> <span class="kw">c</span>(<span class="st">&quot;Dynamic Multipliers&quot;</span>, <span class="kw">rep</span>(<span class="st">&quot;Dynamic Cumulative Multipliers&quot;</span>,<span class="dv">3</span>)),
  <span class="dt">dep.var.caption  =</span> <span class="st">&quot;Monthly Percentage Change in Orange Juice Price&quot;</span>,
  <span class="dt">dep.var.labels.include =</span> <span class="ot">FALSE</span>,
  <span class="dt">covariate.labels =</span> <span class="kw">as.character</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">18</span>),
  <span class="dt">omit =</span> <span class="st">&quot;season&quot;</span>,
  <span class="dt">se =</span> SEs,
  <span class="dt">no.space =</span> T,
  <span class="dt">add.lines =</span> <span class="kw">list</span>(
                   <span class="kw">c</span>(<span class="st">&quot;Monthly indicators?&quot;</span>,<span class="st">&quot;no&quot;</span>, <span class="st">&quot;no&quot;</span>, <span class="st">&quot;no&quot;</span>, <span class="st">&quot;yes&quot;</span>),
                   <span class="kw">c</span>(<span class="st">&quot;HAC truncation&quot;</span>,<span class="st">&quot;7&quot;</span>, <span class="st">&quot;7&quot;</span>, <span class="st">&quot;14&quot;</span>, <span class="st">&quot;7&quot;</span>)
                   ),
  <span class="dt">omit.stat =</span> <span class="kw">c</span>(<span class="st">&quot;rsq&quot;</span>, <span class="st">&quot;f&quot;</span>,<span class="st">&quot;ser&quot;</span>)
  ) </code></pre></div>



<table style="text-align:center"><caption><strong>Dynamic Effects of a Freezing Degree Day on the Price of Orange Juice</strong></caption>
<tr><td colspan="5" style="border-bottom: 1px solid black"></td></tr><tr><td style="text-align:left"></td><td colspan="4">Monthly Percentage Change in Orange Juice Price</td></tr>
<tr><td></td><td colspan="4" style="border-bottom: 1px solid black"></td></tr>
<tr><td style="text-align:left"></td><td>Dynamic Multipliers</td><td>Dynamic Cumulative Multipliers</td><td>Dynamic Cumulative Multipliers</td><td>Dynamic Cumulative Multipliers</td></tr>
<tr><td style="text-align:left"></td><td>(1)</td><td>(2)</td><td>(3)</td><td>(4)</td></tr>
<tr><td colspan="5" style="border-bottom: 1px solid black"></td></tr><tr><td style="text-align:left">0</td><td>0.51<sup>***</sup></td><td>0.51<sup>***</sup></td><td>0.51<sup>***</sup></td><td>0.52<sup>***</sup></td></tr>
<tr><td style="text-align:left"></td><td>(0.14)</td><td>(0.14)</td><td>(0.14)</td><td>(0.14)</td></tr>
<tr><td style="text-align:left">1</td><td>0.17<sup>**</sup></td><td>0.68<sup>***</sup></td><td>0.68<sup>***</sup></td><td>0.72<sup>***</sup></td></tr>
<tr><td style="text-align:left"></td><td>(0.09)</td><td>(0.13)</td><td>(0.13)</td><td>(0.14)</td></tr>
<tr><td style="text-align:left">2</td><td>0.07</td><td>0.75<sup>***</sup></td><td>0.75<sup>***</sup></td><td>0.78<sup>***</sup></td></tr>
<tr><td style="text-align:left"></td><td>(0.06)</td><td>(0.17)</td><td>(0.16)</td><td>(0.17)</td></tr>
<tr><td style="text-align:left">3</td><td>0.07</td><td>0.82<sup>***</sup></td><td>0.82<sup>***</sup></td><td>0.86<sup>***</sup></td></tr>
<tr><td style="text-align:left"></td><td>(0.04)</td><td>(0.18)</td><td>(0.18)</td><td>(0.19)</td></tr>
<tr><td style="text-align:left">4</td><td>0.02</td><td>0.84<sup>***</sup></td><td>0.84<sup>***</sup></td><td>0.89<sup>***</sup></td></tr>
<tr><td style="text-align:left"></td><td>(0.03)</td><td>(0.18)</td><td>(0.18)</td><td>(0.19)</td></tr>
<tr><td style="text-align:left">5</td><td>0.03</td><td>0.87<sup>***</sup></td><td>0.87<sup>***</sup></td><td>0.90<sup>***</sup></td></tr>
<tr><td style="text-align:left"></td><td>(0.03)</td><td>(0.19)</td><td>(0.19)</td><td>(0.20)</td></tr>
<tr><td style="text-align:left">6</td><td>0.03</td><td>0.90<sup>***</sup></td><td>0.90<sup>***</sup></td><td>0.92<sup>***</sup></td></tr>
<tr><td style="text-align:left"></td><td>(0.05)</td><td>(0.20)</td><td>(0.21)</td><td>(0.21)</td></tr>
<tr><td style="text-align:left">7</td><td>0.02</td><td>0.91<sup>***</sup></td><td>0.91<sup>***</sup></td><td>0.94<sup>***</sup></td></tr>
<tr><td style="text-align:left"></td><td>(0.02)</td><td>(0.20)</td><td>(0.21)</td><td>(0.21)</td></tr>
<tr><td style="text-align:left">8</td><td>-0.04</td><td>0.87<sup>***</sup></td><td>0.87<sup>***</sup></td><td>0.90<sup>***</sup></td></tr>
<tr><td style="text-align:left"></td><td>(0.03)</td><td>(0.21)</td><td>(0.22)</td><td>(0.22)</td></tr>
<tr><td style="text-align:left">9</td><td>-0.01</td><td>0.86<sup>***</sup></td><td>0.86<sup>***</sup></td><td>0.88<sup>***</sup></td></tr>
<tr><td style="text-align:left"></td><td>(0.05)</td><td>(0.24)</td><td>(0.24)</td><td>(0.24)</td></tr>
<tr><td style="text-align:left">10</td><td>-0.12<sup>*</sup></td><td>0.75<sup>***</sup></td><td>0.75<sup>***</sup></td><td>0.75<sup>***</sup></td></tr>
<tr><td style="text-align:left"></td><td>(0.07)</td><td>(0.26)</td><td>(0.26)</td><td>(0.26)</td></tr>
<tr><td style="text-align:left">11</td><td>-0.07</td><td>0.68<sup>**</sup></td><td>0.68<sup>**</sup></td><td>0.68<sup>**</sup></td></tr>
<tr><td style="text-align:left"></td><td>(0.05)</td><td>(0.27)</td><td>(0.27)</td><td>(0.27)</td></tr>
<tr><td style="text-align:left">12</td><td>-0.14<sup>*</sup></td><td>0.54<sup>**</sup></td><td>0.54<sup>**</sup></td><td>0.55<sup>**</sup></td></tr>
<tr><td style="text-align:left"></td><td>(0.08)</td><td>(0.27)</td><td>(0.27)</td><td>(0.27)</td></tr>
<tr><td style="text-align:left">13</td><td>-0.08<sup>*</sup></td><td>0.45<sup>*</sup></td><td>0.45<sup>*</sup></td><td>0.49<sup>*</sup></td></tr>
<tr><td style="text-align:left"></td><td>(0.04)</td><td>(0.27)</td><td>(0.27)</td><td>(0.27)</td></tr>
<tr><td style="text-align:left">14</td><td>-0.06</td><td>0.40</td><td>0.40</td><td>0.43</td></tr>
<tr><td style="text-align:left"></td><td>(0.03)</td><td>(0.27)</td><td>(0.28)</td><td>(0.28)</td></tr>
<tr><td style="text-align:left">15</td><td>-0.03</td><td>0.37</td><td>0.37</td><td>0.41</td></tr>
<tr><td style="text-align:left"></td><td>(0.03)</td><td>(0.28)</td><td>(0.29)</td><td>(0.28)</td></tr>
<tr><td style="text-align:left">16</td><td>-0.01</td><td>0.36</td><td>0.36</td><td>0.41</td></tr>
<tr><td style="text-align:left"></td><td>(0.05)</td><td>(0.28)</td><td>(0.29)</td><td>(0.29)</td></tr>
<tr><td style="text-align:left">17</td><td>0.003</td><td>0.36</td><td>0.36</td><td>0.40</td></tr>
<tr><td style="text-align:left"></td><td>(0.02)</td><td>(0.29)</td><td>(0.29)</td><td>(0.29)</td></tr>
<tr><td style="text-align:left">18</td><td>0.003</td><td>0.37</td><td>0.37</td><td>0.39</td></tr>
<tr><td style="text-align:left"></td><td>(0.02)</td><td>(0.29)</td><td>(0.30)</td><td>(0.29)</td></tr>
<tr><td style="text-align:left">Constant</td><td>-0.34</td><td>-0.34</td><td>-0.34</td><td>-0.24</td></tr>
<tr><td style="text-align:left"></td><td>(0.27)</td><td>(0.27)</td><td>(0.26)</td><td>(0.93)</td></tr>
<tr><td colspan="5" style="border-bottom: 1px solid black"></td></tr><tr><td style="text-align:left">Monthly indicators?</td><td>no</td><td>no</td><td>no</td><td>yes</td></tr>
<tr><td style="text-align:left">HAC truncation</td><td>7</td><td>7</td><td>14</td><td>7</td></tr>
<tr><td style="text-align:left">Observations</td><td>594</td><td>594</td><td>594</td><td>594</td></tr>
<tr><td style="text-align:left">Adjusted R<sup>2</sup></td><td>0.11</td><td>0.11</td><td>0.11</td><td>0.10</td></tr>
<tr><td colspan="5" style="border-bottom: 1px solid black"></td></tr><tr><td style="text-align:left"><em>Note:</em></td><td colspan="4" style="text-align:right"><sup>*</sup>p<0.1; <sup>**</sup>p<0.05; <sup>***</sup>p<0.01</td></tr>
</table>


<p>Acording to coloumn (1), the contemporaneous effect of a freezing degree day is an increase of <span class="math inline">\(0.5\%\)</span> in orange juice prices. The estimated effect is only <span class="math inline">\(0.17\%\)</span> for the next month and close to zero for subsequent months. In fact, for all lags larger than 1, we cannot reject the individual null hypotheses that the respective coefficients are zero. Notice also that the model <code>FOJC_mod_DM</code> does only explain little variation in the dependent variable (<span class="math inline">\(\overline{R}^2 = 0.11\)</span>).</p>
<p>Columns (2) and (3) present estimates of the dynamic cumulative multipliers of model <code>FOJC_mod_CM1</code>. Apparently, it does not matter whether we choose <span class="math inline">\(m=7\)</span> or <span class="math inline">\(m=14\)</span> when computing HAC standard errors so we stick with <span class="math inline">\(m=7\)</span> and the standard errors reported in column (2).</p>
<p>If demand for orange juice is higher in winter, <span class="math inline">\(FDD_t\)</span> would be correlated with the error term since since freezes occur rather in winter so we would face omitted variable bias. The third model estimate, <code>FOJC_mod_CM2</code>, accounts for this possible issue by using an additional set of 11 monthly dummies. For brevity, estimates of the dummy coefficients are excluded from the output produced by stargazer (this is achieved by setting <code>omit = &quot;season&quot;</code>). We may check that the dummy for January was omitted to prevent perfect multicollinearity.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># estimates on mothly dummies</span>
FOJC_mod_CM2<span class="op">$</span>coefficients[<span class="op">-</span><span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">20</span>)]</code></pre></div>
<pre><code>## season(FDD)Feb season(FDD)Mar season(FDD)Apr season(FDD)May season(FDD)Jun 
##     -0.9565759     -0.6358007      0.5006770     -1.0801764      0.3195624 
## season(FDD)Jul season(FDD)Aug season(FDD)Sep season(FDD)Oct season(FDD)Nov 
##      0.1951113      0.3644312     -0.4130969     -0.1566622      0.3116534 
## season(FDD)Dec 
##      0.1481589</code></pre>
<p>A comparison of the estimates presented in columns (3) and (4) indicates that adding monthly dummies has a negligible effect. Further evidence for this comes from a test of the hypothesis that the 11 dummy coefficients are jointly zero. Instead of using <code>linearHypothesis()</code> which requires that all 11 restrictions are provided in a matrix, we use the function <code>waldtest()</code> and supply two model objects instead: <code>unres_model</code>, the unrestricted model object which is the same as <code>FOJC_mod_CM2</code> (except for the coefficient names since we have modified them above) and <code>res_model</code>, the model where the restriction that all dummy coefficients are zero is imposed. <code>res_model</code> is conveniently obtained using the function <code>update()</code>. It extracts the argument <tt>formula</tt> of a model object, updates it as specified and then re-fits the model. By setting <code>formula = . ~ . - season(FDD)</code> we impose that the monthly dummies do not enter the model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># test if coefficients on monthly dummies are zero</span>

unres_model &lt;-<span class="st"> </span><span class="kw">dynlm</span>(FOJC_pctc <span class="op">~</span><span class="st"> </span><span class="kw">L</span>(<span class="kw">d</span>(FDD), <span class="dv">0</span><span class="op">:</span><span class="dv">17</span>) <span class="op">+</span><span class="st"> </span><span class="kw">L</span>(FDD, <span class="dv">18</span>) <span class="op">+</span><span class="st"> </span><span class="kw">season</span>(FDD))

res_model &lt;-<span class="st"> </span><span class="kw">update</span>(unres_model, <span class="dt">formula =</span> . <span class="op">~</span><span class="st"> </span>. <span class="op">-</span><span class="st"> </span><span class="kw">season</span>(FDD))

<span class="kw">waldtest</span>(unres_model, 
         res_model, 
         <span class="dt">vcov =</span> <span class="kw">NeweyWest</span>(unres_model, <span class="dt">lag =</span> <span class="dv">7</span>, <span class="dt">prewhite =</span> F))</code></pre></div>
<pre><code>## Wald test
## 
## Model 1: FOJC_pctc ~ L(d(FDD), 0:17) + L(FDD, 18) + season(FDD)
## Model 2: FOJC_pctc ~ L(d(FDD), 0:17) + L(FDD, 18)
##   Res.Df  Df      F Pr(&gt;F)
## 1    563                  
## 2    574 -11 0.9683 0.4743</code></pre>
<p>The <span class="math inline">\(p\)</span>-value is <span class="math inline">\(0.47\)</span> so we cannot reject the hypothesis that the coefficients on the monthly dummies are zero, even at the <span class="math inline">\(10\%\)</span> level of significance. We conclude that the seasonal fluctuations in demand for orange juice do not pose a serious threat to internal validity of the model.</p>
<p>It is convenient to use plots of dynamic multipliers and cumulative dynamic multipliers. The following two code chunks reproduce Figures 15.2 (a) and 15.2 (b) of the book which display point estimates of dynamic and cumulative multipliers along with upper and lower bounds of their <span class="math inline">\(95\%\)</span> confidence intervals computed using the HAC standard errors from above.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 95% CI bounds</span>
point_estimates &lt;-<span class="st"> </span>FOJC_mod_DM<span class="op">$</span>coefficients

CI_bounds &lt;-<span class="st"> </span><span class="kw">cbind</span>(
   <span class="st">&quot;lower&quot;</span> =<span class="st"> </span>point_estimates <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>SEs[[<span class="dv">1</span>]],
   <span class="st">&quot;upper&quot;</span> =<span class="st"> </span>point_estimates <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>SEs[[<span class="dv">1</span>]]
 )[<span class="op">-</span><span class="dv">1</span>,]


<span class="co"># plot estimated dynamic multipliers</span>
<span class="kw">plot</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">18</span>, point_estimates[<span class="op">-</span><span class="dv">1</span>], 
     <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, 
     <span class="dt">lwd =</span> <span class="dv">2</span>, 
     <span class="dt">col =</span> <span class="st">&quot;steelblue&quot;</span>, 
     <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="fl">0.4</span>, <span class="dv">1</span>),
     <span class="dt">xlab =</span> <span class="st">&quot;Lag&quot;</span>,
     <span class="dt">ylab =</span> <span class="st">&quot;Dynamic multiplier&quot;</span>,
     <span class="dt">main =</span> <span class="st">&quot;Dynamic Effect of FDD on Orange Juice Price&quot;</span>
     )

<span class="co"># add dashed line at 0</span>
<span class="kw">abline</span>(<span class="dt">h =</span> <span class="dv">0</span>, <span class="dt">lty =</span> <span class="dv">2</span>)

<span class="co"># add CI bounds</span>
<span class="kw">lines</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">18</span>, CI_bounds[,<span class="dv">1</span>], <span class="dt">col =</span> <span class="st">&quot;darkred&quot;</span>)
<span class="kw">lines</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">18</span>, CI_bounds[,<span class="dv">2</span>], <span class="dt">col =</span> <span class="st">&quot;darkred&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:DM"></span>
<img src="URFITE_files/figure-html/DM-1.png" alt="Dynamic Multipliers" width="672" />
<p class="caption">
Figure 15.1: Dynamic Multipliers
</p>
</div>
<p>Notice that the <span class="math inline">\(95\%\)</span> confidence intervals plotted in Figure <a href="orange-juice-prices-and-cold-weather.html#fig:DM">15.1</a> indeed include zero for lags larger than 1 such that the null of a zero multiplier cannot be rejected for these lags.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 95% CI bounds</span>
point_estimates &lt;-<span class="st"> </span>FOJC_mod_CM1<span class="op">$</span>coefficients

CI_bounds &lt;-<span class="st"> </span><span class="kw">cbind</span>(
   <span class="st">&quot;lower&quot;</span> =<span class="st"> </span>point_estimates <span class="op">-</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>SEs[[<span class="dv">2</span>]],
   <span class="st">&quot;upper&quot;</span> =<span class="st"> </span>point_estimates <span class="op">+</span><span class="st"> </span><span class="fl">1.96</span> <span class="op">*</span><span class="st"> </span>SEs[[<span class="dv">2</span>]]
 )[<span class="op">-</span><span class="dv">1</span>,]


<span class="co"># plot estimated dynamic multipliers</span>
<span class="kw">plot</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">18</span>, point_estimates[<span class="op">-</span><span class="dv">1</span>], 
     <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, 
     <span class="dt">lwd =</span> <span class="dv">2</span>, 
     <span class="dt">col =</span> <span class="st">&quot;steelblue&quot;</span>, 
     <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="fl">0.4</span>, <span class="fl">1.6</span>),
     <span class="dt">xlab =</span> <span class="st">&quot;Lag&quot;</span>,
     <span class="dt">ylab =</span> <span class="st">&quot;Cumulative dynamic multiplier&quot;</span>,
    <span class="dt">main =</span> <span class="st">&quot;Cumulative Dynamic Effect of FDD on Orange Juice Price&quot;</span>
     )

<span class="co"># add dashed line at 0</span>
<span class="kw">abline</span>(<span class="dt">h =</span> <span class="dv">0</span>, <span class="dt">lty =</span> <span class="dv">2</span>)

<span class="co"># add CI bounds</span>
<span class="kw">lines</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">18</span>, CI_bounds[, <span class="dv">1</span>], <span class="dt">col =</span> <span class="st">&quot;darkred&quot;</span>)
<span class="kw">lines</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">18</span>, CI_bounds[, <span class="dv">2</span>], <span class="dt">col =</span> <span class="st">&quot;darkred&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:DCM"></span>
<img src="URFITE_files/figure-html/DCM-1.png" alt="Dynamic Cumulative Multipliers" width="672" />
<p class="caption">
Figure 15.2: Dynamic Cumulative Multipliers
</p>
</div>
<p>As can be seen from Figure <a href="orange-juice-prices-and-cold-weather.html#fig:DCM">15.2</a>, the estimated dynamic cumulative multipliers grow through the seventh month up to a price increase of about <span class="math inline">\(0.91\%\)</span> and then decrease slighly to the estimated long-run cumulative multiplier of <span class="math inline">\(0.37\%\)</span> which, however, is not significantly different from zero at the <span class="math inline">\(5\%\)</span> level.</p>
<p>Have the dynamic multipliers been stable over time? One way to see this is the estimate them for different subperiods of the sample. For example, consider periods 1950 - 1966, 1967 - 1983 and 1984 - 2000. If the multipliers are the same for all three periods the estimates should be close and thus the estimated cumulative multipliers should be similar, too. We investigate this by re-estimating <code>FOJC_mod_CM1</code> for the three different time spans and then plot the estimated cumulative dynamic multipliers for the comparison.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># estimate cumulative multiplieres using different sample periods</span>
FOJC_mod_CM1950 &lt;-<span class="st"> </span><span class="kw">update</span>(FOJC_mod_CM1, <span class="dt">start =</span> <span class="kw">c</span>(<span class="dv">1950</span>,<span class="dv">1</span>), <span class="dt">end =</span> <span class="kw">c</span>(<span class="dv">1966</span>,<span class="dv">12</span>))

FOJC_mod_CM1967 &lt;-<span class="st"> </span><span class="kw">update</span>(FOJC_mod_CM1, <span class="dt">start =</span> <span class="kw">c</span>(<span class="dv">1967</span>,<span class="dv">1</span>), <span class="dt">end =</span> <span class="kw">c</span>(<span class="dv">1983</span>,<span class="dv">12</span>))

FOJC_mod_CM1984 &lt;-<span class="st"> </span><span class="kw">update</span>(FOJC_mod_CM1, <span class="dt">start =</span> <span class="kw">c</span>(<span class="dv">1984</span>,<span class="dv">1</span>), <span class="dt">end =</span> <span class="kw">c</span>(<span class="dv">2000</span>,<span class="dv">12</span>))</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># plot estimated dynamic cumulative multipliers (1950-1966)</span>
<span class="kw">plot</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">18</span>, FOJC_mod_CM1950<span class="op">$</span>coefficients[<span class="op">-</span><span class="dv">1</span>], 
     <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, 
     <span class="dt">lwd =</span> <span class="dv">2</span>, 
     <span class="dt">col =</span> <span class="st">&quot;steelblue&quot;</span>,
     <span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">20</span>),
     <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="fl">0.5</span>, <span class="dv">2</span>),
     <span class="dt">xlab =</span> <span class="st">&quot;Lag&quot;</span>,
     <span class="dt">ylab =</span> <span class="st">&quot;Cumulative dynamic multiplier&quot;</span>,
     <span class="dt">main =</span> <span class="st">&quot;Cumulative Dynamic Effect for Different Sample Periods&quot;</span>
)

<span class="co"># plot estimated dynamic multipliers (1967-1983)</span>
<span class="kw">lines</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">18</span>, FOJC_mod_CM1967<span class="op">$</span>coefficients[<span class="op">-</span><span class="dv">1</span>], <span class="dt">lwd =</span> <span class="dv">2</span>)

<span class="co"># plot estimated dynamic multipliers (1984-2000)</span>
<span class="kw">lines</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">18</span>, FOJC_mod_CM1984<span class="op">$</span>coefficients[<span class="op">-</span><span class="dv">1</span>], <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="st">&quot;darkgreen&quot;</span>)

<span class="co"># add dashed line at 0</span>
<span class="kw">abline</span>(<span class="dt">h =</span> <span class="dv">0</span>, <span class="dt">lty =</span> <span class="dv">2</span>)

<span class="co"># add annotations</span>
<span class="kw">text</span>(<span class="dv">18</span>, <span class="op">-</span><span class="fl">0.24</span>, <span class="st">&quot;1984 - 2000&quot;</span>)
<span class="kw">text</span>(<span class="dv">18</span>, <span class="fl">0.6</span>, <span class="st">&quot;1967 - 1983&quot;</span>)
<span class="kw">text</span>(<span class="dv">18</span>, <span class="fl">1.2</span>, <span class="st">&quot;1950 - 1966&quot;</span>)</code></pre></div>
<p><img src="URFITE_files/figure-html/unnamed-chunk-416-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Clearly, the cumulative dynamic multipliers have changed considerarbly over time. Notice that the effect of a freeze was stronger an more persistent in the 1950s and 1960s. For the 1970s the magnitude of the effect was lower but still highly persistent. We observe an even lower magnitude for the final third of the sample (1984 - 2000) where the long-run effect is much less persist and essentialy zero after a year.</p>
<p>Evidence of a QLR test for a break in the population distributed lag regression of column (1) with <span class="math inline">\(15\%\)</span> trimming and HAC variance-covariance matrix estimator supports the conjection that the population regression coefficients have changed over time.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># set up a range of possible break dates</span>
tau &lt;-<span class="st"> </span><span class="kw">c</span>(
  <span class="kw">window</span>(
    <span class="kw">time</span>(FDD), 
    <span class="kw">time</span>(FDD)[<span class="kw">round</span>(<span class="dv">612</span><span class="op">/</span><span class="dv">100</span><span class="op">*</span><span class="dv">15</span>)], 
    <span class="kw">time</span>(FDD)[<span class="kw">round</span>(<span class="dv">612</span><span class="op">/</span><span class="dv">100</span><span class="op">*</span><span class="dv">85</span>)]
    )
  )

<span class="co"># initialize vector of F-statistics</span>
Fstats &lt;-<span class="st"> </span><span class="kw">numeric</span>(<span class="kw">length</span>(tau))

<span class="co"># restricted model</span>
res_model &lt;-<span class="st"> </span><span class="kw">update</span>(unres_model, <span class="dt">formula =</span> . <span class="op">~</span><span class="st"> </span><span class="kw">L</span>(FDD, <span class="dv">0</span><span class="op">:</span><span class="dv">18</span>))


<span class="co"># estimation loop over break dates</span>
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(tau)) {
  
  <span class="co"># set up dummy variable</span>
  D &lt;-<span class="st"> </span><span class="kw">time</span>(FOJC_pctc) <span class="op">&gt;</span><span class="st"> </span>tau[i]
  
  <span class="co"># estimate DL model with intercations</span>
  unres_model &lt;-<span class="st"> </span><span class="kw">dynlm</span>(FOJC_pctc <span class="op">~</span><span class="st"> </span><span class="kw">L</span>(FDD, <span class="dv">0</span><span class="op">:</span><span class="dv">18</span>) <span class="op">+</span><span class="st"> </span>D<span class="op">*</span><span class="kw">L</span>(FDD, <span class="dv">0</span><span class="op">:</span><span class="dv">18</span>))
                 
  <span class="co"># compute and save F-statistic</span>
  Fstats[i] &lt;-<span class="st"> </span><span class="kw">waldtest</span>(unres_model, 
                        res_model, 
                        <span class="dt">vcov =</span> <span class="kw">NeweyWest</span>(unres_model, <span class="dt">lag =</span> <span class="dv">7</span>, <span class="dt">prewhite =</span> F))<span class="op">$</span>F[<span class="dv">2</span>]
    
}</code></pre></div>
<p>Note that this code takes a couple of seconds to run since a total of 429 regressions with 40 model coefficients each are estimated.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># QLR test statistic</span>
<span class="kw">max</span>(Fstats)</code></pre></div>
<pre><code>## [1] 36.76819</code></pre>
<p>The QLR statistic is <span class="math inline">\(36.77\)</span>. From table 14.5 of the book we see that the <span class="math inline">\(1\%\)</span> critical value for the QLR test with <span class="math inline">\(15\%\)</span> trimming and <span class="math inline">\(q=20\)</span> restrictions is <span class="math inline">\(2.43\)</span>. Since this is a right-sided test, the QLR statistic clearly lies in the region of rejection so we can discard the null hypothesis of no break in the population regression function.</p>
<p>See Chapter 15.7 of the book for a discussion of empirical examples where it is questionable whether the assumption of (past and present) exogeneity of regressors is plausible.</p>

</div>
<!-- </div> -->














            </section>

          </div>
        </div>
      </div>
<a href="estimation-of-dynamic-causal-effects-with-strictly-exogeneous-regressors.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 1
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/15-ch15.Rmd",
"text": "Edit"
},
"download": ["URFITE.pdf"],
"toc": {
"collapse": "subsection",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
